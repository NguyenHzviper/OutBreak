{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import joblib\n",
    "from statistics import mean \n",
    "\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import  RandomForest, LinearRegressionModel, LightGBMModel, \\\n",
    "                        CatBoostModel, XGBModel,  BlockRNNModel, NBEATSModel, NHiTSModel, \\\n",
    "                        TCNModel, TFTModel\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = '../'\n",
    "data_path = prj_path + \"data/new_data/DH/squeezed/\"\n",
    "prj_path_opt= prj_path + \"optimize_hyperparam/opt_results/\"\n",
    "output_process = prj_path + \"data/new_data/DH/processed_data/\"\n",
    "output_featureselection = prj_path + \"data/new_data/DH/feature_selection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = [\n",
    "        'An Giang', 'BR Vũng Tàu', 'Bình Phước', 'Bình Thuận', 'Bình Định',\n",
    "        'Bạc Liêu', 'Bắc Kạn', 'Bắc Giang', 'Cao Bằng', 'Cà Mau',\n",
    "        'Cần Thơ', 'Gia Lai', 'Hà Giang', 'Hà Nội', 'Hà Tĩnh',\n",
    "        'Hòa Bình','Hưng Yên', 'Hải Dương', 'Hải Phòng', 'Khánh Hòa', 'Kiên Giang',\n",
    "        'Kon Tum', 'Lai Châu', 'Long An', 'Lào Cai', 'Lâm Đồng',\n",
    "        'Lạng Sơn','Nam Định', 'Nghệ An', 'Ninh Bình', 'Ninh Thuận',\n",
    "        'Phú Thọ', 'Phú Yên', 'Quảng Bình', 'Quảng Nam', 'Quảng Ngãi',\n",
    "        'Quảng Ninh', 'Quảng Trị', 'Sóc Trăng', 'Sơn La', 'TT Huế',\n",
    "        'Thanh Hóa', 'Thái Bình', 'Thái Nguyên', 'Tiền Giang', 'Trà Vinh',\n",
    "        'Tuyên Quang', 'Tây Ninh', 'Vĩnh Phúc', 'Yên Bái', 'Điện Biên',\n",
    "        'Đà Nẵng', 'Đắk Nông', 'Đắk Lắk', 'Đồng Tháp'\n",
    "]\n",
    "cities = ['Hà Nội','Hải Phòng','Quảng Ninh','Nam Định','Thái Bình','Quảng Nam','Quảng Ngãi', 'Phú Yên',\n",
    "          'Ninh Thuận', 'Bình Thuận', 'Tây Ninh', 'Bình Phước', 'An Giang', 'Tiền Giang','Cần Thơ', 'Trà Vinh']\n",
    "cities = [ 'Bình Phước', 'An Giang','Quảng Ninh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters as args using the Configuration class\n",
    "class Configuration():\n",
    "    def __init__(self):\n",
    "        # lấy bộ test dài 36 tháng = 3 năm\n",
    "        self.test_size = 36\n",
    "        # là nhìn vào dữ liệu trước 3 tháng và dự phóng        \n",
    "        self.look_back = 3\n",
    "        # dự phóng n-step trong 6 tháng\n",
    "        self.n_predicted_period_months = 6\n",
    "        self.n_features = 3\n",
    "        self.seed = 42\n",
    "        # mỗi phần tử x trong tập suppervise có độ lớn là 16 = 16 tháng\n",
    "        self.batch_size = 16\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.epochs = 300\n",
    "        #others\n",
    "        self.labels = \"Dengue_fever_rates\"\n",
    "        # Input param for Optimize Run\n",
    "        self.ntry = 1\n",
    "        self.njob = 1\n",
    "\n",
    "args = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_to_telegram(message):\n",
    "\n",
    "    apiToken = '5908735099:AAGVSLrW62aXPBP-GrMvxoVgMsuJxXJpP1Q'\n",
    "    chatID = '@ptn_announcement'\n",
    "    apiURL = f'https://api.telegram.org/bot{apiToken}/sendMessage'\n",
    "\n",
    "    try:\n",
    "        response = requests.post(apiURL, json={'chat_id': chatID, 'text': message})\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        message_error = \"Bị lỗi rùi: \"+str(e)\n",
    "        response = requests.post(apiURL, json={'chat_id': chatID, 'text': message_error})\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_all_city_data():\n",
    "  cities_data = {}  \n",
    "  for city in cities:\n",
    "    city_result = pd.read_excel(prj_path+'data/new_data/DH/squeezed/squeezed_'+city+'.xlsx')  \n",
    "    \"\"\"Get all data from all city in 1997 - 2016\"\"\" \n",
    "    city_result = city_result.loc[city_result['year_month'] < '2017-1-1'] \n",
    "    cities_data[city] = city_result\n",
    "  return cities_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data (pre-)processing functions\n",
    "# modification\n",
    "def get_city_data(city_name, dict_full_data):\n",
    "    \"\"\"Returns Dengue fever rate and climate data\"\"\" \n",
    "    city_data = dict_full_data[city_name].drop(columns=['Diarrhoea_cases','Diarrhoea_rates', 'province',\n",
    "                                                        'Influenza_rates','Influenza_cases',\n",
    "                                                        'Dengue_fever_cases', 'year', 'month'], \n",
    "                                                                  axis=1, \n",
    "                                                                  inplace=False)    \n",
    "    return city_data\n",
    "\n",
    "def convert_to_stationary(city_data):\n",
    "    \"\"\"Subtracts previous value for all cols except disease rates\"\"\"\n",
    "    for col_name in city_data.columns:\n",
    "        if col_name != 'Dengue_fever_rates':\n",
    "            try:\n",
    "                city_data[col_name] = city_data[col_name] - city_data[col_name].shift()\n",
    "            except:\n",
    "                print(col_name)\n",
    "    return city_data\n",
    "\n",
    "def impute_missing_value(city_data):\n",
    "    \"\"\"\n",
    "    Imputes 0 for first 12 months, \n",
    "    last year's value for months 12-24, \n",
    "    and minimum value of last two years for months 25+\n",
    "    \"\"\"\n",
    "    for col in city_data.columns:\n",
    "        for index in range(len(city_data[col])):\n",
    "            if np.isnan(city_data[col].iloc[index]):\n",
    "                if index < 12:\n",
    "                    city_data[col].iloc[index] = 0\n",
    "                elif index >= 12 and index <= 24:\n",
    "                    city_data[col].iloc[index] = city_data[col].iloc[index - 12]\n",
    "                else:\n",
    "                    city_data[col].iloc[index] = min(city_data[col].iloc[index - 12], city_data[col].iloc[index - 24])\n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_full_data(dict_full_data):\n",
    "    climate_and_disease_feats = ['Total_Evaporation',\n",
    "       'Total_Rainfall', 'Max_Daily_Rainfall', 'n_raining_days',\n",
    "       'Average_temperature', 'Max_Average_Temperature',\n",
    "       'Min_Average_Temperature', 'Max_Absolute_Temperature',\n",
    "       'Min_Absolute_Temperature', 'Average_Humidity', 'Min_Humidity',\n",
    "       'n_hours_sunshine', 'Dengue_fever_rates']\n",
    "    for city in cities:\n",
    "        city_data = get_city_data(city_name=city,dict_full_data = dict_full_data)\n",
    "        city_data_features = city_data[climate_and_disease_feats]\n",
    "        city_data_features = impute_missing_value(city_data_features)\n",
    "        city_data_features = convert_to_stationary(city_data_features)\n",
    "        city_data_features.dropna(inplace=True)\n",
    "        city_data_features.loc[:, \"year_month\"] = city_data[\"year_month\"]\n",
    "        dict_full_data[city] = city_data_features\n",
    "    return dict_full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, look_back, n_nextstep = args.n_predicted_period_months):\n",
    "    \"\"\"Splits data into train and test sets based on args (Configuration class)\"\"\"\n",
    "    train = data[: -args.test_size]    \n",
    "    test = data[-args.test_size - look_back-(n_nextstep - 1): ]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(data,  d_out, d_in, features_list=[]):\n",
    "    \"\"\"\n",
    "    Frames time-series as supervised learning dataset.\n",
    "    \n",
    "    Args:\n",
    "      d_in: lookback window\n",
    "      d_out: number of predicted months\n",
    "      features_list: list of all features **where last col is the disease incidence**\n",
    "\n",
    "    Returns:\n",
    "      Numpy arrays of disease incidence (y) and other predictors (X)\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for index, _ in enumerate(data):\n",
    "        in_end = index + d_in\n",
    "        out_end = in_end + d_out\n",
    "        if out_end <= len(data):\n",
    "            if len(features_list) == 0 :\n",
    "                X.append(data[index: in_end, :-1])\n",
    "            else:\n",
    "                X.append(data[index: in_end, features_list])\n",
    "            y.append(data[out_end-1: out_end, -1])\n",
    "    return np.array(X), np.array(y).reshape(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(df_full, model_name, location, feature_list, labels, scaler, cfg):\n",
    "    \"\"\"\n",
    "    $df: pandas.DataFrame object containing data for training and testing model:\n",
    "    $model: darts model object\n",
    "    $feature_list: Names of the features used as model input\n",
    "    $label: the value the model will be trained to predict\n",
    "    $scaler: scaler object. Note: the scaler will be fitted on training data and applied to test data\n",
    "    $lags: how much to look back into the past to output prediction\n",
    "    $split_index: the point at which to divide train and test_data\n",
    "\n",
    "    \"\"\"\n",
    "    order, sorder, trend = cfg\n",
    "    trainlist = [x for x in df_full.Dengue_fever_rates]\n",
    "    nstep = args.n_predicted_period_months\n",
    "\n",
    "    if(model_name == \"SARIMA\"):\n",
    "        predict_list = []\n",
    "        for i in range (args.test_size+(nstep-1)):\n",
    "            history = trainlist[:-args.test_size-(nstep-1-i)]\n",
    "            model = SARIMAX(history, \n",
    "                            order=order, \n",
    "                            seasonal_order=sorder, \n",
    "                            trend = trend,\n",
    "                            enforce_stationarity=False,\n",
    "                            enforce_invertibility=False)\n",
    "            model_fit = model.fit(disp=False)\n",
    "            yhat = model_fit.predict(len(history), len(history) + nstep - 1)\n",
    "            predict_list.append(yhat)\n",
    "    y_pred_list = []\n",
    "    for step in range(nstep):\n",
    "        moving = nstep-1-step\n",
    "        y_pred_list.append([x[step] for x in predict_list][moving:args.test_size+moving])\n",
    "\n",
    "    df_eval_true_inverse = df_full[-args.test_size:]\n",
    "    y_true = scaler.inverse_transform(df_eval_true_inverse.iloc[:,:-1])[:,[-1]].reshape(args.test_size)\n",
    "\n",
    "    y_pred_inverse_list = []\n",
    "    for step in range(nstep):\n",
    "        df_eval_pred_inverse = df_full[-args.test_size:]\n",
    "        df_eval_pred_inverse[args.labels]= y_pred_list[step] #step 1\n",
    "        y_pred_inverse = scaler.inverse_transform(df_eval_pred_inverse.iloc[:,:-1])[:,[-1]].reshape(args.test_size)\n",
    "        y_pred_inverse_list.append(y_pred_inverse)\n",
    "\n",
    "    y_pred_inverse_list\n",
    "    df_compare_test_predict = pd.DataFrame({\n",
    "        'y_true':y_true,\n",
    "        'y_pred_1step':y_pred_inverse_list[0],\n",
    "        'y_pred_2step':y_pred_inverse_list[1],\n",
    "        'y_pred_3step':y_pred_inverse_list[2],\n",
    "        'y_pred_4step':y_pred_inverse_list[3],\n",
    "        'y_pred_5step':y_pred_inverse_list[4],\n",
    "        'y_pred_6step':y_pred_inverse_list[5],\n",
    "        })\n",
    "    df_compare_test_predict.plot()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    mse_nstep = []\n",
    "    mae_nstep = []\n",
    "    rmse_nstep = []\n",
    "    mape_nstep = []\n",
    "    for step in range(nstep):\n",
    "        mse_nstep.append(mean_squared_error(y_true, y_pred_inverse_list[step]))\n",
    "        mae_nstep.append(mean_absolute_error(y_true, y_pred_inverse_list[step]))\n",
    "        rmse_nstep.append(mse_nstep[step]**0.5)\n",
    "        mape_nstep.append(mean_absolute_percentage_error(y_true, y_pred_inverse_list[step]))\n",
    "    return model, y_true, y_pred_inverse_list, mse_nstep, mae_nstep, rmse_nstep, mape_nstep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction_for_location(df_full, model_name, location, feature_list, \n",
    "                                                labels, scaler, cfg):\n",
    "    \"\"\"train and generate prediction for a province\n",
    "    df: DataFrame object containing features and label(s) for training model\n",
    "    localtion: location_name\n",
    "    feature_list: list of features used as model input,  must be among the column names of df\n",
    "    labels: the values model will be trained to predict\n",
    "    scaler: sklearn scaler object\n",
    "    lags: how long into the past to look back when making prediction\n",
    "    split_index: the point at which to divide data into the train and test subsets.\n",
    "    \"\"\"\n",
    "    model, y_true, y_pred_inverse_list, mse_nstep, mae_nstep, rmse_nstep, mape_nstep = train_and_evaluate(df_full, model_name, location, feature_list, labels, scaler, cfg)\n",
    "    \n",
    "    df_prediction = pd.DataFrame({\"Date\": df_full[\"year_month\"][-args.test_size:],\n",
    "                                  \"Observed\": y_true[-args.test_size:],\n",
    "                                  f\"{1}-month\": y_pred_inverse_list[0],\n",
    "                                  f\"{2}-month\": y_pred_inverse_list[1],\n",
    "                                  f\"{3}-month\": y_pred_inverse_list[2],\n",
    "                                  f\"{4}-month\": y_pred_inverse_list[3],\n",
    "                                  f\"{5}-month\": y_pred_inverse_list[4],\n",
    "                                  f\"{6}-month\": y_pred_inverse_list[5]})\n",
    "    \n",
    "    df_prediction[\"City\"] = location\n",
    "    for step in range(args.n_predicted_period_months):\n",
    "        df_prediction[f\"RMSE_{step+1}-month\"] = rmse_nstep[step]\n",
    "        df_prediction[f\"MAE_{step+1}-month\"] = mae_nstep[step]\n",
    "        df_prediction[f\"MAPE_{step+1}-month\"] = mape_nstep[step]\n",
    "        df_prediction[f\"MSE_{step+1}-month\"] = mse_nstep[step]\n",
    "    print(\"⭐️⭐️⭐️⭐️⭐️⭐️⭐️\")\n",
    "    display(df_prediction.head(5))\n",
    "    print(mean(mae_nstep))\n",
    "    return mean(mae_nstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataWithSelectedFeature(city, next_predicted_month):\n",
    "  selected_feature = []\n",
    "  df = pd.read_csv(output_featureselection+str(next_predicted_month)+\"step_feature_selection_3_most.csv\")\n",
    "  for row in range(len(df)):\n",
    "    if (df[\"City\"][row] == city):\n",
    "      selected_feature.append(df[\"1st_Feature\"][row])\n",
    "      selected_feature.append(df[\"2nd_Feature\"][row])\n",
    "      selected_feature.append(df[\"3rd_Feature\"][row])\n",
    "  return selected_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective and Suggest Hyperparams of Darts Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(model_name, trial, city):   \n",
    "    specific_data = pd.read_csv(output_process+city+'_train_preprocessed.csv', parse_dates=True, index_col= None, encoding = 'unicode_escape')\n",
    "    scaler = joblib.load(output_process+city+'_train_scalerMinMaxNorm.save') #ok\n",
    "    # df_train, df_valid = split_data(specific_data, args.look_back,nstep)\n",
    "\n",
    "    selected_features = getDataWithSelectedFeature(city, 6)\n",
    "\n",
    "    # lags_by_nstep = args.look_back + nstep - 1\n",
    "    # lags_past_covariates_by_nstep = [-lags_by_nstep+2,-lags_by_nstep+1,-lags_by_nstep] #Mảng này chứa ba giá trị tương ứng cho args.lookback 3\n",
    "    # is_dl_algo = 0\n",
    "    # is_sklearn_model = 0\n",
    "\n",
    "    if model_name == \"SARIMA\":\n",
    "      p = trial.suggest_int('p', 0, 5)\n",
    "      d = trial.suggest_int('d', 0, 1)\n",
    "      q = trial.suggest_int('q', 0, 5)\n",
    "      t = trial.suggest_categorical('t', ['n', 'c', 't', 'ct'])\n",
    "      P = trial.suggest_int('P', 0, 6)\n",
    "      D = trial.suggest_int('D', 0, 1)\n",
    "      Q = trial.suggest_int('Q', 0, 6)\n",
    "      m = trial.suggest_categorical('m', [6, 12])\n",
    "      cfg = [(p, d, q), (P, D, Q, m), t]\n",
    "\n",
    "    # elif model_name == 'SARIMAX':\n",
    "    #   p = trial.suggest_int('p', 0, 5)\n",
    "    #   d = trial.suggest_int('d', 0, 1)\n",
    "    #   q = trial.suggest_int('q', 0, 5)\n",
    "    #   t = trial.suggest_categorical('t', ['n', 'c', 't', 'ct'])\n",
    "    #   P = trial.suggest_int('P', 0, 6)\n",
    "    #   D = trial.suggest_int('D', 0, 1)\n",
    "    #   Q = trial.suggest_int('Q', 0, 6)\n",
    "    #   m = trial.suggest_categorical('m', [6, 12])\n",
    "\n",
    "    #   cfg = [(p, d, q), (P, D, Q, m), t]\n",
    "    \n",
    "    mae_error = output_prediction_for_location(specific_data, model_name, location=city, feature_list=selected_features,\n",
    "                                                labels=args.labels, scaler=scaler,cfg = cfg)\n",
    "\n",
    "    return mae_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main run optimize and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-02 10:48:52,193] A new study created in memory with name: SARIMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⭐️⭐️⭐️⭐️⭐️⭐️⭐️⭐️ Model_name:  SARIMA\n",
      "⭐️⭐️ City:  Bình Phước\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-11-02 10:49:10,140] Trial 0 failed with parameters: {'p': 0, 'd': 0, 'q': 4, 't': 'c', 'P': 5, 'D': 0, 'Q': 5, 'm': 6} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_1979/711090237.py\", line 34, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index])\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_1979/726751381.py\", line 36, in objective\n",
      "    mae_error = output_prediction_for_location(specific_data, model_name, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_1979/1746125129.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, y_pred_inverse_list, mse_nstep, mae_nstep, rmse_nstep, mape_nstep = train_and_evaluate(df_full, model_name, location, feature_list, labels, scaler, cfg)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_1979/1019962422.py\", line 26, in train_and_evaluate\n",
      "    model_fit = model.fit(disp=False)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 704, in fit\n",
      "    mlefit = super(MLEModel, self).fit(start_params, method=method,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py\", line 566, in fit\n",
      "    xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/base/optimizer.py\", line 242, in _fit\n",
      "    xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/base/optimizer.py\", line 659, in _fit_lbfgs\n",
      "    retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_lbfgsb_py.py\", line 199, in fmin_l_bfgs_b\n",
      "    res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_lbfgsb_py.py\", line 365, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py\", line 286, in fun_and_grad\n",
      "    self._update_grad()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py\", line 256, in _update_grad\n",
      "    self._update_grad_impl()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py\", line 173, in update_grad\n",
      "    self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_numdiff.py\", line 505, in approx_derivative\n",
      "    return _dense_difference(fun_wrapped, x0, f0, h,\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_numdiff.py\", line 576, in _dense_difference\n",
      "    df = fun(x) - f0\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_numdiff.py\", line 456, in fun_wrapped\n",
      "    f = np.atleast_1d(fun(x, *args, **kwargs))\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py\", line 534, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 939, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 1001, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 924, in _filter\n",
      "    kfilter()\n",
      "KeyboardInterrupt\n",
      "[W 2023-11-02 10:49:10,141] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m obj_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m trial: objective(model_name, trial, cities[city_index])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   \u001b[39m# Optimise over 100 trials\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   study\u001b[39m.\u001b[39;49moptimize(obj_func, n_trials\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mntry, n_jobs\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mnjob)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m   \u001b[39m# Print results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStudy statistics for : \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(sampler\u001b[39m=\u001b[39msampler, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, study_name \u001b[39m=\u001b[39m model_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# truyền multiple param vào trong biến trial\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m obj_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m trial: objective(model_name, trial, cities[city_index])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   \u001b[39m# Optimise over 100 trials\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   study\u001b[39m.\u001b[39moptimize(obj_func, n_trials\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mntry, n_jobs\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnjob)\n",
      "\u001b[1;32m/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m   cfg \u001b[39m=\u001b[39m [(p, d, q), (P, D, Q, m), t]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# elif model_name == 'SARIMAX':\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#   p = trial.suggest_int('p', 0, 5)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#   d = trial.suggest_int('d', 0, 1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#   cfg = [(p, d, q), (P, D, Q, m), t]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m mae_error \u001b[39m=\u001b[39m output_prediction_for_location(specific_data, model_name, location\u001b[39m=\u001b[39;49mcity, feature_list\u001b[39m=\u001b[39;49mselected_features,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                                             labels\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlabels, scaler\u001b[39m=\u001b[39;49mscaler,cfg \u001b[39m=\u001b[39;49m cfg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mae_error\n",
      "\u001b[1;32m/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moutput_prediction_for_location\u001b[39m(df_full, model_name, location, feature_list, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                 labels, scaler, cfg):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"train and generate prediction for a province\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    df: DataFrame object containing features and label(s) for training model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    localtion: location_name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m    split_index: the point at which to divide data into the train and test subsets.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     model, y_true, y_pred_inverse_list, mse_nstep, mae_nstep, rmse_nstep, mape_nstep \u001b[39m=\u001b[39m train_and_evaluate(df_full, model_name, location, feature_list, labels, scaler, cfg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     df_prediction \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m\"\u001b[39m: df_full[\u001b[39m\"\u001b[39m\u001b[39myear_month\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mtest_size:],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                   \u001b[39m\"\u001b[39m\u001b[39mObserved\u001b[39m\u001b[39m\"\u001b[39m: y_true[\u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mtest_size:],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-month\u001b[39m\u001b[39m\"\u001b[39m: y_pred_inverse_list[\u001b[39m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m5\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-month\u001b[39m\u001b[39m\"\u001b[39m: y_pred_inverse_list[\u001b[39m4\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m6\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-month\u001b[39m\u001b[39m\"\u001b[39m: y_pred_inverse_list[\u001b[39m5\u001b[39m]})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     df_prediction[\u001b[39m\"\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m location\n",
      "\u001b[1;32m/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m history \u001b[39m=\u001b[39m trainlist[:\u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mtest_size\u001b[39m-\u001b[39m(nstep\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mi)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model \u001b[39m=\u001b[39m SARIMAX(history, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                 order\u001b[39m=\u001b[39morder, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                 seasonal_order\u001b[39m=\u001b[39msorder, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                 trend \u001b[39m=\u001b[39m trend,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                 enforce_stationarity\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                 enforce_invertibility\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model_fit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(disp\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m yhat \u001b[39m=\u001b[39m model_fit\u001b[39m.\u001b[39mpredict(\u001b[39mlen\u001b[39m(history), \u001b[39mlen\u001b[39m(history) \u001b[39m+\u001b[39m nstep \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_291023_multioutput.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m predict_list\u001b[39m.\u001b[39mappend(yhat)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py:704\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         flags[\u001b[39m'\u001b[39m\u001b[39mhessian_method\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m optim_hessian\n\u001b[1;32m    703\u001b[0m     fargs \u001b[39m=\u001b[39m (flags,)\n\u001b[0;32m--> 704\u001b[0m     mlefit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(MLEModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(start_params, method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    705\u001b[0m                                        fargs\u001b[39m=\u001b[39;49mfargs,\n\u001b[1;32m    706\u001b[0m                                        maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    707\u001b[0m                                        full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[1;32m    708\u001b[0m                                        disp\u001b[39m=\u001b[39;49mdisp, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    709\u001b[0m                                        skip_hessian\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    711\u001b[0m \u001b[39m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mif\u001b[39;00m return_params:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_t\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    565\u001b[0m optimizer \u001b[39m=\u001b[39m Optimizer()\n\u001b[0;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49m_fit(f, score, start_params,\n\u001b[1;32m    567\u001b[0m                                                fargs, kwargs,\n\u001b[1;32m    568\u001b[0m                                                hessian\u001b[39m=\u001b[39;49mhess,\n\u001b[1;32m    569\u001b[0m                                                method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    570\u001b[0m                                                disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m    571\u001b[0m                                                maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    572\u001b[0m                                                callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    573\u001b[0m                                                retall\u001b[39m=\u001b[39;49mretall,\n\u001b[1;32m    574\u001b[0m                                                full_output\u001b[39m=\u001b[39;49mfull_output)\n\u001b[1;32m    575\u001b[0m \u001b[39m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    576\u001b[0m optim_settings\u001b[39m.\u001b[39mupdate(kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/optimizer.py:242\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    239\u001b[0m     fit_funcs\u001b[39m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    241\u001b[0m func \u001b[39m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 242\u001b[0m xopt, retvals \u001b[39m=\u001b[39m func(objective, gradient, start_params, fargs, kwargs,\n\u001b[1;32m    243\u001b[0m                      disp\u001b[39m=\u001b[39;49mdisp, maxiter\u001b[39m=\u001b[39;49mmaxiter, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    244\u001b[0m                      retall\u001b[39m=\u001b[39;49mretall, full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[1;32m    245\u001b[0m                      hess\u001b[39m=\u001b[39;49mhessian)\n\u001b[1;32m    247\u001b[0m optim_settings \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: method, \u001b[39m'\u001b[39m\u001b[39mstart_params\u001b[39m\u001b[39m'\u001b[39m: start_params,\n\u001b[1;32m    248\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m: maxiter, \u001b[39m'\u001b[39m\u001b[39mfull_output\u001b[39m\u001b[39m'\u001b[39m: full_output,\n\u001b[1;32m    249\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp, \u001b[39m'\u001b[39m\u001b[39mfargs\u001b[39m\u001b[39m'\u001b[39m: fargs, \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[1;32m    250\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mretall\u001b[39m\u001b[39m'\u001b[39m: retall, \u001b[39m\"\u001b[39m\u001b[39mextra_fit_funcs\u001b[39m\u001b[39m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    251\u001b[0m optim_settings\u001b[39m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/optimizer.py:659\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39melif\u001b[39;00m approx_grad:\n\u001b[1;32m    657\u001b[0m     func \u001b[39m=\u001b[39m f\n\u001b[0;32m--> 659\u001b[0m retvals \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mfmin_l_bfgs_b(func, start_params, maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    660\u001b[0m                                  callback\u001b[39m=\u001b[39;49mcallback, args\u001b[39m=\u001b[39;49mfargs,\n\u001b[1;32m    661\u001b[0m                                  bounds\u001b[39m=\u001b[39;49mbounds, disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m    662\u001b[0m                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kwargs)\n\u001b[1;32m    664\u001b[0m \u001b[39mif\u001b[39;00m full_output:\n\u001b[1;32m    665\u001b[0m     xopt, fopt, d \u001b[39m=\u001b[39m retvals\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_lbfgsb_py.py:199\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    187\u001b[0m callback \u001b[39m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m    188\u001b[0m opts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp,\n\u001b[1;32m    189\u001b[0m         \u001b[39m'\u001b[39m\u001b[39miprint\u001b[39m\u001b[39m'\u001b[39m: iprint,\n\u001b[1;32m    190\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxcor\u001b[39m\u001b[39m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[1;32m    197\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxls\u001b[39m\u001b[39m'\u001b[39m: maxls}\n\u001b[0;32m--> 199\u001b[0m res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[39m=\u001b[39;49margs, jac\u001b[39m=\u001b[39;49mjac, bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    200\u001b[0m                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopts)\n\u001b[1;32m    201\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mjac\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    202\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    203\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mfuncalls\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    204\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    205\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mwarnflag\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m    206\u001b[0m f \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[0;32m--> 286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    174\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m sparsity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[1;32m    506\u001b[0m                              use_one_sided, method)\n\u001b[1;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(sparsity) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sparsity) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[39m=\u001b[39m x[i] \u001b[39m-\u001b[39m x0[i]  \u001b[39m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[39m=\u001b[39m fun(x) \u001b[39m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3-point\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` return value has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mmore than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(params, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 534\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloglike(params, \u001b[39m*\u001b[39;49margs) \u001b[39m/\u001b[39m nobs\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py:939\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m complex_step:\n\u001b[1;32m    937\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minversion_method\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m INVERT_UNIVARIATE \u001b[39m|\u001b[39m SOLVE_LU\n\u001b[0;32m--> 939\u001b[0m loglike \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssm\u001b[39m.\u001b[39;49mloglike(complex_step\u001b[39m=\u001b[39;49mcomplex_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    941\u001b[0m \u001b[39m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[39m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mreturn\u001b[39;00m loglike\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[39m    The joint loglikelihood.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mconserve_memory\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[39m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m-> 1001\u001b[0m kfilter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1002\u001b[0m loglikelihood_burn \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mloglikelihood_burn\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1003\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloglikelihood_burn)\n\u001b[1;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (kwargs[\u001b[39m'\u001b[39m\u001b[39mconserve_memory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/kalman_filter.py:924\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_state(prefix\u001b[39m=\u001b[39mprefix, complex_step\u001b[39m=\u001b[39mcomplex_step)\n\u001b[1;32m    923\u001b[0m \u001b[39m# Run the filter\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m kfilter()\n\u001b[1;32m    926\u001b[0m \u001b[39mreturn\u001b[39;00m kfilter\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Main cell for optimize ML algorithm\n",
    "#########################\n",
    "# Hai thuật toán này chưa chạy đc nhe, nên đừng truyền vô mảng để nó chạy nhoé!\n",
    "# \"PoissonRegressor\"\n",
    "# \"SVMRBF\"\n",
    "model_name_list = [\n",
    "    \"SARIMA\"\n",
    "    #  \"RandomForest\",\n",
    "    #  \"LinearRegressionModel\",\n",
    "    #  \"LightGBMModel\",\n",
    "    #  \"CatBoostModel\",\n",
    "    #  \"XGBModel\",\n",
    "    # \"SVMRBF\",\n",
    "    # \"PoissonRegressor\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# Lưu thông tin traceback study và error city trong quá trình optimize\n",
    "l_study_city ={}\n",
    "l_errCity =[]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  for model_name in model_name_list: \n",
    "    print(\"⭐️⭐️⭐️⭐️⭐️⭐️⭐️⭐️ Model_name: \",model_name)\n",
    "    best_param = pd.DataFrame()\n",
    "    for city_index in range(len(cities)):\n",
    "      print(\"⭐️⭐️ City: \",cities[city_index])\n",
    "      # Use Tree-structured Parzen Estimator sampler to minimise RMSE\n",
    "      sampler = optuna.samplers.TPESampler()\n",
    "      study = optuna.create_study(sampler=sampler, direction='minimize', study_name = model_name)\n",
    "      # truyền multiple param vào trong biến trial\n",
    "      obj_func = lambda trial: objective(model_name, trial, cities[city_index])\n",
    "      try:\n",
    "        # Optimise over 100 trials\n",
    "        study.optimize(obj_func, n_trials=args.ntry, n_jobs=args.njob)\n",
    "\n",
    "        # Print results\n",
    "        print(\"Study statistics for : \")\n",
    "        print(\"  Number of finished trials: \", len(study.trials))\n",
    "        print(\"Best trial of city: \",cities[city_index])\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "        print(\"🌈🌈🌈🌈🌈\")\n",
    "        print(best_trial.params)\n",
    "        print(\"🍓:\",best_trial.params['p'])\n",
    "        print(\"🍓:\",best_trial.params['p'])\n",
    "        # lưu best param vào trong biến toàn cục\n",
    "\n",
    "        if model_name == \"SARIMA\":\n",
    "            one_city_param = pd.DataFrame({\n",
    "                              'City':  [cities[city_index]],\n",
    "                              'Alg_name': 'SARIMA',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'p':best_trial.params['p'],\n",
    "                              'd':best_trial.params['d'],\n",
    "                              'q':best_trial.params['q'],\n",
    "                              't':best_trial.params['t'],\n",
    "                              'P':best_trial.params['P'],\n",
    "                              'D':best_trial.params['D'],\n",
    "                              'Q':best_trial.params['Q'],\n",
    "                              'm':best_trial.params['m']\n",
    "                          })\n",
    "            print(\"🔥🔥🔥🔥🔥🔥\")\n",
    "            display(one_city_param)\n",
    "        folder_path = f'opt_results/opt_res_ml_26102023/{model_name}/'\n",
    "        file_path = folder_path+ f'261023_DF_opt_hyperparam_{model_name}_multi-nstep.xlsx'\n",
    "        if(os.path.isfile(file_path)):\n",
    "            print(\"🐸\")\n",
    "            with pd.ExcelWriter(file_path,mode=\"a\",engine=\"openpyxl\",if_sheet_exists=\"overlay\") as writer:\n",
    "                one_city_param.to_excel(writer, header=None, startrow=city_index+1,index=False)\n",
    "        else:\n",
    "            print(\"🐹\")\n",
    "            if(not (os.path.isdir(folder_path))):\n",
    "              os.mkdir(folder_path)\n",
    "            with pd.ExcelWriter(file_path,engine=\"openpyxl\") as writer:\n",
    "                one_city_param.to_excel(writer, startrow=city_index,index=False)\n",
    "      except Exception as e:# có error thì lưu vào l_errCity để check lại sau \n",
    "        l_errCity.append(cities[city_index])\n",
    "        print(\"VÃI Ò CÓ LỖI!!!\")\n",
    "        print(e)\n",
    "        # send_to_telegram(\"TEST ARIMA error!\" )\n",
    "        # send_to_telegram(f'Tỉnh bị lỗi trong quá trình optimize bằng model {model_name}: {cities[city_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send_to_telegram(\"TEST ARIMA done!\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
