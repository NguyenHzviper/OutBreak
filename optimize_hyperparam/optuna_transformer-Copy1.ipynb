{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Smx2B-csrq"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17063,
     "status": "ok",
     "timestamp": 1675101187981,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "VW4v2IEcTYHa",
    "outputId": "3eae95c8-1dab-4f6b-be39-9e8ffc15a25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ftfy in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (6.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from ftfy) (0.2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (3.0.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: tqdm in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mlworker/.local/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: PyYAML in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.23.3)\n",
      "Requirement already satisfied: colorlog in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: cliff in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: Mako in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mlworker/.local/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mlworker/.local/lib/python3.9/site-packages (from cliff->optuna) (5.0.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mlworker/.local/lib/python3.9/site-packages (from importlib-metadata>=4.4->cliff->optuna) (3.8.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from stevedore>=2.0.1->cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "%pip install -U scikit-learn\n",
    "%pip install ftfy\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2280,
     "status": "ok",
     "timestamp": 1675101190254,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "b8I8S9koHjT_"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ftfy import fix_text\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA7yvJS1czVO"
   },
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3325,
     "status": "ok",
     "timestamp": 1675101193568,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "MNAuUk6_HVs1",
    "outputId": "9e3b5911-d2e8-4c20-9936-c0cbc4955010"
   },
   "outputs": [],
   "source": [
    "\n",
    "prj_path = '/home/mlworker/Quang/HealthCare/Source_14012023_v4/'\n",
    "data_path = prj_path + \"/data/\"\n",
    "prj_path_opt= prj_path + \"optimize_hyperparam/opt_results/opt_results_12022023_v4/\"\n",
    "\n",
    "os.chdir(prj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X94Oj9inc8Fk"
   },
   "source": [
    "# Create Dict data for all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1675101194240,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "ONDHBTEPRMTu"
   },
   "outputs": [],
   "source": [
    "cities = [\n",
    "     'Thanh Hóa', 'Thái Bình', 'Thái Nguyên', 'Tiền Giang', 'Trà Vinh',  'TT Huế',\n",
    "        ]\n",
    "\n",
    "def get_dict_all_city_data():\n",
    "  cities_data = {}  \n",
    "  for city in cities:\n",
    "    city_result = pd.read_excel(prj_path+'data/new_data/DH/squeezed/squeezed_'+city+'.xlsx')  \n",
    "    # Đoạn này rất quan trọng. Vì việc optimize không được đụng vào 24 tháng (2016-2017) để dự báo. \n",
    "    # Dữ liệu optimize tính từ 1997- 30/12/2015. Sau đó tách ra train và test trên bộ này.\n",
    "    # lọc 2 năm cuối ra khỏi bộ dữ liệu trước khi chạy optimize \n",
    "    # đoạn này áp dụng cho tất cả các bước optimize trong project\n",
    "    city_result = city_result.loc[city_result['year_month'] < '2013-1-1'] \n",
    "    cities_data[city] = city_result\n",
    "  return cities_data\n",
    "\n",
    "dict_full_data = get_dict_all_city_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUPWuxbOdBlU"
   },
   "source": [
    "# Seed and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194240,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "fVkHGeUPO6cO"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194241,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "lEn56jmQtEmD"
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters as args using the Configuration class\n",
    "class Configuration():\n",
    "    def __init__(self):\n",
    "        self.test_size = 24\n",
    "        self.look_back = 3\n",
    "        self.n_predicted_month = 3\n",
    "        self.n_features = 3\n",
    "        self.seed = 42\n",
    "        self.batch_size = 16\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.epochs = 300\n",
    "\n",
    "args = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OyQATbT2nRz"
   },
   "source": [
    "# Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194241,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "ukoPuS5CHvdl"
   },
   "outputs": [],
   "source": [
    "# Define data (pre-)processing functions\n",
    "# modification\n",
    "def get_city_data(city_name):\n",
    "    \"\"\"Returns Diarrhoea rate and climate data\"\"\" \n",
    "    city_data = dict_full_data[city_name].drop(columns=['Diarrhoea_cases', 'province', 'year_month',\n",
    "                                                        'Influenza_rates','Dengue_fever_rates',\n",
    "                                                        'Influenza_cases','Dengue_fever_cases', 'year', 'month'], \n",
    "                                                                  axis=1, \n",
    "                                                                  inplace=False)    \n",
    "    return city_data\n",
    "\n",
    "\n",
    "def convert_to_stationary(city_data):\n",
    "    \"\"\"Subtracts previous value for all cols except disease rates\"\"\"\n",
    "    for col_name in city_data.columns:\n",
    "        if col_name != 'Diarrhoea_rates':\n",
    "            try:\n",
    "                city_data[col_name] = city_data[col_name] - city_data[col_name].shift()\n",
    "            except:\n",
    "                print(col_name)\n",
    "    return city_data\n",
    "\n",
    "def impute_missing_value(city_data):\n",
    "    \"\"\"\n",
    "    Cơ bản dữ liệu bị thiếu sót rất nhiều: Như Điện Biên 1997 -2003 là thiếu dữ liệu về bệnh\n",
    "    Hàm này sẽ tự sinh ra dữ liệu bị thiếu. Nếu tháng nào không có số liệu thì tính như sau:\n",
    "    12 tháng đầu không có số liệu thì gán = 0\n",
    "    tháng 13-24 không có số liệu, sẽ lấy giá trị của tháng cùng kỳ năm trước\n",
    "    tháng từ 24 trở đi sẽ lấy giá trị nhỏ nhất của 2 tháng cùng kỳ trong 2 năm gần nhất.\n",
    "    Do Điện Biên bằng 0 nên sau khi xử lý từ 1997 -2003 là đều = 0.  \n",
    "    \"\"\"\n",
    "    for col in city_data.columns:\n",
    "        for index in range(len(city_data[col])):\n",
    "            if np.isnan(city_data[col].iloc[index]):\n",
    "                if index < 12:\n",
    "                    city_data[col].iloc[index] = 0\n",
    "                elif index >= 12 and index <= 24:\n",
    "                    city_data[col].iloc[index] = city_data[col].iloc[index - 12]\n",
    "                else:\n",
    "                    city_data[col].iloc[index] = min(city_data[col].iloc[index - 12], city_data[col].iloc[index - 24])\n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194241,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "RT8LmtHts4fQ"
   },
   "outputs": [],
   "source": [
    "def split_data(data, look_back ):\n",
    "    \"\"\"Splits data into train and test sets based on args (Configuration class)\"\"\"\n",
    "    train = data[: -args.test_size]\n",
    "    print('lookback', look_back)\n",
    "    test = data[-args.test_size - look_back: ]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "6Wdc44U0uMbP"
   },
   "outputs": [],
   "source": [
    "def to_supervised(data, d_in=args.look_back, d_out=args.n_predicted_month, features_list=[]):\n",
    "    \"\"\"\n",
    "    Frames time-series as supervised learning dataset.\n",
    "    \n",
    "    Args:\n",
    "      d_in: lookback window\n",
    "      d_out: number of predicted months\n",
    "      features_list: list of all features **where last col is the disease incidence**\n",
    "\n",
    "    Returns:\n",
    "      Numpy arrays of disease incidence (y) and other predictors (X)\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for index, _ in enumerate(data):\n",
    "        in_end = index + d_in\n",
    "        out_end = in_end + d_out\n",
    "        if out_end <= len(data):\n",
    "            if len(features_list) == 0 :\n",
    "                X.append(data[index: in_end, :])\n",
    "            else:\n",
    "                X.append(data[index: in_end, features_list])\n",
    "            y.append(data[in_end: out_end, -1])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "x_RfqYtVGTAk"
   },
   "outputs": [],
   "source": [
    "def select_feature(train, specific_data):\n",
    "    \"\"\"Selects args.n_features top features using RFE\"\"\"\n",
    "    train_X, train_y = to_supervised(train, d_in=1, d_out=1)\n",
    "    train_X, train_y = np.squeeze(train_X), np.squeeze(train_y)\n",
    "    rfe = RFE(RandomForestRegressor(n_estimators=500, random_state=args.seed), n_features_to_select=args.n_features)\n",
    "    fit = rfe.fit(train_X, train_y)\n",
    "    important_features = list()\n",
    "    # print(\"Important Feature:\")\n",
    "    for i in range(len(fit.support_)):\n",
    "        if fit.support_[i]:\n",
    "            important_features.append(i)\n",
    "            # print(specific_data.columns[i])\n",
    "    return np.array(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "OsgC3mbHV96C"
   },
   "outputs": [],
   "source": [
    "def get_data(train_np, test_np, batch_size, specific_data):\n",
    "    \"\"\"\n",
    "    Returns important feature list and data formatted for input into Pytorch \n",
    "    models\n",
    "    \"\"\"\n",
    "    important_features = select_feature(train_np, specific_data)\n",
    "\n",
    "    train_X, train_y = to_supervised(train_np, features_list=important_features)\n",
    "    test_X, test_y = to_supervised(test_np, features_list=important_features)\n",
    "    train_tensor = TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\n",
    "    test_tensor = (torch.from_numpy(test_X), torch.from_numpy(test_y))\n",
    "\n",
    "    train_loader = DataLoader(train_tensor, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return important_features, train_loader, test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "PW18DMZgF5K_"
   },
   "outputs": [],
   "source": [
    "#Define Pytorch LSTM model\n",
    "class MultiVariateLSTM(nn.Module):\n",
    "    def __init__(self, n_feature=3, n_layers=2, hidden_size=50):\n",
    "        super(MultiVariateLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_feature, hidden_size=hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, args.n_predicted_month)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "    \n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        output, (last_hidden, _) = self.lstm(X_batch)\n",
    "        last_hidden_vector = output[:, -1, :]\n",
    "        y_predicted = self.linear(last_hidden_vector)\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "            #return y_predicted, self.loss_fn(y_predicted, y_batch)\n",
    "        else:\n",
    "            return y_predicted\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X)\n",
    "\n",
    "#Define Pytorch LSTM-ATT model\n",
    "class MultiVariateLSTM_Attention(nn.Module):\n",
    "    def __init__(self, n_feature=3, n_layers=2, hidden_size=50):\n",
    "        super(MultiVariateLSTM_Attention, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_feature, hidden_size=hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.attention_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        # self.linear = nn.Linear(hidden_size*2, args.n_predicted_month)\n",
    "        self.linear = nn.Linear(hidden_size, args.n_predicted_month)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "    \n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        output, (last_hidden, _) = self.lstm(X_batch)\n",
    "        last_hidden_vector = last_hidden[-1]\n",
    "        remain_hidden_vector = output\n",
    "        e_t = remain_hidden_vector.bmm(self.attention_linear(last_hidden_vector).unsqueeze(2)).squeeze(-1)\n",
    "        alpha_t = F.softmax(e_t, dim=1)\n",
    "        attenion_vector = remain_hidden_vector.transpose(2, 1).bmm(alpha_t.unsqueeze(2)).squeeze(-1)\n",
    "        # combine_vector = torch.cat((last_hidden_vector, attenion_vector), dim=1)\n",
    "        # combine_vector = last_hidden_vector + attenion_vector\n",
    "        y_predicted = self.linear(attenion_vector)\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "            # return y_predicted, self.loss_fn(y_predicted, y_batch)\n",
    "        else:\n",
    "            return y_predicted\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X)\n",
    "\n",
    "# Define Pytorch CNN model\n",
    "class MultivariateCNN(nn.Module):\n",
    "    def __init__(self, num_filters=[100, 100, 100], dropout=0.01):\n",
    "        super(MultivariateCNN, self).__init__()\n",
    "        self.loss_fn = loss = nn.MSELoss()\n",
    "        self.filter_sizes = [1, 2, 3]\n",
    "        self.conv1d_list = nn.ModuleList([nn.Conv1d(args.n_features, num_filters[i], self.filter_sizes[i]) for i in range(len(self.filter_sizes))])\n",
    "        self.linear = nn.Linear(np.sum(num_filters), args.n_predicted_month)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "\n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        X_batch = X_batch.permute(0, 2, 1)  #(batch_size, n_features, n_look_back)\n",
    "        X_conv_list = [F.relu(conv1d(X_batch)) for conv1d in self.conv1d_list]\n",
    "        X_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2]) for x_conv in X_conv_list]\n",
    "        X_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in X_pool_list], dim=1)\n",
    "        y_predicted = self.linear(self.dropout(X_fc))\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "            # return y_predicted, self.loss_fn(y_predicted, y_batch)\n",
    "        else:\n",
    "            return y_predicted\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3TB2E72MDb"
   },
   "source": [
    "# Define Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675101194243,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "ZvmfYUt4vWeP"
   },
   "outputs": [],
   "source": [
    "# Define Pytorch Transformer model\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=3, n_feature=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(n_feature, d_model)\n",
    "        for pos in range(n_feature):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n",
    "                if i + 1 < d_model:\n",
    "                    pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n",
    "        pe = pe.unsqueeze(0)        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x*math.sqrt(self.d_model)\n",
    "        length = x.size(1)\n",
    "        pe = Variable(self.pe[:, :length], requires_grad=False)\n",
    "        if x.is_cuda:\n",
    "            pe.cuda()\n",
    "        x = x + pe\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, d_input=3, n_head=3, hidden_size=256, n_layers=3, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pe = PositionalEncoder(dropout=dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_input, nhead=n_head, dim_feedforward=hidden_size, dropout=dropout, activation='gelu')\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "        self.decoder = nn.Linear(d_input*n_head, args.n_predicted_month)\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        X_batch = self.pe(X_batch)\n",
    "        X_batch = self.transformer_encoder(X_batch)\n",
    "        X_batch = X_batch.view(X_batch.size(0), -1)\n",
    "        \n",
    "        y_predicted = self.decoder(X_batch)\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "        else:\n",
    "            return y_predicted\n",
    "        return X_batch\n",
    "    \n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaAY5LAp2Htc"
   },
   "source": [
    "# Class Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675101194243,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "8TvH93W9mNWQ"
   },
   "outputs": [],
   "source": [
    "# Create class to train and evaluate models\n",
    "class Trainer():\n",
    "    def __init__(self, city, model_type, learning_rate, important_features, train_loader, test_tensor, n_layers=2, hidden_size=128, num_filters=[100, 100, 100], dropout=0.01):\n",
    "        \"\"\"\n",
    "        Initialise trainer, allowing input of LSTM, LSTM-ATT, or CNN \n",
    "        hyperparameters. Adam optimiser used for all models.\n",
    "        \"\"\"\n",
    "        self.model_type = model_type    \n",
    "        self.city = city    \n",
    "        self.Model = self.init_model(model_type, n_layers, hidden_size, num_filters, dropout, city)\n",
    "        self.Model.double().to(args.device)\n",
    "        self.optimizer = torch.optim.Adam(self.Model.parameters(), lr=learning_rate)\n",
    "        self.important_features, self.train_loader, self.test_tensor = important_features, train_loader, test_tensor\n",
    "    \n",
    "    def init_model(self, model_type, n_layers, hidden_size, num_filters, dropout, city):\n",
    "        \"\"\"Initialise a model based on whether LSTM, LSTM-ATT, CNN or Transformer is chosen.\"\"\"\n",
    "        model = TransformerModel()\n",
    "        if model_type.lower() == 'lstm':\n",
    "            model = MultiVariateLSTM(args.n_features, n_layers, hidden_size)\n",
    "        elif model_type.lower() == 'lstm_attention':\n",
    "            model = MultiVariateLSTM_Attention(args.n_features, n_layers, hidden_size)\n",
    "        elif model_type.lower() == 'cnn':\n",
    "            model = MultivariateCNN(num_filters, dropout)\n",
    "        elif model_type.lower() == 'transformers':\n",
    "            model = TransformerModel(d_input=args.look_back, n_head=3, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
    "        return model\n",
    "\n",
    "    def step(self, batch):\n",
    "        self.Model.train()\n",
    "        X_batch, y_batch = tuple(t.to(args.device) for t in batch)\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred, loss = self.Model.forward(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.mean().item()\n",
    "\n",
    "    def validation(self):\n",
    "        self.Model.eval()\n",
    "        eval_loss = 0.0\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        y_true = np.array([])\n",
    "        y_pred = np.array([])\n",
    "\n",
    "        X_batch, y_batch = tuple(t.to(args.device) for t in self.test_tensor)\n",
    "        with torch.no_grad():\n",
    "            outputs, loss = self.Model.forward(X_batch, y_batch)\n",
    "            eval_loss = loss.mean().item()\n",
    "\n",
    "        return eval_loss\n",
    "\n",
    "    def train(self, epochs=20):\n",
    "        best_lost = float(\"inf\")\n",
    "        best_model = None\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            for batch in self.train_loader:\n",
    "                loss = self.step(batch)\n",
    "                total_loss += loss\n",
    "            train_loss = total_loss/len(self.train_loader)\n",
    "            eval_loss = self.validation()\n",
    "            if eval_loss < best_lost:\n",
    "                best_lost = eval_loss\n",
    "                best_model = copy.deepcopy(self.Model)\n",
    "            if (epoch + 1) == epochs or (epoch + 1) in [c + 1 for c in range(epochs) if c % int(epochs/4) == 0]:\n",
    "                print(f\"Epoch: {epoch:2}/{epochs:2} - train_loss: {train_loss:.4f} - test_loss: {eval_loss:4f}\")\n",
    "        self.Model = best_model\n",
    "        self.Model.eval()\n",
    "        return None\n",
    "\n",
    "    # Lưu model vào trong thư mục models\n",
    "    def save_model_to(self, path = '', city =''):       \n",
    "        torch.save(self.Model, path)\n",
    "\n",
    "    def load_model_to(self, path = ''):       \n",
    "        return torch.load(path)\n",
    "\n",
    "    def evaluate_model(self, np_data=None, plot=True, scaled=True, city=None, k_steps=None, y_scaler =None):\n",
    "        assert scaled, \"data must be scaled\"\n",
    "        self.Model.eval()\n",
    "        tensor_data = torch.from_numpy(np_data)\n",
    "        rmse_list = []\n",
    "        mae_list = [] \n",
    "        mape_list = []\n",
    "\n",
    "        y_predicted_list = []\n",
    "        y_true_list = []\n",
    "\n",
    "        for k_steps in range(1, args.n_predicted_month + 1):\n",
    "            y_predicted = []\n",
    "            y_true = []\n",
    "            for index in range(tensor_data.size(0) - args.look_back):\n",
    "                X = tensor_data[index: index + args.look_back, self.important_features]\n",
    "                # yhat = self.Model.predict(X.unsqueeze(0)).squeeze()\n",
    "\n",
    "                yhat = self.Model.predict(X.unsqueeze(0))\n",
    "                yhat = yhat.squeeze()\n",
    "\n",
    "                y_predicted.append(yhat.detach().cpu().numpy()[k_steps - 1])\n",
    "                y_true.append(tensor_data[index + args.look_back, -1].detach().cpu().numpy())\n",
    "\n",
    "            y_predicted = y_scaler.inverse_transform(np.array(y_predicted).reshape(-1, 1)).reshape(-1, )\n",
    "            y_true = y_scaler.inverse_transform(np.array(y_true).reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "            rmse = mean_squared_error(y_true, y_predicted, squared=False)\n",
    "            mae = mean_absolute_error(y_true, y_predicted)\n",
    "            mape = mean_absolute_percentage_error(y_true, y_predicted)\n",
    "\n",
    "            rmse_list.append(rmse)\n",
    "            mae_list.append(mae)\n",
    "            mape_list.append(mape)\n",
    "\n",
    "            # print('City: '+self.city+'  _algo:'+self.model_type+'  -RMSE: '+str(rmse))\n",
    "            if plot==True:\n",
    "              plt.grid(True)\n",
    "              plt.plot(y_predicted, label='predicted')\n",
    "              plt.plot(y_true, label='actual')\n",
    "              plt.title(f\"k-steps = {k_steps} - city: \"+self.city+'  _algo:'+self.model_type+'  -RMSE: '+str(rmse))\n",
    "              plt.legend()\n",
    "              plt.show()\n",
    "\n",
    "              plt.show()\n",
    "            y_predicted_list.append(y_predicted)\n",
    "            y_true_list.append(y_true)\n",
    "\n",
    "        return y_true_list, y_predicted_list, rmse_list, mae_list, mape_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gOIdsGo19Oc"
   },
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194243,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "8px_TDW2mtRt"
   },
   "outputs": [],
   "source": [
    "def objective(trial, city):\n",
    "    # Define search parameters\n",
    "    n_layers = trial.suggest_int('n layers', 3, 6) # a    \n",
    "    hidden_size = trial.suggest_int('Hidden size', 5, 384, log=True) #b\n",
    "    learning_rate = trial.suggest_loguniform('Learning rate', 1e-4, 1e-2)\n",
    "    dropout = trial.suggest_uniform('Dropout rate', 0.01, 0.80)\n",
    "    args.epochs = trial.suggest_int('Epochs', 100, 500, step=10)\n",
    "    lookback_window = 3 # fix cứng optimize sau\n",
    "\n",
    "    # Pre-process data\n",
    "    specific_data = get_city_data(fix_text(city))\n",
    "    specific_data = impute_missing_value(specific_data)\n",
    "    specific_data = convert_to_stationary(specific_data)\n",
    "    specific_data.dropna(inplace=True)\n",
    "\n",
    "    train, test = split_data(specific_data,lookback_window)\n",
    "\n",
    "    # Fit data scaler to training data\n",
    "    full_scaler = MinMaxScaler().fit(train)\n",
    "    y_scaler = MinMaxScaler().fit(train.values[:, -1].reshape(-1, 1))\n",
    "\n",
    "    # Scale train and test data\n",
    "    train = full_scaler.transform(train)\n",
    "    test = full_scaler.transform(test)\n",
    "\n",
    "    # Get data to run model\n",
    "    important_features, train_loader, test_tensor = get_data(train, test, args.batch_size, specific_data)\n",
    "\n",
    "    # Transformer model\n",
    "    trainer = Trainer(model_type='transformer',\n",
    "                  city = city,\n",
    "                  important_features=important_features,\n",
    "                  train_loader=train_loader,\n",
    "                  test_tensor=test_tensor,\n",
    "                  n_layers=n_layers,\n",
    "                  hidden_size=hidden_size,\n",
    "                  learning_rate=learning_rate,\n",
    "                  dropout=dropout)\n",
    "\n",
    "    # Train model\n",
    "    # trainer.train(epochs=args.epochs, trial=trial)\n",
    "    trainer.train(epochs=args.epochs)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_true, y_pred, rmse_list, mae_list, mape_list = trainer.evaluate_model(np_data=test, plot= False, scaled=True, city=city, y_scaler = y_scaler)\n",
    "    # _, _, rmse, mae, = trainer.evaluate_model(np_data=test, plot=False, scaled=True, city=city, y_scaler=y_scaler)\n",
    "\n",
    "    return mae_list[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHbv5lQ7dn3S"
   },
   "source": [
    "# Main Cell For Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggBbhETfXbsk",
    "outputId": "743bc695-4dd4-4b98-e665-df86250c4a04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-13 23:59:32,365]\u001b[0m A new study created in memory with name: no-name-70a3dbd6-f7a6-4ce5-adf3-95908ff60876\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/260 - train_loss: 1.3189 - test_loss: 0.867485\n",
      "Epoch:  0/260 - train_loss: 1.3649 - test_loss: 0.842023\n",
      "Epoch:  0/260 - train_loss: 1.2339 - test_loss: 1.041969\n",
      "Epoch:  0/260 - train_loss: 1.5622 - test_loss: 1.461736\n",
      "Epoch:  0/260 - train_loss: 1.0119 - test_loss: 0.597168Epoch:  0/260 - train_loss: 1.4304 - test_loss: 0.736624\n",
      "Epoch:  0/260 - train_loss: 1.1550 - test_loss: 0.778616\n",
      "\n",
      "Epoch:  0/260 - train_loss: 1.5150 - test_loss: 1.618645\n",
      "Epoch:  0/260 - train_loss: 0.9349 - test_loss: 0.737185\n",
      "Epoch:  0/260 - train_loss: 1.6335 - test_loss: 1.581276\n",
      "Epoch:  0/260 - train_loss: 1.2073 - test_loss: 0.877813Epoch:  0/260 - train_loss: 2.1909 - test_loss: 3.005919\n",
      "\n",
      "Epoch:  0/260 - train_loss: 2.1192 - test_loss: 1.989816\n",
      "Epoch:  0/260 - train_loss: 1.1761 - test_loss: 0.924223Epoch:  0/260 - train_loss: 1.6170 - test_loss: 2.083083\n",
      "\n",
      "Epoch:  0/260 - train_loss: 1.6406 - test_loss: 0.923469Epoch:  0/260 - train_loss: 1.1954 - test_loss: 1.044055\n",
      "\n",
      "Epoch:  0/260 - train_loss: 1.0805 - test_loss: 0.778984\n",
      "Epoch:  0/260 - train_loss: 0.8847 - test_loss: 0.637508\n",
      "Epoch:  0/260 - train_loss: 1.3167 - test_loss: 0.909443\n",
      "Epoch: 65/260 - train_loss: 0.4016 - test_loss: 0.210096\n",
      "Epoch: 65/260 - train_loss: 0.4467 - test_loss: 0.359706\n",
      "Epoch: 65/260 - train_loss: 0.3992 - test_loss: 0.244815\n",
      "Epoch: 65/260 - train_loss: 0.3634 - test_loss: 0.224029\n",
      "Epoch: 65/260 - train_loss: 0.3591 - test_loss: 0.241456\n",
      "Epoch: 65/260 - train_loss: 0.3940 - test_loss: 0.234583\n",
      "Epoch: 65/260 - train_loss: 0.3856 - test_loss: 0.309189\n",
      "Epoch: 65/260 - train_loss: 0.6979 - test_loss: 0.565538\n",
      "Epoch: 65/260 - train_loss: 0.4053 - test_loss: 0.321939\n",
      "Epoch: 65/260 - train_loss: 0.3783 - test_loss: 0.266915\n",
      "Epoch: 65/260 - train_loss: 0.6592 - test_loss: 0.586548\n",
      "Epoch: 65/260 - train_loss: 0.4861 - test_loss: 0.413489\n",
      "Epoch: 65/260 - train_loss: 0.3619 - test_loss: 0.242352\n",
      "Epoch: 65/260 - train_loss: 0.5658 - test_loss: 0.488458\n",
      "Epoch: 65/260 - train_loss: 0.5514 - test_loss: 0.483006Epoch: 65/260 - train_loss: 0.4706 - test_loss: 0.340499\n",
      "\n",
      "Epoch: 65/260 - train_loss: 0.5552 - test_loss: 0.493835Epoch: 65/260 - train_loss: 0.5937 - test_loss: 0.509008Epoch: 65/260 - train_loss: 0.4961 - test_loss: 0.390891\n",
      "\n",
      "\n",
      "Epoch: 65/260 - train_loss: 0.6823 - test_loss: 0.577608\n",
      "Epoch: 130/260 - train_loss: 0.4109 - test_loss: 0.237721\n",
      "Epoch: 195/260 - train_loss: 0.3758 - test_loss: 0.252924\n",
      "Epoch: 259/260 - train_loss: 0.3707 - test_loss: 0.230312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:19:27,834]\u001b[0m Trial 12 finished with value: 14.678395405604965 and parameters: {'n layers': 3, 'Hidden size': 7, 'Learning rate': 0.0014977948146712057, 'Dropout rate': 0.6473942526966988, 'Epochs': 200}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/400 - train_loss: 1.0022 - test_loss: 0.671165\n",
      "Epoch: 130/260 - train_loss: 0.4370 - test_loss: 0.350633\n",
      "Epoch: 130/260 - train_loss: 0.4422 - test_loss: 0.285730\n",
      "Epoch: 130/260 - train_loss: 0.3685 - test_loss: 0.216050\n",
      "Epoch: 130/260 - train_loss: 0.3590 - test_loss: 0.240935\n",
      "Epoch: 130/260 - train_loss: 0.4103 - test_loss: 0.244832\n",
      "Epoch: 130/260 - train_loss: 0.3648 - test_loss: 0.240070\n",
      "Epoch: 130/260 - train_loss: 0.3909 - test_loss: 0.221383\n",
      "Epoch: 130/260 - train_loss: 0.5394 - test_loss: 0.442434\n",
      "Epoch: 130/260 - train_loss: 0.4134 - test_loss: 0.330502Epoch: 130/260 - train_loss: 0.5047 - test_loss: 0.446325\n",
      "\n",
      "Epoch: 130/260 - train_loss: 0.3631 - test_loss: 0.254394\n",
      "Epoch: 130/260 - train_loss: 0.3808 - test_loss: 0.266437\n",
      "Epoch: 130/260 - train_loss: 0.3598 - test_loss: 0.270799\n",
      "Epoch: 130/260 - train_loss: 0.3567 - test_loss: 0.236942\n",
      "Epoch: 130/260 - train_loss: 0.4403 - test_loss: 0.346997\n",
      "Epoch: 130/260 - train_loss: 0.4549 - test_loss: 0.367415\n",
      "Epoch: 130/260 - train_loss: 0.5351 - test_loss: 0.446063\n",
      "Epoch: 130/260 - train_loss: 0.3611 - test_loss: 0.254163\n",
      "Epoch: 130/260 - train_loss: 0.3634 - test_loss: 0.261360\n",
      "Epoch: 195/260 - train_loss: 0.3673 - test_loss: 0.281233\n",
      "Epoch: 195/260 - train_loss: 0.3740 - test_loss: 0.238431\n",
      "Epoch: 195/260 - train_loss: 0.3695 - test_loss: 0.215946\n",
      "Epoch: 100/400 - train_loss: 0.3733 - test_loss: 0.251169\n",
      "Epoch: 195/260 - train_loss: 0.3572 - test_loss: 0.236787\n",
      "Epoch: 195/260 - train_loss: 0.4406 - test_loss: 0.350550\n",
      "Epoch: 259/260 - train_loss: 0.3933 - test_loss: 0.249951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:22:16,860]\u001b[0m Trial 3 finished with value: 19.592727409764706 and parameters: {'n layers': 4, 'Hidden size': 223, 'Learning rate': 0.0002302724325136032, 'Dropout rate': 0.35198434044099547, 'Epochs': 220}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 259/260 - train_loss: 0.3620 - test_loss: 0.242346\n",
      "Epoch: 195/260 - train_loss: 0.4434 - test_loss: 0.363283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:22:26,916]\u001b[0m Trial 10 finished with value: 18.648117363223935 and parameters: {'n layers': 5, 'Hidden size': 374, 'Learning rate': 0.00030995729514635167, 'Dropout rate': 0.41632339899382065, 'Epochs': 300}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 259/260 - train_loss: 0.4261 - test_loss: 0.218799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:23:01,753]\u001b[0m Trial 4 finished with value: 15.922447863523757 and parameters: {'n layers': 3, 'Hidden size': 32, 'Learning rate': 0.004888166649582021, 'Dropout rate': 0.16514804542981068, 'Epochs': 500}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/380 - train_loss: 1.2011 - test_loss: 0.793495\n",
      "Epoch: 259/260 - train_loss: 0.3633 - test_loss: 0.226688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:23:24,005]\u001b[0m Trial 0 finished with value: 16.322143867701424 and parameters: {'n layers': 3, 'Hidden size': 288, 'Learning rate': 0.0009829057983540858, 'Dropout rate': 0.29252547988198535, 'Epochs': 230}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/270 - train_loss: 1.6506 - test_loss: 1.052081\n",
      "Epoch: 195/260 - train_loss: 0.3587 - test_loss: 0.242713\n",
      "Epoch:  0/270 - train_loss: 1.0409 - test_loss: 0.661606\n",
      "Epoch: 200/400 - train_loss: 0.3932 - test_loss: 0.264362\n",
      "Epoch: 259/260 - train_loss: 0.3802 - test_loss: 0.293488\n",
      "Epoch: 195/260 - train_loss: 0.3837 - test_loss: 0.250472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:24:22,555]\u001b[0m Trial 17 finished with value: 19.662189484920656 and parameters: {'n layers': 6, 'Hidden size': 27, 'Learning rate': 0.00014110591229274074, 'Dropout rate': 0.12904704135369252, 'Epochs': 480}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/270 - train_loss: 1.9090 - test_loss: 1.345252\n",
      "Epoch: 259/260 - train_loss: 0.3881 - test_loss: 0.291250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:24:54,887]\u001b[0m Trial 9 finished with value: 19.571419156102547 and parameters: {'n layers': 5, 'Hidden size': 219, 'Learning rate': 0.00014128979250270924, 'Dropout rate': 0.08977940185499246, 'Epochs': 290}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/100 - train_loss: 1.5081 - test_loss: 1.282345\n",
      "Epoch: 195/260 - train_loss: 0.3783 - test_loss: 0.261219\n",
      "Epoch: 195/260 - train_loss: 0.3689 - test_loss: 0.276828\n",
      "Epoch:  0/100 - train_loss: 1.0576 - test_loss: 0.754550\n",
      "Epoch: 67/270 - train_loss: 0.4083 - test_loss: 0.227022\n",
      "Epoch: 25/100 - train_loss: 0.7036 - test_loss: 0.579212\n",
      "Epoch: 67/270 - train_loss: 0.3632 - test_loss: 0.252002\n",
      "Epoch: 95/380 - train_loss: 0.5474 - test_loss: 0.476395\n",
      "Epoch: 67/270 - train_loss: 0.5498 - test_loss: 0.457707\n",
      "Epoch: 259/260 - train_loss: 0.3616 - test_loss: 0.265954\n",
      "Epoch: 25/100 - train_loss: 0.3917 - test_loss: 0.228074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:26:17,024]\u001b[0m Trial 5 finished with value: 15.741431024017423 and parameters: {'n layers': 4, 'Hidden size': 28, 'Learning rate': 0.008100635321853029, 'Dropout rate': 0.27994547678414966, 'Epochs': 360}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/100 - train_loss: 0.5753 - test_loss: 0.442701\n",
      "Epoch: 300/400 - train_loss: 0.3576 - test_loss: 0.222814\n",
      "Epoch:  0/160 - train_loss: 1.0180 - test_loss: 0.821582\n",
      "Epoch: 259/260 - train_loss: 0.3605 - test_loss: 0.236844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:27:04,476]\u001b[0m Trial 8 finished with value: 17.762504279526535 and parameters: {'n layers': 5, 'Hidden size': 351, 'Learning rate': 0.0005377958384207233, 'Dropout rate': 0.11017998075744154, 'Epochs': 240}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/100 - train_loss: 0.3550 - test_loss: 0.206389\n",
      "Epoch: 75/100 - train_loss: 0.4464 - test_loss: 0.360980\n",
      "Epoch: 134/270 - train_loss: 0.3574 - test_loss: 0.235042\n",
      "Epoch:  0/160 - train_loss: 0.8051 - test_loss: 0.615784\n",
      "Epoch: 134/270 - train_loss: 0.3627 - test_loss: 0.242763\n",
      "Epoch: 99/100 - train_loss: 0.3895 - test_loss: 0.303416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:27:51,965]\u001b[0m Trial 25 finished with value: 23.63552282005965 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.00037021373965390425, 'Dropout rate': 0.38875038717028365, 'Epochs': 380}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 75/100 - train_loss: 0.3574 - test_loss: 0.258084\n",
      "Epoch: 134/270 - train_loss: 0.4222 - test_loss: 0.307595\n",
      "Epoch: 40/160 - train_loss: 0.3663 - test_loss: 0.252244\n",
      "Epoch: 190/380 - train_loss: 0.4098 - test_loss: 0.322687\n",
      "Epoch:  0/130 - train_loss: 1.0805 - test_loss: 0.776325\n",
      "Epoch: 99/100 - train_loss: 0.4086 - test_loss: 0.271022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:28:41,103]\u001b[0m Trial 26 finished with value: 15.174657525191975 and parameters: {'n layers': 5, 'Hidden size': 185, 'Learning rate': 0.003021739749601373, 'Dropout rate': 0.21898815566152302, 'Epochs': 100}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 259/260 - train_loss: 0.3689 - test_loss: 0.239763\n",
      "Epoch: 201/270 - train_loss: 0.3602 - test_loss: 0.223582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:29:06,354]\u001b[0m Trial 1 finished with value: 18.467757927092837 and parameters: {'n layers': 3, 'Hidden size': 50, 'Learning rate': 0.00024463842284501, 'Dropout rate': 0.19537943145505637, 'Epochs': 270}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 40/160 - train_loss: 0.3697 - test_loss: 0.245997\n",
      "Epoch:  0/100 - train_loss: 1.2570 - test_loss: 0.940979\n",
      "Epoch: 399/400 - train_loss: 0.3593 - test_loss: 0.232567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:29:31,499]\u001b[0m Trial 20 finished with value: 15.482279440826735 and parameters: {'n layers': 6, 'Hidden size': 27, 'Learning rate': 0.0029678191100536103, 'Dropout rate': 0.3084337432047614, 'Epochs': 400}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 32/130 - train_loss: 0.4206 - test_loss: 0.296524\n",
      "Epoch: 201/270 - train_loss: 0.3718 - test_loss: 0.235221\n",
      "Epoch: 80/160 - train_loss: 0.4424 - test_loss: 0.245763\n",
      "Epoch:  0/100 - train_loss: 1.0286 - test_loss: 0.768902\n",
      "Epoch: 201/270 - train_loss: 0.4126 - test_loss: 0.257543\n",
      "Epoch: 25/100 - train_loss: 0.3763 - test_loss: 0.261822\n",
      "Epoch:  0/100 - train_loss: 1.1650 - test_loss: 0.922504\n",
      "Epoch: 64/130 - train_loss: 0.3616 - test_loss: 0.255165\n",
      "Epoch: 25/100 - train_loss: 0.3831 - test_loss: 0.293467\n",
      "Epoch: 268/270 - train_loss: 0.3710 - test_loss: 0.246436\n",
      "Epoch: 269/270 - train_loss: 0.3660 - test_loss: 0.270872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:31:00,921]\u001b[0m Trial 22 finished with value: 14.852951551638322 and parameters: {'n layers': 5, 'Hidden size': 42, 'Learning rate': 0.0018971274447771816, 'Dropout rate': 0.4088843381457394, 'Epochs': 110}. Best is trial 12 with value: 14.678395405604965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 285/380 - train_loss: 0.3960 - test_loss: 0.246605\n",
      "Epoch: 50/100 - train_loss: 0.3619 - test_loss: 0.275776\n",
      "Epoch: 80/160 - train_loss: 0.3612 - test_loss: 0.242187\n",
      "Epoch: 120/160 - train_loss: 0.3567 - test_loss: 0.271150\n",
      "Epoch: 96/130 - train_loss: 0.3631 - test_loss: 0.221516\n",
      "Epoch: 50/100 - train_loss: 0.3858 - test_loss: 0.325726\n",
      "Epoch: 268/270 - train_loss: 0.3597 - test_loss: 0.245568\n",
      "Epoch: 269/270 - train_loss: 0.4445 - test_loss: 0.230069\n",
      "Epoch:  0/130 - train_loss: 1.1981 - test_loss: 0.735090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:31:40,322]\u001b[0m Trial 23 finished with value: 13.507644863507549 and parameters: {'n layers': 6, 'Hidden size': 57, 'Learning rate': 0.008581562783467776, 'Dropout rate': 0.6371541190781319, 'Epochs': 380}. Best is trial 23 with value: 13.507644863507549.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 25/100 - train_loss: 0.3622 - test_loss: 0.251720\n",
      "Epoch: 75/100 - train_loss: 0.3684 - test_loss: 0.244571\n",
      "Epoch: 268/270 - train_loss: 0.3649 - test_loss: 0.232103\n",
      "Epoch: 269/270 - train_loss: 0.4043 - test_loss: 0.235240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:32:09,887]\u001b[0m Trial 24 finished with value: 18.28463878506953 and parameters: {'n layers': 6, 'Hidden size': 179, 'Learning rate': 0.00026925479701573224, 'Dropout rate': 0.7539912110651854, 'Epochs': 270}. Best is trial 23 with value: 13.507644863507549.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 259/260 - train_loss: 0.3961 - test_loss: 0.274009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:32:17,626]\u001b[0m Trial 13 finished with value: 15.591395032770746 and parameters: {'n layers': 5, 'Hidden size': 36, 'Learning rate': 0.007646338071550327, 'Dropout rate': 0.7015123997068755, 'Epochs': 480}. Best is trial 23 with value: 13.507644863507549.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 75/100 - train_loss: 0.3893 - test_loss: 0.239432\n",
      "Epoch:  0/160 - train_loss: 1.1741 - test_loss: 0.641228\n",
      "Epoch: 128/130 - train_loss: 0.4293 - test_loss: 0.233345\n",
      "Epoch: 129/130 - train_loss: 0.3520 - test_loss: 0.186555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:32:48,294]\u001b[0m Trial 29 finished with value: 9.11556393199472 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.002476494374034275, 'Dropout rate': 0.6848467597399552, 'Epochs': 130}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/130 - train_loss: 0.3723 - test_loss: 0.263470\n",
      "lookback 3\n",
      "Epoch: 99/100 - train_loss: 0.3572 - test_loss: 0.231945\n",
      "Epoch: 159/160 - train_loss: 0.3631 - test_loss: 0.283277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:33:01,298]\u001b[0m Trial 30 finished with value: 15.200934568084847 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.0026001314542986142, 'Dropout rate': 0.6774839037758589, 'Epochs': 100}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:33:03,693]\u001b[0m Trial 27 finished with value: 13.947561826383335 and parameters: {'n layers': 4, 'Hidden size': 110, 'Learning rate': 0.0018672388398878904, 'Dropout rate': 0.6811103989922711, 'Epochs': 160}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/100 - train_loss: 0.3616 - test_loss: 0.240332\n",
      "Epoch: 120/160 - train_loss: 0.3754 - test_loss: 0.263683\n",
      "Epoch: 99/100 - train_loss: 0.3712 - test_loss: 0.241758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:33:37,097]\u001b[0m Trial 32 finished with value: 18.045141484830648 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.0021831593611711104, 'Dropout rate': 0.6531738808543134, 'Epochs': 100}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/420 - train_loss: 1.0241 - test_loss: 0.691528\n",
      "Epoch:  0/420 - train_loss: 1.2630 - test_loss: 0.712149\n",
      "Epoch: 40/160 - train_loss: 0.3536 - test_loss: 0.220281\n",
      "Epoch: 64/130 - train_loss: 0.3937 - test_loss: 0.228219\n",
      "Epoch:  0/420 - train_loss: 1.3208 - test_loss: 0.837693\n",
      "Epoch:  0/420 - train_loss: 1.2604 - test_loss: 1.337802\n",
      "Epoch: 75/100 - train_loss: 0.3793 - test_loss: 0.234725\n",
      "Epoch:  0/420 - train_loss: 1.1340 - test_loss: 0.738375\n",
      "Epoch:  0/420 - train_loss: 1.6010 - test_loss: 1.214841\n",
      "Epoch: 379/380 - train_loss: 0.3599 - test_loss: 0.215796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:35:07,954]\u001b[0m Trial 21 finished with value: 14.670018790460524 and parameters: {'n layers': 4, 'Hidden size': 84, 'Learning rate': 0.00016502793774791498, 'Dropout rate': 0.09542299575264315, 'Epochs': 500}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 159/160 - train_loss: 0.3566 - test_loss: 0.242190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:35:35,714]\u001b[0m Trial 28 finished with value: 16.957891092544994 and parameters: {'n layers': 6, 'Hidden size': 8, 'Learning rate': 0.006806147069623315, 'Dropout rate': 0.7436896385031077, 'Epochs': 160}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/150 - train_loss: 1.0791 - test_loss: 0.742364\n",
      "Epoch: 96/130 - train_loss: 0.3713 - test_loss: 0.249632\n",
      "Epoch: 80/160 - train_loss: 0.3571 - test_loss: 0.275079\n",
      "Epoch:  0/150 - train_loss: 1.3313 - test_loss: 1.027132\n",
      "Epoch: 99/100 - train_loss: 0.3947 - test_loss: 0.243546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:36:31,904]\u001b[0m Trial 31 finished with value: 17.878386034157657 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.0026825164696586425, 'Dropout rate': 0.6507959506213079, 'Epochs': 100}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 128/130 - train_loss: 0.3707 - test_loss: 0.236161\n",
      "Epoch: 129/130 - train_loss: 0.3691 - test_loss: 0.248651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:36:49,553]\u001b[0m Trial 33 finished with value: 16.387108612310787 and parameters: {'n layers': 4, 'Hidden size': 7, 'Learning rate': 0.0015859268320136848, 'Dropout rate': 0.6270317418218103, 'Epochs': 130}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 37/150 - train_loss: 0.4105 - test_loss: 0.284068\n",
      "Epoch:  0/160 - train_loss: 1.7852 - test_loss: 0.998037\n",
      "Epoch: 120/160 - train_loss: 0.3902 - test_loss: 0.236476\n",
      "Epoch:  0/160 - train_loss: 1.3218 - test_loss: 0.903557\n",
      "Epoch: 105/420 - train_loss: 0.3876 - test_loss: 0.236175\n",
      "Epoch: 74/150 - train_loss: 0.3986 - test_loss: 0.226517\n",
      "Epoch: 105/420 - train_loss: 0.3576 - test_loss: 0.234737\n",
      "Epoch: 105/420 - train_loss: 0.3639 - test_loss: 0.241493\n",
      "Epoch: 159/160 - train_loss: 0.3813 - test_loss: 0.230223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:38:17,916]\u001b[0m Trial 34 finished with value: 12.039396380834035 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.009600704889196088, 'Dropout rate': 0.6518184079364037, 'Epochs': 160}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 37/150 - train_loss: 0.3846 - test_loss: 0.278898\n",
      "Epoch: 40/160 - train_loss: 0.4316 - test_loss: 0.340466\n",
      "Epoch: 105/420 - train_loss: 0.3632 - test_loss: 0.250918\n",
      "Epoch: 111/150 - train_loss: 0.3536 - test_loss: 0.232189\n",
      "Epoch:  0/340 - train_loss: 0.9094 - test_loss: 0.686131\n",
      "Epoch: 105/420 - train_loss: 0.3672 - test_loss: 0.239660\n",
      "Epoch: 80/160 - train_loss: 0.3636 - test_loss: 0.248468\n",
      "Epoch: 148/150 - train_loss: 0.4063 - test_loss: 0.261319\n",
      "Epoch: 149/150 - train_loss: 0.3628 - test_loss: 0.270697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:39:37,813]\u001b[0m Trial 41 finished with value: 13.593440517464268 and parameters: {'n layers': 4, 'Hidden size': 14, 'Learning rate': 0.005059306549938097, 'Dropout rate': 0.5196267482069925, 'Epochs': 170}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 74/150 - train_loss: 0.3621 - test_loss: 0.247147\n",
      "Epoch:  0/340 - train_loss: 0.8732 - test_loss: 0.636408\n",
      "Epoch: 210/420 - train_loss: 0.3716 - test_loss: 0.235895\n",
      "Epoch: 120/160 - train_loss: 0.4120 - test_loss: 0.259309\n",
      "Epoch: 210/420 - train_loss: 0.3572 - test_loss: 0.256073\n",
      "Epoch: 40/160 - train_loss: 0.4114 - test_loss: 0.289117\n",
      "Epoch: 85/340 - train_loss: 0.3963 - test_loss: 0.234090\n",
      "Epoch: 210/420 - train_loss: 0.3643 - test_loss: 0.271266\n",
      "Epoch: 159/160 - train_loss: 0.3702 - test_loss: 0.232269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:41:12,099]\u001b[0m Trial 44 finished with value: 17.904068844407085 and parameters: {'n layers': 4, 'Hidden size': 86, 'Learning rate': 0.000715137480057154, 'Dropout rate': 0.5392035962707961, 'Epochs': 160}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 195/260 - train_loss: 0.3587 - test_loss: 0.239484\n",
      "Epoch: 210/420 - train_loss: 0.3616 - test_loss: 0.232933\n",
      "Epoch:  0/340 - train_loss: 0.9721 - test_loss: 0.712044\n",
      "Epoch: 85/340 - train_loss: 0.3588 - test_loss: 0.212060\n",
      "Epoch: 111/150 - train_loss: 0.3562 - test_loss: 0.246451\n",
      "Epoch: 315/420 - train_loss: 0.3586 - test_loss: 0.239846\n",
      "Epoch: 315/420 - train_loss: 0.3591 - test_loss: 0.227419\n",
      "Epoch: 170/340 - train_loss: 0.3559 - test_loss: 0.255499\n",
      "Epoch: 210/420 - train_loss: 0.3549 - test_loss: 0.242898\n",
      "Epoch: 85/340 - train_loss: 0.3791 - test_loss: 0.253847\n",
      "Epoch: 315/420 - train_loss: 0.4020 - test_loss: 0.252912\n",
      "Epoch: 170/340 - train_loss: 0.3584 - test_loss: 0.273723\n",
      "Epoch: 148/150 - train_loss: 0.4111 - test_loss: 0.255182\n",
      "Epoch: 255/340 - train_loss: 0.3591 - test_loss: 0.254438\n",
      "Epoch: 149/150 - train_loss: 0.3660 - test_loss: 0.287059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:44:21,407]\u001b[0m Trial 42 finished with value: 16.559570601750867 and parameters: {'n layers': 4, 'Hidden size': 104, 'Learning rate': 0.0009901644003569928, 'Dropout rate': 0.5548757628659006, 'Epochs': 150}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 315/420 - train_loss: 0.3736 - test_loss: 0.219892\n",
      "Epoch: 419/420 - train_loss: 0.3587 - test_loss: 0.229425\n",
      "Epoch: 80/160 - train_loss: 0.3618 - test_loss: 0.254475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:44:30,139]\u001b[0m Trial 40 finished with value: 15.36240884548421 and parameters: {'n layers': 4, 'Hidden size': 94, 'Learning rate': 0.0010461548797763966, 'Dropout rate': 0.5307030307519716, 'Epochs': 420}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 419/420 - train_loss: 0.3871 - test_loss: 0.225044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:45:06,585]\u001b[0m Trial 35 finished with value: 18.0533573592663 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.008790675201130766, 'Dropout rate': 0.6541869994558801, 'Epochs': 170}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/330 - train_loss: 1.0919 - test_loss: 0.625690\n",
      "Epoch: 170/340 - train_loss: 0.3759 - test_loss: 0.236985\n",
      "Epoch:  0/330 - train_loss: 1.0495 - test_loss: 0.915487\n",
      "Epoch: 255/340 - train_loss: 0.3574 - test_loss: 0.242218\n",
      "Epoch: 419/420 - train_loss: 0.3844 - test_loss: 0.235233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:45:59,960]\u001b[0m Trial 37 finished with value: 18.01253645564542 and parameters: {'n layers': 4, 'Hidden size': 81, 'Learning rate': 0.005088331814327899, 'Dropout rate': 0.5619976132067307, 'Epochs': 160}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/420 - train_loss: 0.3664 - test_loss: 0.248876\n",
      "Epoch: 315/420 - train_loss: 0.3637 - test_loss: 0.244854\n",
      "Epoch: 120/160 - train_loss: 0.3628 - test_loss: 0.241361\n",
      "Epoch: 339/340 - train_loss: 0.3634 - test_loss: 0.240086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:46:16,255]\u001b[0m Trial 45 finished with value: 16.50309727389276 and parameters: {'n layers': 4, 'Hidden size': 17, 'Learning rate': 0.004638536248921456, 'Dropout rate': 0.5441776722118693, 'Epochs': 340}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/330 - train_loss: 0.3564 - test_loss: 0.225470\n",
      "Epoch: 255/340 - train_loss: 0.3979 - test_loss: 0.274104\n",
      "Epoch: 419/420 - train_loss: 0.3732 - test_loss: 0.235033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:46:50,207]\u001b[0m Trial 38 finished with value: 14.554571910474033 and parameters: {'n layers': 4, 'Hidden size': 78, 'Learning rate': 0.004708471187625876, 'Dropout rate': 0.5447201527104817, 'Epochs': 170}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/340 - train_loss: 0.3952 - test_loss: 0.230593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:46:53,294]\u001b[0m Trial 46 finished with value: 12.886657518049839 and parameters: {'n layers': 4, 'Hidden size': 15, 'Learning rate': 0.005001480011191856, 'Dropout rate': 0.557735185297924, 'Epochs': 340}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195/260 - train_loss: 0.3879 - test_loss: 0.236593\n",
      "Epoch: 195/260 - train_loss: 0.4384 - test_loss: 0.349433\n",
      "Epoch: 159/160 - train_loss: 0.3633 - test_loss: 0.269532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:47:03,880]\u001b[0m Trial 43 finished with value: 16.47501408383934 and parameters: {'n layers': 4, 'Hidden size': 95, 'Learning rate': 0.0011816454101029798, 'Dropout rate': 0.5237972690302153, 'Epochs': 150}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/330 - train_loss: 0.3566 - test_loss: 0.224766\n",
      "Epoch: 259/260 - train_loss: 0.3581 - test_loss: 0.241469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:47:26,575]\u001b[0m Trial 11 finished with value: 16.47531348216803 and parameters: {'n layers': 6, 'Hidden size': 115, 'Learning rate': 0.0003961022117394002, 'Dropout rate': 0.2284741835042582, 'Epochs': 500}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 419/420 - train_loss: 0.3717 - test_loss: 0.247006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:47:53,499]\u001b[0m Trial 39 finished with value: 12.271184554692283 and parameters: {'n layers': 4, 'Hidden size': 11, 'Learning rate': 0.004498177417083888, 'Dropout rate': 0.5591477763367114, 'Epochs': 340}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 164/330 - train_loss: 0.3571 - test_loss: 0.289216\n",
      "Epoch: 339/340 - train_loss: 0.3739 - test_loss: 0.222351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:48:04,516]\u001b[0m Trial 47 finished with value: 16.183773867388588 and parameters: {'n layers': 5, 'Hidden size': 15, 'Learning rate': 0.009765677682082734, 'Dropout rate': 0.5700532723342738, 'Epochs': 340}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210/420 - train_loss: 0.3568 - test_loss: 0.270695\n",
      "Epoch: 259/260 - train_loss: 0.4031 - test_loss: 0.240026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:48:20,514]\u001b[0m Trial 18 finished with value: 17.77400006619102 and parameters: {'n layers': 4, 'Hidden size': 70, 'Learning rate': 0.0006266471335588981, 'Dropout rate': 0.020099957959812183, 'Epochs': 240}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 164/330 - train_loss: 0.3978 - test_loss: 0.230446\n",
      "Epoch: 259/260 - train_loss: 0.4160 - test_loss: 0.291183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:48:26,842]\u001b[0m Trial 6 finished with value: 19.16349846883939 and parameters: {'n layers': 4, 'Hidden size': 17, 'Learning rate': 0.000142389694909949, 'Dropout rate': 0.7235796765460006, 'Epochs': 210}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195/260 - train_loss: 0.3694 - test_loss: 0.270944\n",
      "Epoch: 195/260 - train_loss: 0.3914 - test_loss: 0.241144\n",
      "Epoch: 195/260 - train_loss: 0.4023 - test_loss: 0.250931\n",
      "Epoch: 246/330 - train_loss: 0.3800 - test_loss: 0.266486\n",
      "Epoch: 246/330 - train_loss: 0.4027 - test_loss: 0.279540\n",
      "Epoch: 259/260 - train_loss: 0.3605 - test_loss: 0.246167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:49:37,203]\u001b[0m Trial 15 finished with value: 18.221110291183976 and parameters: {'n layers': 6, 'Hidden size': 95, 'Learning rate': 0.000226643650611028, 'Dropout rate': 0.4879632224795252, 'Epochs': 260}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259/260 - train_loss: 0.3802 - test_loss: 0.264090\n",
      "Epoch: 195/260 - train_loss: 0.3679 - test_loss: 0.231178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:49:42,570]\u001b[0m Trial 2 finished with value: 15.563569465263598 and parameters: {'n layers': 6, 'Hidden size': 66, 'Learning rate': 0.0016371530866765471, 'Dropout rate': 0.6787994473322883, 'Epochs': 120}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 315/420 - train_loss: 0.3522 - test_loss: 0.250665\n",
      "Epoch: 195/260 - train_loss: 0.3662 - test_loss: 0.287331\n",
      "Epoch: 259/260 - train_loss: 0.3580 - test_loss: 0.248380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:49:55,105]\u001b[0m Trial 19 finished with value: 18.682343389779554 and parameters: {'n layers': 5, 'Hidden size': 7, 'Learning rate': 0.00040008149359451866, 'Dropout rate': 0.6892599451239689, 'Epochs': 260}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195/260 - train_loss: 0.3870 - test_loss: 0.284027\n",
      "Epoch: 328/330 - train_loss: 0.3601 - test_loss: 0.253093\n",
      "Epoch: 329/330 - train_loss: 0.3733 - test_loss: 0.266003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:50:11,207]\u001b[0m Trial 49 finished with value: 9.267214490044568 and parameters: {'n layers': 3, 'Hidden size': 15, 'Learning rate': 0.004512487898631914, 'Dropout rate': 0.46270781339246114, 'Epochs': 330}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259/260 - train_loss: 0.3629 - test_loss: 0.232990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:50:28,837]\u001b[0m Trial 14 finished with value: 17.497906446471983 and parameters: {'n layers': 6, 'Hidden size': 23, 'Learning rate': 0.0005289167286513307, 'Dropout rate': 0.6927052565540495, 'Epochs': 490}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 328/330 - train_loss: 0.3568 - test_loss: 0.223467\n",
      "Epoch: 329/330 - train_loss: 0.3768 - test_loss: 0.234774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:50:30,233]\u001b[0m Trial 48 finished with value: 14.495524588614595 and parameters: {'n layers': 3, 'Hidden size': 16, 'Learning rate': 0.004914137936585838, 'Dropout rate': 0.5889004924933968, 'Epochs': 340}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259/260 - train_loss: 0.3634 - test_loss: 0.241824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:50:34,345]\u001b[0m Trial 16 finished with value: 16.116250981030458 and parameters: {'n layers': 6, 'Hidden size': 35, 'Learning rate': 0.0023499187806004015, 'Dropout rate': 0.3815497724810562, 'Epochs': 110}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259/260 - train_loss: 0.3610 - test_loss: 0.248649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:50:39,139]\u001b[0m Trial 7 finished with value: 19.432254916714875 and parameters: {'n layers': 5, 'Hidden size': 148, 'Learning rate': 0.00020043731042582811, 'Dropout rate': 0.4548401426872707, 'Epochs': 330}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 419/420 - train_loss: 0.3625 - test_loss: 0.191595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:50:41,655]\u001b[0m Trial 36 finished with value: 9.208713726352185 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0011626808150182087, 'Dropout rate': 0.5942970242627715, 'Epochs': 160}. Best is trial 29 with value: 9.11556393199472.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 00:50:41,674]\u001b[0m A new study created in memory with name: no-name-8f483000-5098-4aa3-b221-a021e24952b5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Thanh Hóa\n",
      "  Value:  9.11556393199472\n",
      "optimize result of city: Thanh Hóa\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/200 - train_loss: 1.5166 - test_loss: 0.900355\n",
      "Epoch:  0/200 - train_loss: 1.0616 - test_loss: 0.736795\n",
      "Epoch:  0/200 - train_loss: 1.4372 - test_loss: 1.705683\n",
      "Epoch:  0/200 - train_loss: 1.3209 - test_loss: 0.849626\n",
      "Epoch:  0/200 - train_loss: 1.2430 - test_loss: 1.325126\n",
      "Epoch:  0/200 - train_loss: 1.2448 - test_loss: 0.752200\n",
      "Epoch:  0/200 - train_loss: 0.8763 - test_loss: 0.609595\n",
      "Epoch:  0/200 - train_loss: 0.9729 - test_loss: 0.651218\n",
      "Epoch:  0/200 - train_loss: 1.2267 - test_loss: 0.823496Epoch:  0/200 - train_loss: 1.4801 - test_loss: 1.523281\n",
      "\n",
      "Epoch:  0/200 - train_loss: 1.2750 - test_loss: 1.029642\n",
      "Epoch:  0/200 - train_loss: 1.1731 - test_loss: 0.815727\n",
      "Epoch:  0/200 - train_loss: 1.3076 - test_loss: 1.080437\n",
      "Epoch:  0/200 - train_loss: 1.0605 - test_loss: 0.682781\n",
      "Epoch:  0/200 - train_loss: 1.2806 - test_loss: 0.976420\n",
      "Epoch:  0/200 - train_loss: 1.1564 - test_loss: 0.778212\n",
      "Epoch:  0/200 - train_loss: 1.3610 - test_loss: 1.329248\n",
      "Epoch:  0/200 - train_loss: 1.1418 - test_loss: 0.816144\n",
      "Epoch:  0/200 - train_loss: 1.0766 - test_loss: 1.001632\n",
      "Epoch:  0/200 - train_loss: 1.1508 - test_loss: 1.417136\n",
      "Epoch: 50/200 - train_loss: 0.2996 - test_loss: 0.220137\n",
      "Epoch: 50/200 - train_loss: 0.2321 - test_loss: 0.115548\n",
      "Epoch: 50/200 - train_loss: 0.2340 - test_loss: 0.114148\n",
      "Epoch: 100/200 - train_loss: 0.2230 - test_loss: 0.113122\n",
      "Epoch: 100/200 - train_loss: 0.2601 - test_loss: 0.097432\n",
      "Epoch: 100/200 - train_loss: 0.2183 - test_loss: 0.101194\n",
      "Epoch: 50/200 - train_loss: 0.5359 - test_loss: 0.490218\n",
      "Epoch: 150/200 - train_loss: 0.2214 - test_loss: 0.105709\n",
      "Epoch: 150/200 - train_loss: 0.2227 - test_loss: 0.108602\n",
      "Epoch: 150/200 - train_loss: 0.2571 - test_loss: 0.100749\n",
      "Epoch: 100/200 - train_loss: 0.3940 - test_loss: 0.336338\n",
      "Epoch: 199/200 - train_loss: 0.2728 - test_loss: 0.103687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:58:56,549]\u001b[0m Trial 6 finished with value: 21.29898139681304 and parameters: {'n layers': 4, 'Hidden size': 246, 'Learning rate': 0.0007405793149638788, 'Dropout rate': 0.07598259299817976, 'Epochs': 360}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 199/200 - train_loss: 0.2221 - test_loss: 0.108338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:59:14,572]\u001b[0m Trial 10 finished with value: 22.87729707011792 and parameters: {'n layers': 5, 'Hidden size': 9, 'Learning rate': 0.008847445707844731, 'Dropout rate': 0.7969466668665384, 'Epochs': 190}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/200 - train_loss: 0.5576 - test_loss: 0.550401\n",
      "Epoch: 50/200 - train_loss: 0.2713 - test_loss: 0.108896\n",
      "Epoch: 50/200 - train_loss: 0.4832 - test_loss: 0.409820\n",
      "Epoch: 199/200 - train_loss: 0.2182 - test_loss: 0.101647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:59:40,262]\u001b[0m Trial 8 finished with value: 23.471939848285526 and parameters: {'n layers': 6, 'Hidden size': 327, 'Learning rate': 0.0013482793240349065, 'Dropout rate': 0.33470168843577597, 'Epochs': 230}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/330 - train_loss: 1.0180 - test_loss: 0.732586\n",
      "Epoch: 150/200 - train_loss: 0.2921 - test_loss: 0.227032\n",
      "Epoch:  0/330 - train_loss: 1.2443 - test_loss: 0.812622\n",
      "Epoch:  0/330 - train_loss: 1.1850 - test_loss: 0.846172\n",
      "Epoch: 50/200 - train_loss: 0.2509 - test_loss: 0.115102\n",
      "Epoch: 50/200 - train_loss: 0.2226 - test_loss: 0.107159\n",
      "Epoch: 50/200 - train_loss: 0.2237 - test_loss: 0.106939\n",
      "Epoch: 50/200 - train_loss: 0.2275 - test_loss: 0.106481\n",
      "Epoch: 50/200 - train_loss: 0.2740 - test_loss: 0.192889\n",
      "Epoch: 50/200 - train_loss: 0.2336 - test_loss: 0.133827\n",
      "Epoch: 50/200 - train_loss: 0.5524 - test_loss: 0.473202\n",
      "Epoch: 100/200 - train_loss: 0.3704 - test_loss: 0.346594\n",
      "Epoch: 100/200 - train_loss: 0.2223 - test_loss: 0.112757\n",
      "Epoch: 199/200 - train_loss: 0.2460 - test_loss: 0.157975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:01:05,052]\u001b[0m Trial 15 finished with value: 23.171056052667286 and parameters: {'n layers': 4, 'Hidden size': 8, 'Learning rate': 0.00024395333522044885, 'Dropout rate': 0.44465291336260027, 'Epochs': 280}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 100/200 - train_loss: 0.3101 - test_loss: 0.205656\n",
      "Epoch: 82/330 - train_loss: 0.2540 - test_loss: 0.103806\n",
      "Epoch: 50/200 - train_loss: 0.2363 - test_loss: 0.139230\n",
      "Epoch: 50/200 - train_loss: 0.2179 - test_loss: 0.101945\n",
      "Epoch:  0/350 - train_loss: 1.5944 - test_loss: 1.326765\n",
      "Epoch: 150/200 - train_loss: 0.2829 - test_loss: 0.230823\n",
      "Epoch: 82/330 - train_loss: 0.2662 - test_loss: 0.142951\n",
      "Epoch: 82/330 - train_loss: 0.2270 - test_loss: 0.103252\n",
      "Epoch: 150/200 - train_loss: 0.2185 - test_loss: 0.102857\n",
      "Epoch: 150/200 - train_loss: 0.2462 - test_loss: 0.134064\n",
      "Epoch: 199/200 - train_loss: 0.2421 - test_loss: 0.164447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:32,633]\u001b[0m Trial 19 finished with value: 80.03723857243835 and parameters: {'n layers': 6, 'Hidden size': 27, 'Learning rate': 0.0002661466317701684, 'Dropout rate': 0.1801949197093486, 'Epochs': 200}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 164/330 - train_loss: 0.2507 - test_loss: 0.102473\n",
      "Epoch: 199/200 - train_loss: 0.2193 - test_loss: 0.098204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:58,554]\u001b[0m Trial 12 finished with value: 22.850104476878688 and parameters: {'n layers': 6, 'Hidden size': 157, 'Learning rate': 0.005588571771224007, 'Dropout rate': 0.15895911153415856, 'Epochs': 460}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 164/330 - train_loss: 0.2172 - test_loss: 0.102435\n",
      "Epoch: 87/350 - train_loss: 0.4265 - test_loss: 0.345485\n",
      "Epoch:  0/460 - train_loss: 1.3633 - test_loss: 1.202982\n",
      "Epoch: 164/330 - train_loss: 0.2644 - test_loss: 0.103203\n",
      "Epoch: 199/200 - train_loss: 0.2469 - test_loss: 0.110091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:03:36,167]\u001b[0m Trial 7 finished with value: 26.62523708507676 and parameters: {'n layers': 5, 'Hidden size': 13, 'Learning rate': 0.00033630656231007597, 'Dropout rate': 0.7511610405280778, 'Epochs': 480}. Best is trial 6 with value: 21.29898139681304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/200 - train_loss: 0.3365 - test_loss: 0.268211\n",
      "Epoch:  0/170 - train_loss: 1.3615 - test_loss: 1.702745\n",
      "Epoch:  0/170 - train_loss: 1.0900 - test_loss: 0.800551\n",
      "Epoch: 100/200 - train_loss: 0.2203 - test_loss: 0.111609\n",
      "Epoch: 246/330 - train_loss: 0.2210 - test_loss: 0.104937\n",
      "Epoch: 42/170 - train_loss: 0.8408 - test_loss: 0.995498\n",
      "Epoch: 246/330 - train_loss: 0.2309 - test_loss: 0.104779\n",
      "Epoch: 174/350 - train_loss: 0.2548 - test_loss: 0.168310\n",
      "Epoch: 246/330 - train_loss: 0.2200 - test_loss: 0.106970\n",
      "Epoch: 42/170 - train_loss: 0.2308 - test_loss: 0.100136\n",
      "Epoch: 84/170 - train_loss: 0.6696 - test_loss: 0.606854\n",
      "Epoch: 115/460 - train_loss: 0.4529 - test_loss: 0.393410\n",
      "Epoch: 328/330 - train_loss: 0.2165 - test_loss: 0.099130\n",
      "Epoch: 329/330 - train_loss: 0.2180 - test_loss: 0.099577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:05:41,107]\u001b[0m Trial 20 finished with value: 21.13722950728968 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.0018646513187643673, 'Dropout rate': 0.6936849682047866, 'Epochs': 340}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/200 - train_loss: 0.2190 - test_loss: 0.112270\n",
      "Epoch: 328/330 - train_loss: 0.2185 - test_loss: 0.101162\n",
      "Epoch: 329/330 - train_loss: 0.2617 - test_loss: 0.102997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:06:05,590]\u001b[0m Trial 21 finished with value: 21.53312494421489 and parameters: {'n layers': 6, 'Hidden size': 14, 'Learning rate': 0.000618009967183983, 'Dropout rate': 0.5735764638001298, 'Epochs': 220}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 100/200 - train_loss: 0.2184 - test_loss: 0.099497\n",
      "Epoch: 100/200 - train_loss: 0.2217 - test_loss: 0.107896\n",
      "Epoch: 100/200 - train_loss: 0.2226 - test_loss: 0.109678\n",
      "Epoch: 100/200 - train_loss: 0.2203 - test_loss: 0.099949\n",
      "Epoch: 100/200 - train_loss: 0.2176 - test_loss: 0.103033\n",
      "Epoch: 100/200 - train_loss: 0.4054 - test_loss: 0.307606\n",
      "Epoch: 84/170 - train_loss: 0.2670 - test_loss: 0.108448\n",
      "Epoch: 126/170 - train_loss: 0.5556 - test_loss: 0.485782\n",
      "Epoch: 328/330 - train_loss: 0.2191 - test_loss: 0.099039\n",
      "Epoch: 329/330 - train_loss: 0.2622 - test_loss: 0.101786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:06:36,455]\u001b[0m Trial 22 finished with value: 21.374633789803852 and parameters: {'n layers': 5, 'Hidden size': 13, 'Learning rate': 0.002630592373062346, 'Dropout rate': 0.69616217409458, 'Epochs': 330}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/110 - train_loss: 1.2110 - test_loss: 0.923985\n",
      "Epoch: 261/350 - train_loss: 0.2228 - test_loss: 0.112239\n",
      "Epoch:  0/110 - train_loss: 1.6263 - test_loss: 1.669923\n",
      "Epoch: 100/200 - train_loss: 0.2555 - test_loss: 0.099194\n",
      "Epoch: 27/110 - train_loss: 0.2779 - test_loss: 0.194636\n",
      "Epoch: 199/200 - train_loss: 0.2573 - test_loss: 0.105093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:07:38,117]\u001b[0m Trial 13 finished with value: 21.938675410269216 and parameters: {'n layers': 3, 'Hidden size': 22, 'Learning rate': 0.003696330747219906, 'Dropout rate': 0.7454093691461056, 'Epochs': 250}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 126/170 - train_loss: 0.2178 - test_loss: 0.113267\n",
      "Epoch:  0/380 - train_loss: 1.5397 - test_loss: 2.531748\n",
      "Epoch: 168/170 - train_loss: 0.4748 - test_loss: 0.392290\n",
      "Epoch: 169/170 - train_loss: 0.4845 - test_loss: 0.390595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:07:57,969]\u001b[0m Trial 25 finished with value: 32.30603441828553 and parameters: {'n layers': 5, 'Hidden size': 15, 'Learning rate': 0.00011167272098360311, 'Dropout rate': 0.03955558383664135, 'Epochs': 460}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 27/110 - train_loss: 0.3727 - test_loss: 0.300220\n",
      "Epoch: 54/110 - train_loss: 0.2251 - test_loss: 0.107124\n",
      "Epoch: 50/200 - train_loss: 0.2208 - test_loss: 0.114437\n",
      "Epoch:  0/360 - train_loss: 1.5659 - test_loss: 1.414958\n",
      "Epoch: 54/110 - train_loss: 0.2422 - test_loss: 0.135795\n",
      "Epoch: 230/460 - train_loss: 0.2909 - test_loss: 0.221300\n",
      "Epoch:  0/360 - train_loss: 1.0017 - test_loss: 0.794803\n",
      "Epoch: 168/170 - train_loss: 0.2200 - test_loss: 0.105827\n",
      "Epoch: 81/110 - train_loss: 0.2211 - test_loss: 0.102180\n",
      "Epoch: 169/170 - train_loss: 0.2572 - test_loss: 0.102753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:09:03,421]\u001b[0m Trial 26 finished with value: 25.40097807035127 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.00212788771310132, 'Dropout rate': 0.4746243135393995, 'Epochs': 170}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 348/350 - train_loss: 0.2194 - test_loss: 0.104679\n",
      "Epoch: 349/350 - train_loss: 0.2166 - test_loss: 0.104848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:09:21,209]\u001b[0m Trial 23 finished with value: 27.033967545262424 and parameters: {'n layers': 4, 'Hidden size': 314, 'Learning rate': 0.00026454168494201015, 'Dropout rate': 0.16399487056769022, 'Epochs': 350}. Best is trial 20 with value: 21.13722950728968.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/200 - train_loss: 0.2189 - test_loss: 0.107601\n",
      "Epoch: 81/110 - train_loss: 0.2206 - test_loss: 0.106563\n",
      "Epoch: 100/200 - train_loss: 0.2197 - test_loss: 0.108432\n",
      "Epoch: 108/110 - train_loss: 0.2490 - test_loss: 0.105478\n",
      "Epoch: 109/110 - train_loss: 0.2234 - test_loss: 0.100067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:09:53,609]\u001b[0m Trial 27 finished with value: 20.41393071084554 and parameters: {'n layers': 4, 'Hidden size': 101, 'Learning rate': 0.0014179409717430048, 'Dropout rate': 0.4019301782422886, 'Epochs': 440}. Best is trial 27 with value: 20.41393071084554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/100 - train_loss: 1.2103 - test_loss: 1.008127\n",
      "Epoch: 150/200 - train_loss: 0.2255 - test_loss: 0.098928\n",
      "Epoch:  0/100 - train_loss: 1.4078 - test_loss: 1.411340\n",
      "Epoch: 108/110 - train_loss: 0.2208 - test_loss: 0.104502\n",
      "Epoch: 109/110 - train_loss: 0.2205 - test_loss: 0.103934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:10:36,093]\u001b[0m Trial 28 finished with value: 19.831917290858694 and parameters: {'n layers': 5, 'Hidden size': 70, 'Learning rate': 0.0009717444401976196, 'Dropout rate': 0.47673958222933044, 'Epochs': 450}. Best is trial 28 with value: 19.831917290858694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 95/380 - train_loss: 0.6280 - test_loss: 0.533606\n",
      "Epoch:  0/410 - train_loss: 1.5207 - test_loss: 1.084862\n",
      "Epoch: 25/100 - train_loss: 0.3989 - test_loss: 0.342249\n",
      "Epoch: 25/100 - train_loss: 0.4325 - test_loss: 0.359067\n",
      "Epoch:  0/410 - train_loss: 1.4855 - test_loss: 1.479751\n",
      "Epoch: 199/200 - train_loss: 0.2607 - test_loss: 0.100001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:11:38,713]\u001b[0m Trial 9 finished with value: 19.946465478118014 and parameters: {'n layers': 5, 'Hidden size': 305, 'Learning rate': 0.0013831578606659848, 'Dropout rate': 0.06849346807971525, 'Epochs': 500}. Best is trial 28 with value: 19.831917290858694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/100 - train_loss: 0.2706 - test_loss: 0.178712\n",
      "Epoch: 90/360 - train_loss: 0.2207 - test_loss: 0.106185\n",
      "Epoch: 50/100 - train_loss: 0.2706 - test_loss: 0.183824\n",
      "Epoch: 90/360 - train_loss: 0.2211 - test_loss: 0.109537\n",
      "Epoch:  0/110 - train_loss: 1.6140 - test_loss: 1.009275\n",
      "Epoch: 345/460 - train_loss: 0.2297 - test_loss: 0.134237\n",
      "Epoch: 75/100 - train_loss: 0.2636 - test_loss: 0.123422\n",
      "Epoch: 75/100 - train_loss: 0.2303 - test_loss: 0.121142\n",
      "Epoch: 190/380 - train_loss: 0.4519 - test_loss: 0.386809\n",
      "Epoch: 99/100 - train_loss: 0.2195 - test_loss: 0.110161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:13:03,980]\u001b[0m Trial 33 finished with value: 21.234176240331102 and parameters: {'n layers': 3, 'Hidden size': 79, 'Learning rate': 0.0007505712387045857, 'Dropout rate': 0.32986946615993246, 'Epochs': 370}. Best is trial 28 with value: 19.831917290858694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 99/100 - train_loss: 0.2212 - test_loss: 0.107872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:13:13,232]\u001b[0m Trial 32 finished with value: 21.74061255780997 and parameters: {'n layers': 3, 'Hidden size': 83, 'Learning rate': 0.0008536386568131923, 'Dropout rate': 0.2763665430081419, 'Epochs': 350}. Best is trial 28 with value: 19.831917290858694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 199/200 - train_loss: 0.2263 - test_loss: 0.100413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:13:17,042]\u001b[0m Trial 4 finished with value: 19.76578689774623 and parameters: {'n layers': 6, 'Hidden size': 40, 'Learning rate': 0.0008023213242983029, 'Dropout rate': 0.2581097728342736, 'Epochs': 330}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 102/410 - train_loss: 0.2652 - test_loss: 0.107978\n",
      "Epoch: 150/200 - train_loss: 0.2230 - test_loss: 0.104471\n",
      "Epoch: 150/200 - train_loss: 0.2614 - test_loss: 0.098084\n",
      "Epoch: 150/200 - train_loss: 0.2602 - test_loss: 0.103751\n",
      "Epoch: 150/200 - train_loss: 0.2854 - test_loss: 0.201234\n",
      "Epoch: 27/110 - train_loss: 0.4362 - test_loss: 0.377851\n",
      "Epoch: 102/410 - train_loss: 0.2220 - test_loss: 0.104186\n",
      "Epoch:  0/400 - train_loss: 1.0062 - test_loss: 0.740923\n",
      "Epoch:  0/400 - train_loss: 1.5881 - test_loss: 1.049342\n",
      "Epoch:  0/400 - train_loss: 1.5505 - test_loss: 1.011178\n",
      "Epoch: 180/360 - train_loss: 0.2193 - test_loss: 0.102306\n",
      "Epoch: 54/110 - train_loss: 0.3131 - test_loss: 0.196126\n",
      "Epoch: 180/360 - train_loss: 0.2675 - test_loss: 0.107681\n",
      "Epoch: 285/380 - train_loss: 0.3539 - test_loss: 0.279371\n",
      "Epoch: 459/460 - train_loss: 0.2224 - test_loss: 0.107340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:15:36,714]\u001b[0m Trial 24 finished with value: 23.412944807116414 and parameters: {'n layers': 4, 'Hidden size': 15, 'Learning rate': 0.0001436344569705672, 'Dropout rate': 0.21345204332556644, 'Epochs': 130}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 204/410 - train_loss: 0.2198 - test_loss: 0.103339\n",
      "Epoch:  0/410 - train_loss: 1.6366 - test_loss: 1.402696\n",
      "Epoch: 81/110 - train_loss: 0.2666 - test_loss: 0.123732\n",
      "Epoch: 204/410 - train_loss: 0.2173 - test_loss: 0.103078\n",
      "Epoch: 100/400 - train_loss: 0.2780 - test_loss: 0.169059\n",
      "Epoch: 270/360 - train_loss: 0.2207 - test_loss: 0.110600\n",
      "Epoch: 100/400 - train_loss: 0.2225 - test_loss: 0.100713\n",
      "Epoch: 379/380 - train_loss: 0.2843 - test_loss: 0.199963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:17:34,370]\u001b[0m Trial 29 finished with value: 20.44669656774394 and parameters: {'n layers': 3, 'Hidden size': 79, 'Learning rate': 0.00010133810278374244, 'Dropout rate': 0.5717434016356269, 'Epochs': 110}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 108/110 - train_loss: 0.2245 - test_loss: 0.109637\n",
      "Epoch: 109/110 - train_loss: 0.2609 - test_loss: 0.105645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:18:02,890]\u001b[0m Trial 36 finished with value: 22.570741528497 and parameters: {'n layers': 5, 'Hidden size': 69, 'Learning rate': 0.0007114794100523444, 'Dropout rate': 0.5825181837727884, 'Epochs': 110}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/420 - train_loss: 1.1982 - test_loss: 1.522915\n",
      "Epoch: 306/410 - train_loss: 0.2209 - test_loss: 0.102394\n",
      "Epoch: 270/360 - train_loss: 0.2192 - test_loss: 0.104797\n",
      "Epoch: 102/410 - train_loss: 0.2585 - test_loss: 0.106817\n",
      "Epoch:  0/420 - train_loss: 1.0615 - test_loss: 0.802255\n",
      "Epoch: 306/410 - train_loss: 0.2164 - test_loss: 0.100261\n",
      "Epoch: 200/400 - train_loss: 0.2596 - test_loss: 0.102811\n",
      "Epoch: 359/360 - train_loss: 0.2295 - test_loss: 0.104765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:19:12,848]\u001b[0m Trial 31 finished with value: 20.08308691841661 and parameters: {'n layers': 3, 'Hidden size': 70, 'Learning rate': 0.001386499842309262, 'Dropout rate': 0.4595155063842478, 'Epochs': 360}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/410 - train_loss: 1.2373 - test_loss: 1.217431\n",
      "Epoch: 200/400 - train_loss: 0.2211 - test_loss: 0.104648\n",
      "Epoch: 408/410 - train_loss: 0.2575 - test_loss: 0.099882\n",
      "Epoch: 409/410 - train_loss: 0.2183 - test_loss: 0.108785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:20:25,712]\u001b[0m Trial 34 finished with value: 23.238771475243297 and parameters: {'n layers': 3, 'Hidden size': 72, 'Learning rate': 0.0012119952741244423, 'Dropout rate': 0.33278415916637, 'Epochs': 100}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 105/420 - train_loss: 0.2291 - test_loss: 0.127968\n",
      "Epoch: 204/410 - train_loss: 0.2213 - test_loss: 0.107351\n",
      "Epoch: 408/410 - train_loss: 0.2201 - test_loss: 0.098231\n",
      "Epoch: 409/410 - train_loss: 0.2199 - test_loss: 0.101078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:21:07,981]\u001b[0m Trial 35 finished with value: 22.380220822769818 and parameters: {'n layers': 4, 'Hidden size': 84, 'Learning rate': 0.0010257128236024163, 'Dropout rate': 0.30826943638197296, 'Epochs': 410}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/500 - train_loss: 1.4670 - test_loss: 1.869421\n",
      "Epoch: 300/400 - train_loss: 0.2600 - test_loss: 0.103602\n",
      "Epoch: 100/400 - train_loss: 0.2467 - test_loss: 0.149933\n",
      "Epoch: 359/360 - train_loss: 0.2593 - test_loss: 0.102504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:21:21,966]\u001b[0m Trial 30 finished with value: 20.68464254593719 and parameters: {'n layers': 3, 'Hidden size': 75, 'Learning rate': 0.0010978893472861743, 'Dropout rate': 0.03208540093421014, 'Epochs': 380}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/490 - train_loss: 1.5313 - test_loss: 2.103262\n",
      "Epoch: 199/200 - train_loss: 0.2195 - test_loss: 0.118565\n",
      "Epoch: 199/200 - train_loss: 0.2224 - test_loss: 0.101518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:22:06,711]\u001b[0m Trial 11 finished with value: 20.097283605548327 and parameters: {'n layers': 5, 'Hidden size': 306, 'Learning rate': 0.0010866372207248814, 'Dropout rate': 0.0765063725974142, 'Epochs': 250}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 01:22:06,842]\u001b[0m Trial 0 finished with value: 21.386873935571156 and parameters: {'n layers': 3, 'Hidden size': 40, 'Learning rate': 0.0031980230687207517, 'Dropout rate': 0.6105867923089295, 'Epochs': 300}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/420 - train_loss: 1.2573 - test_loss: 0.991264\n",
      "Epoch: 102/410 - train_loss: 0.2675 - test_loss: 0.156043\n",
      "Epoch: 300/400 - train_loss: 0.2188 - test_loss: 0.103774\n",
      "Epoch: 105/420 - train_loss: 0.2186 - test_loss: 0.099808\n",
      "Epoch:  0/420 - train_loss: 1.4641 - test_loss: 1.169102\n",
      "Epoch:  0/420 - train_loss: 1.1691 - test_loss: 1.039194\n",
      "Epoch: 210/420 - train_loss: 0.2585 - test_loss: 0.105654\n",
      "Epoch: 399/400 - train_loss: 0.2176 - test_loss: 0.104282\n",
      "Epoch: 306/410 - train_loss: 0.2173 - test_loss: 0.104166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:24:05,439]\u001b[0m Trial 37 finished with value: 21.39426124414925 and parameters: {'n layers': 5, 'Hidden size': 54, 'Learning rate': 0.00047116796062162487, 'Dropout rate': 0.5845029505949068, 'Epochs': 110}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 125/500 - train_loss: 0.2270 - test_loss: 0.138252\n",
      "Epoch:  0/500 - train_loss: 1.3777 - test_loss: 0.845758\n",
      "Epoch: 122/490 - train_loss: 0.2268 - test_loss: 0.118920\n",
      "Epoch: 204/410 - train_loss: 0.2224 - test_loss: 0.103369\n",
      "Epoch: 315/420 - train_loss: 0.2924 - test_loss: 0.104204\n",
      "Epoch: 399/400 - train_loss: 0.2189 - test_loss: 0.102214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:26:02,837]\u001b[0m Trial 38 finished with value: 21.52272854084386 and parameters: {'n layers': 5, 'Hidden size': 44, 'Learning rate': 0.0034095340927709616, 'Dropout rate': 0.5700347739071929, 'Epochs': 110}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/420 - train_loss: 0.2851 - test_loss: 0.204574\n",
      "Epoch: 408/410 - train_loss: 0.2554 - test_loss: 0.106175\n",
      "Epoch: 409/410 - train_loss: 0.2370 - test_loss: 0.119890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:26:20,836]\u001b[0m Trial 40 finished with value: 21.035798506696825 and parameters: {'n layers': 5, 'Hidden size': 47, 'Learning rate': 0.0011605348950234266, 'Dropout rate': 0.548894552821151, 'Epochs': 410}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/500 - train_loss: 0.2211 - test_loss: 0.102491\n",
      "Epoch: 125/500 - train_loss: 0.2233 - test_loss: 0.115665\n",
      "Epoch: 244/490 - train_loss: 0.2193 - test_loss: 0.100392\n",
      "Epoch: 200/400 - train_loss: 0.2241 - test_loss: 0.103029\n",
      "Epoch: 210/420 - train_loss: 0.2183 - test_loss: 0.100677\n",
      "Epoch: 419/420 - train_loss: 0.2589 - test_loss: 0.099028\n",
      "Epoch: 306/410 - train_loss: 0.2592 - test_loss: 0.104665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:27:31,894]\u001b[0m Trial 41 finished with value: 20.947401292099343 and parameters: {'n layers': 5, 'Hidden size': 46, 'Learning rate': 0.0005546639501241185, 'Dropout rate': 0.09293096561646658, 'Epochs': 420}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210/420 - train_loss: 0.2169 - test_loss: 0.109407\n",
      "Epoch: 199/200 - train_loss: 0.2403 - test_loss: 0.140550\n",
      "Epoch: 375/500 - train_loss: 0.2161 - test_loss: 0.101134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:28:44,891]\u001b[0m Trial 14 finished with value: 20.129543409612957 and parameters: {'n layers': 6, 'Hidden size': 162, 'Learning rate': 0.0002517195724247383, 'Dropout rate': 0.536113304333465, 'Epochs': 200}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/500 - train_loss: 0.2193 - test_loss: 0.100217\n",
      "Epoch: 408/410 - train_loss: 0.2185 - test_loss: 0.102808\n",
      "Epoch: 409/410 - train_loss: 0.2194 - test_loss: 0.103735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:29:10,082]\u001b[0m Trial 43 finished with value: 20.163881792263187 and parameters: {'n layers': 5, 'Hidden size': 46, 'Learning rate': 0.00046027542922477433, 'Dropout rate': 0.08849842845048439, 'Epochs': 410}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 366/490 - train_loss: 0.2196 - test_loss: 0.102665\n",
      "Epoch: 150/200 - train_loss: 0.2187 - test_loss: 0.103214\n",
      "Epoch: 315/420 - train_loss: 0.2182 - test_loss: 0.102871\n",
      "Epoch: 105/420 - train_loss: 0.2454 - test_loss: 0.156192\n",
      "Epoch: 300/400 - train_loss: 0.2607 - test_loss: 0.103083\n",
      "Epoch: 199/200 - train_loss: 0.2189 - test_loss: 0.097825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:29:32,196]\u001b[0m Trial 16 finished with value: 21.004420882831337 and parameters: {'n layers': 3, 'Hidden size': 114, 'Learning rate': 0.0059901915869879484, 'Dropout rate': 0.5210440837780872, 'Epochs': 380}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 315/420 - train_loss: 0.2178 - test_loss: 0.103085\n",
      "Epoch: 105/420 - train_loss: 0.2539 - test_loss: 0.143838\n",
      "Epoch: 499/500 - train_loss: 0.2244 - test_loss: 0.103790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:30:32,993]\u001b[0m Trial 44 finished with value: 22.364273193196112 and parameters: {'n layers': 5, 'Hidden size': 42, 'Learning rate': 0.00043361963103413326, 'Dropout rate': 0.0899663831271707, 'Epochs': 410}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 375/500 - train_loss: 0.2212 - test_loss: 0.101757\n",
      "Epoch: 419/420 - train_loss: 0.2202 - test_loss: 0.100142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:30:55,986]\u001b[0m Trial 42 finished with value: 20.669419420776343 and parameters: {'n layers': 5, 'Hidden size': 44, 'Learning rate': 0.0012882712345914486, 'Dropout rate': 0.0925412186512958, 'Epochs': 420}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 488/490 - train_loss: 0.2186 - test_loss: 0.103989\n",
      "Epoch: 489/490 - train_loss: 0.2939 - test_loss: 0.103385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:30:58,289]\u001b[0m Trial 45 finished with value: 21.64525877942906 and parameters: {'n layers': 5, 'Hidden size': 37, 'Learning rate': 0.000507015902458312, 'Dropout rate': 0.24380587478520774, 'Epochs': 500}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200 - train_loss: 0.2184 - test_loss: 0.103998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:31:03,445]\u001b[0m Trial 5 finished with value: 22.13416365096153 and parameters: {'n layers': 4, 'Hidden size': 16, 'Learning rate': 0.0010725905747720557, 'Dropout rate': 0.19506791611927296, 'Epochs': 370}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 399/400 - train_loss: 0.2175 - test_loss: 0.104947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:31:04,483]\u001b[0m Trial 39 finished with value: 21.99362708178151 and parameters: {'n layers': 6, 'Hidden size': 41, 'Learning rate': 0.000505204020593863, 'Dropout rate': 0.5524974098576354, 'Epochs': 400}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200 - train_loss: 0.2578 - test_loss: 0.101593\n",
      "Epoch: 210/420 - train_loss: 0.2239 - test_loss: 0.104180\n",
      "Epoch: 100/200 - train_loss: 0.2325 - test_loss: 0.123966\n",
      "Epoch: 419/420 - train_loss: 0.2182 - test_loss: 0.103618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:31:22,500]\u001b[0m Trial 46 finished with value: 21.781448473879852 and parameters: {'n layers': 5, 'Hidden size': 39, 'Learning rate': 0.00036527414278911296, 'Dropout rate': 0.09478431860252982, 'Epochs': 490}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/200 - train_loss: 0.3771 - test_loss: 0.288199\n",
      "Epoch: 100/200 - train_loss: 0.2197 - test_loss: 0.104554\n",
      "Epoch: 199/200 - train_loss: 0.2349 - test_loss: 0.109554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:31:48,432]\u001b[0m Trial 17 finished with value: 20.57028673425824 and parameters: {'n layers': 6, 'Hidden size': 33, 'Learning rate': 0.004663354606117298, 'Dropout rate': 0.728094256198405, 'Epochs': 410}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/200 - train_loss: 0.5710 - test_loss: 0.520715\n",
      "Epoch: 150/200 - train_loss: 0.2641 - test_loss: 0.109866\n",
      "Epoch: 210/420 - train_loss: 0.2210 - test_loss: 0.103956\n",
      "Epoch: 150/200 - train_loss: 0.2598 - test_loss: 0.104080\n",
      "Epoch: 499/500 - train_loss: 0.2200 - test_loss: 0.106605\n",
      "Epoch: 100/200 - train_loss: 0.2314 - test_loss: 0.133032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:32:25,383]\u001b[0m Trial 49 finished with value: 20.812524548107284 and parameters: {'n layers': 6, 'Hidden size': 37, 'Learning rate': 0.000497582731949548, 'Dropout rate': 0.2524432576672505, 'Epochs': 500}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 315/420 - train_loss: 0.2203 - test_loss: 0.100436\n",
      "Epoch: 199/200 - train_loss: 0.2269 - test_loss: 0.103665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:32:29,943]\u001b[0m Trial 3 finished with value: 22.00695939588644 and parameters: {'n layers': 6, 'Hidden size': 160, 'Learning rate': 0.0006071305030857268, 'Dropout rate': 0.5992865541485418, 'Epochs': 260}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/200 - train_loss: 0.4368 - test_loss: 0.383286\n",
      "Epoch: 199/200 - train_loss: 0.2583 - test_loss: 0.099702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:32:50,392]\u001b[0m Trial 1 finished with value: 20.866668026609037 and parameters: {'n layers': 4, 'Hidden size': 17, 'Learning rate': 0.0017752889780258115, 'Dropout rate': 0.536411158243451, 'Epochs': 270}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200 - train_loss: 0.2197 - test_loss: 0.108691\n",
      "Epoch: 315/420 - train_loss: 0.2616 - test_loss: 0.104509\n",
      "Epoch: 150/200 - train_loss: 0.3389 - test_loss: 0.279475\n",
      "Epoch: 419/420 - train_loss: 0.2461 - test_loss: 0.100252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:33:12,681]\u001b[0m Trial 48 finished with value: 22.134590181677407 and parameters: {'n layers': 6, 'Hidden size': 46, 'Learning rate': 0.00046028669852699045, 'Dropout rate': 0.25487553024992227, 'Epochs': 420}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200 - train_loss: 0.2200 - test_loss: 0.099240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:33:14,637]\u001b[0m Trial 2 finished with value: 21.436461673667154 and parameters: {'n layers': 5, 'Hidden size': 138, 'Learning rate': 0.0005672812311037511, 'Dropout rate': 0.6956163322526292, 'Epochs': 170}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200 - train_loss: 0.3077 - test_loss: 0.204476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:33:21,682]\u001b[0m Trial 18 finished with value: 25.65429580183175 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.00019368477421922748, 'Dropout rate': 0.46017521890390495, 'Epochs': 490}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 419/420 - train_loss: 0.2193 - test_loss: 0.104254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:33:26,124]\u001b[0m Trial 47 finished with value: 21.41155318282902 and parameters: {'n layers': 6, 'Hidden size': 37, 'Learning rate': 0.0004796068260615645, 'Dropout rate': 0.24729608421166446, 'Epochs': 500}. Best is trial 4 with value: 19.76578689774623.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 01:33:26,140]\u001b[0m A new study created in memory with name: no-name-d86a640b-68c6-4fc9-a2f0-323939315af5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Thái Bình\n",
      "  Value:  19.76578689774623\n",
      "optimize result of city: Thái Bình\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookbacklookback 3\n",
      " 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookbacklookback 3\n",
      " 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/270 - train_loss: 1.6651 - test_loss: 0.934403\n",
      "Epoch:  0/270 - train_loss: 1.0599 - test_loss: 0.776053\n",
      "Epoch:  0/270 - train_loss: 1.2222 - test_loss: 1.173186\n",
      "Epoch:  0/270 - train_loss: 0.9155 - test_loss: 0.703395\n",
      "Epoch:  0/270 - train_loss: 1.1088 - test_loss: 0.684786\n",
      "Epoch:  0/270 - train_loss: 1.3249 - test_loss: 0.978629\n",
      "Epoch:  0/270 - train_loss: 0.7860 - test_loss: 0.616080\n",
      "Epoch:  0/270 - train_loss: 0.9508 - test_loss: 0.739095\n",
      "Epoch:  0/270 - train_loss: 1.4967 - test_loss: 0.986966\n",
      "Epoch:  0/270 - train_loss: 1.0926 - test_loss: 1.460430Epoch:  0/270 - train_loss: 1.4167 - test_loss: 1.045637Epoch:  0/270 - train_loss: 0.9165 - test_loss: 0.698640\n",
      "\n",
      "\n",
      "Epoch:  0/270 - train_loss: 1.0640 - test_loss: 0.685399\n",
      "Epoch:  0/270 - train_loss: 1.0295 - test_loss: 0.647630\n",
      "Epoch:  0/270 - train_loss: 0.9324 - test_loss: 0.602567\n",
      "Epoch:  0/270 - train_loss: 1.1829 - test_loss: 1.064464\n",
      "Epoch:  0/270 - train_loss: 1.0072 - test_loss: 0.721055\n",
      "Epoch:  0/270 - train_loss: 1.0687 - test_loss: 0.705642\n",
      "Epoch:  0/270 - train_loss: 0.9407 - test_loss: 0.659354\n",
      "Epoch:  0/270 - train_loss: 1.1000 - test_loss: 0.918282\n",
      "Epoch: 67/270 - train_loss: 0.1333 - test_loss: 0.106314\n",
      "Epoch: 67/270 - train_loss: 0.4635 - test_loss: 0.427841\n",
      "Epoch: 67/270 - train_loss: 0.1450 - test_loss: 0.107012\n",
      "Epoch: 67/270 - train_loss: 0.1334 - test_loss: 0.112690\n",
      "Epoch: 67/270 - train_loss: 0.2581 - test_loss: 0.238501\n",
      "Epoch: 67/270 - train_loss: 0.1327 - test_loss: 0.116779\n",
      "Epoch: 134/270 - train_loss: 0.1325 - test_loss: 0.111993\n",
      "Epoch: 134/270 - train_loss: 0.2736 - test_loss: 0.253128\n",
      "Epoch: 134/270 - train_loss: 0.1323 - test_loss: 0.098825\n",
      "Epoch: 67/270 - train_loss: 0.2349 - test_loss: 0.109431\n",
      "Epoch: 134/270 - train_loss: 0.1319 - test_loss: 0.104431\n",
      "Epoch: 134/270 - train_loss: 0.1381 - test_loss: 0.116504\n",
      "Epoch: 134/270 - train_loss: 0.1309 - test_loss: 0.111383\n",
      "Epoch: 201/270 - train_loss: 0.1321 - test_loss: 0.102551\n",
      "Epoch: 201/270 - train_loss: 0.1742 - test_loss: 0.157854\n",
      "Epoch: 201/270 - train_loss: 0.1303 - test_loss: 0.102318\n",
      "Epoch: 201/270 - train_loss: 0.1337 - test_loss: 0.110415\n",
      "Epoch: 67/270 - train_loss: 0.1333 - test_loss: 0.102201\n",
      "Epoch: 134/270 - train_loss: 0.1305 - test_loss: 0.105696\n",
      "Epoch: 201/270 - train_loss: 0.1340 - test_loss: 0.106423\n",
      "Epoch: 268/270 - train_loss: 0.1335 - test_loss: 0.106434\n",
      "Epoch: 269/270 - train_loss: 0.1353 - test_loss: 0.105226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:23,999]\u001b[0m Trial 10 finished with value: 15.00763777084392 and parameters: {'n layers': 5, 'Hidden size': 244, 'Learning rate': 0.0022386881518515695, 'Dropout rate': 0.09232334321312238, 'Epochs': 140}. Best is trial 10 with value: 15.00763777084392.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 268/270 - train_loss: 0.1428 - test_loss: 0.118090\n",
      "Epoch: 269/270 - train_loss: 0.1458 - test_loss: 0.113295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:35,431]\u001b[0m Trial 17 finished with value: 16.375679154313822 and parameters: {'n layers': 5, 'Hidden size': 172, 'Learning rate': 0.0002452724291563479, 'Dropout rate': 0.614461975888234, 'Epochs': 260}. Best is trial 10 with value: 15.00763777084392.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 201/270 - train_loss: 0.1319 - test_loss: 0.100054\n",
      "Epoch: 268/270 - train_loss: 0.1329 - test_loss: 0.101296\n",
      "Epoch: 269/270 - train_loss: 0.1310 - test_loss: 0.106267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:43,884]\u001b[0m Trial 14 finished with value: 15.710582046097562 and parameters: {'n layers': 5, 'Hidden size': 274, 'Learning rate': 0.0013438457227723324, 'Dropout rate': 0.5165678653108913, 'Epochs': 160}. Best is trial 10 with value: 15.00763777084392.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 268/270 - train_loss: 0.1327 - test_loss: 0.109724\n",
      "Epoch: 269/270 - train_loss: 0.1358 - test_loss: 0.100321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:44:12,746]\u001b[0m Trial 15 finished with value: 15.694353683272332 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0014712896814997344, 'Dropout rate': 0.5381263541123281, 'Epochs': 450}. Best is trial 10 with value: 15.00763777084392.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/200 - train_loss: 1.6765 - test_loss: 1.025110\n",
      "Epoch:  0/200 - train_loss: 0.9756 - test_loss: 0.678869\n",
      "Epoch: 268/270 - train_loss: 0.1335 - test_loss: 0.103071\n",
      "Epoch: 269/270 - train_loss: 0.1386 - test_loss: 0.109034\n",
      "Epoch:  0/200 - train_loss: 1.2304 - test_loss: 1.501093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:45:15,084]\u001b[0m Trial 11 finished with value: 16.060553270179508 and parameters: {'n layers': 4, 'Hidden size': 7, 'Learning rate': 0.0005280824225706408, 'Dropout rate': 0.7696120904960337, 'Epochs': 350}. Best is trial 10 with value: 15.00763777084392.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 201/270 - train_loss: 0.1402 - test_loss: 0.112554\n",
      "Epoch: 134/270 - train_loss: 0.1334 - test_loss: 0.104622\n",
      "Epoch:  0/350 - train_loss: 1.2627 - test_loss: 0.757357\n",
      "Epoch: 67/270 - train_loss: 0.1370 - test_loss: 0.104986\n",
      "Epoch: 67/270 - train_loss: 0.1303 - test_loss: 0.101641\n",
      "Epoch:  0/350 - train_loss: 1.5192 - test_loss: 0.942009\n",
      "Epoch: 268/270 - train_loss: 0.1308 - test_loss: 0.107095\n",
      "Epoch: 269/270 - train_loss: 0.1342 - test_loss: 0.101273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:46:10,849]\u001b[0m Trial 8 finished with value: 14.796405764516889 and parameters: {'n layers': 4, 'Hidden size': 134, 'Learning rate': 0.007366327993781505, 'Dropout rate': 0.44580928880804993, 'Epochs': 210}. Best is trial 8 with value: 14.796405764516889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/200 - train_loss: 0.5101 - test_loss: 0.461464\n",
      "Epoch: 67/270 - train_loss: 0.1341 - test_loss: 0.100087\n",
      "Epoch: 50/200 - train_loss: 0.1452 - test_loss: 0.102035\n",
      "Epoch: 50/200 - train_loss: 0.5073 - test_loss: 0.448907\n",
      "Epoch:  0/100 - train_loss: 1.4081 - test_loss: 1.185889\n",
      "Epoch: 100/200 - train_loss: 0.3083 - test_loss: 0.282625\n",
      "Epoch: 25/100 - train_loss: 1.0070 - test_loss: 0.844816\n",
      "Epoch: 268/270 - train_loss: 0.1333 - test_loss: 0.095962\n",
      "Epoch: 269/270 - train_loss: 0.1298 - test_loss: 0.110283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:47:26,844]\u001b[0m Trial 4 finished with value: 15.570282661402294 and parameters: {'n layers': 4, 'Hidden size': 6, 'Learning rate': 0.0020447474158811684, 'Dropout rate': 0.28004687568629766, 'Epochs': 470}. Best is trial 8 with value: 14.796405764516889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 100/200 - train_loss: 0.1359 - test_loss: 0.102874\n",
      "Epoch: 87/350 - train_loss: 0.4737 - test_loss: 0.432600\n",
      "Epoch: 100/200 - train_loss: 0.2805 - test_loss: 0.260961\n",
      "Epoch: 201/270 - train_loss: 0.2246 - test_loss: 0.136359\n",
      "Epoch: 50/100 - train_loss: 0.7570 - test_loss: 0.635781\n",
      "Epoch:  0/370 - train_loss: 1.2199 - test_loss: 1.297805\n",
      "Epoch: 87/350 - train_loss: 0.2090 - test_loss: 0.179359\n",
      "Epoch: 150/200 - train_loss: 0.2072 - test_loss: 0.178570\n",
      "Epoch: 75/100 - train_loss: 0.6427 - test_loss: 0.529745\n",
      "Epoch: 150/200 - train_loss: 0.1304 - test_loss: 0.107382\n",
      "Epoch: 134/270 - train_loss: 0.1409 - test_loss: 0.106485\n",
      "Epoch: 150/200 - train_loss: 0.1882 - test_loss: 0.166657\n",
      "Epoch: 99/100 - train_loss: 0.5223 - test_loss: 0.466392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:49:15,201]\u001b[0m Trial 25 finished with value: 23.136977875928398 and parameters: {'n layers': 4, 'Hidden size': 6, 'Learning rate': 0.00013183485072338426, 'Dropout rate': 0.6287312944866763, 'Epochs': 100}. Best is trial 8 with value: 14.796405764516889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 199/200 - train_loss: 0.1552 - test_loss: 0.130577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:49:34,330]\u001b[0m Trial 20 finished with value: 16.167300212316906 and parameters: {'n layers': 6, 'Hidden size': 79, 'Learning rate': 0.0002943583961613013, 'Dropout rate': 0.04280061633570505, 'Epochs': 350}. Best is trial 8 with value: 14.796405764516889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 174/350 - train_loss: 0.2819 - test_loss: 0.258038\n",
      "Epoch: 199/200 - train_loss: 0.1327 - test_loss: 0.096791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:49:55,863]\u001b[0m Trial 21 finished with value: 15.578015064759107 and parameters: {'n layers': 5, 'Hidden size': 66, 'Learning rate': 0.0027025566579116935, 'Dropout rate': 0.07137404971350442, 'Epochs': 420}. Best is trial 8 with value: 14.796405764516889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/240 - train_loss: 1.5364 - test_loss: 1.637536\n",
      "Epoch: 199/200 - train_loss: 0.1461 - test_loss: 0.125865\n",
      "Epoch: 268/270 - train_loss: 0.1348 - test_loss: 0.107593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:50:15,357]\u001b[0m Trial 22 finished with value: 16.03936281222357 and parameters: {'n layers': 5, 'Hidden size': 47, 'Learning rate': 0.0002967738345456811, 'Dropout rate': 0.5942636061862161, 'Epochs': 420}. Best is trial 8 with value: 14.796405764516889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 269/270 - train_loss: 0.1325 - test_loss: 0.099253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:50:20,644]\u001b[0m Trial 18 finished with value: 14.405458720293936 and parameters: {'n layers': 6, 'Hidden size': 8, 'Learning rate': 0.0045657277801958475, 'Dropout rate': 0.2332033728267365, 'Epochs': 430}. Best is trial 18 with value: 14.405458720293936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 134/270 - train_loss: 0.1341 - test_loss: 0.107086\n",
      "Epoch: 174/350 - train_loss: 0.1377 - test_loss: 0.104055\n",
      "Epoch:  0/230 - train_loss: 1.0863 - test_loss: 0.884526\n",
      "Epoch: 92/370 - train_loss: 0.4703 - test_loss: 0.443933\n",
      "Epoch:  0/230 - train_loss: 0.9166 - test_loss: 0.559203\n",
      "Epoch:  0/230 - train_loss: 0.9414 - test_loss: 0.591919\n",
      "Epoch:  0/230 - train_loss: 1.0216 - test_loss: 0.614055\n",
      "Epoch: 201/270 - train_loss: 0.1341 - test_loss: 0.107873\n",
      "Epoch: 60/240 - train_loss: 0.4589 - test_loss: 0.428091\n",
      "Epoch: 57/230 - train_loss: 0.1338 - test_loss: 0.100066\n",
      "Epoch: 261/350 - train_loss: 0.1792 - test_loss: 0.158507\n",
      "Epoch: 57/230 - train_loss: 0.1336 - test_loss: 0.100158\n",
      "Epoch: 57/230 - train_loss: 0.1361 - test_loss: 0.103142\n",
      "Epoch: 261/350 - train_loss: 0.1333 - test_loss: 0.103393\n",
      "Epoch: 114/230 - train_loss: 0.1321 - test_loss: 0.098431\n",
      "Epoch: 120/240 - train_loss: 0.3068 - test_loss: 0.248824\n",
      "Epoch: 57/230 - train_loss: 0.1353 - test_loss: 0.110846\n",
      "Epoch: 134/270 - train_loss: 0.1322 - test_loss: 0.102768\n",
      "Epoch: 114/230 - train_loss: 0.1332 - test_loss: 0.100300\n",
      "Epoch: 184/370 - train_loss: 0.2922 - test_loss: 0.271084\n",
      "Epoch: 114/230 - train_loss: 0.1317 - test_loss: 0.113512\n",
      "Epoch: 348/350 - train_loss: 0.1451 - test_loss: 0.118544\n",
      "Epoch: 349/350 - train_loss: 0.1407 - test_loss: 0.119891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:53:54,628]\u001b[0m Trial 23 finished with value: 16.053337441893486 and parameters: {'n layers': 4, 'Hidden size': 20, 'Learning rate': 0.00017586806994676936, 'Dropout rate': 0.49016590630398676, 'Epochs': 200}. Best is trial 18 with value: 14.405458720293936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 171/230 - train_loss: 0.1330 - test_loss: 0.104010\n",
      "Epoch:  0/250 - train_loss: 0.7903 - test_loss: 0.547762\n",
      "Epoch: 348/350 - train_loss: 0.1312 - test_loss: 0.102925\n",
      "Epoch: 171/230 - train_loss: 0.1306 - test_loss: 0.108063\n",
      "Epoch: 349/350 - train_loss: 0.2327 - test_loss: 0.104420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:54:44,758]\u001b[0m Trial 24 finished with value: 15.920231385233485 and parameters: {'n layers': 4, 'Hidden size': 207, 'Learning rate': 0.00046955991897289467, 'Dropout rate': 0.2963209423683924, 'Epochs': 350}. Best is trial 18 with value: 14.405458720293936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 201/270 - train_loss: 0.1331 - test_loss: 0.103908\n",
      "Epoch: 180/240 - train_loss: 0.1796 - test_loss: 0.153912\n",
      "Epoch: 268/270 - train_loss: 0.1315 - test_loss: 0.101434\n",
      "Epoch: 269/270 - train_loss: 0.1339 - test_loss: 0.106286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:54:55,977]\u001b[0m Trial 12 finished with value: 14.322836093110263 and parameters: {'n layers': 6, 'Hidden size': 59, 'Learning rate': 0.0049028571143509515, 'Dropout rate': 0.6564470094457224, 'Epochs': 470}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 171/230 - train_loss: 0.1362 - test_loss: 0.105326\n",
      "Epoch: 114/230 - train_loss: 0.1328 - test_loss: 0.112178\n",
      "Epoch:  0/480 - train_loss: 0.7937 - test_loss: 0.563181\n",
      "Epoch:  0/480 - train_loss: 0.9592 - test_loss: 0.639196\n",
      "Epoch: 228/230 - train_loss: 0.1356 - test_loss: 0.092889\n",
      "Epoch: 229/230 - train_loss: 0.1326 - test_loss: 0.098991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:55:58,814]\u001b[0m Trial 28 finished with value: 14.5113948705691 and parameters: {'n layers': 4, 'Hidden size': 223, 'Learning rate': 0.0014422776970506414, 'Dropout rate': 0.5811829433469508, 'Epochs': 430}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 228/230 - train_loss: 0.1322 - test_loss: 0.108494\n",
      "Epoch: 276/370 - train_loss: 0.1906 - test_loss: 0.166649\n",
      "Epoch: 229/230 - train_loss: 0.1327 - test_loss: 0.102404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:56:24,913]\u001b[0m Trial 29 finished with value: 14.52648915169501 and parameters: {'n layers': 3, 'Hidden size': 24, 'Learning rate': 0.009829167231826478, 'Dropout rate': 0.3140293007101525, 'Epochs': 240}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 62/250 - train_loss: 0.1383 - test_loss: 0.105563\n",
      "Epoch: 67/270 - train_loss: 0.4211 - test_loss: 0.400861\n",
      "Epoch: 239/240 - train_loss: 0.1396 - test_loss: 0.117608\n",
      "Epoch: 228/230 - train_loss: 0.1602 - test_loss: 0.125478\n",
      "Epoch:  0/500 - train_loss: 0.8488 - test_loss: 0.554134\n",
      "Epoch: 229/230 - train_loss: 0.1456 - test_loss: 0.121714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:56:47,499]\u001b[0m Trial 27 finished with value: 16.00649839459407 and parameters: {'n layers': 4, 'Hidden size': 8, 'Learning rate': 0.00028811630545773646, 'Dropout rate': 0.6693640782161734, 'Epochs': 490}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:56:50,809]\u001b[0m Trial 30 finished with value: 15.230888814580952 and parameters: {'n layers': 3, 'Hidden size': 348, 'Learning rate': 0.009058463365876868, 'Dropout rate': 0.31008062117443347, 'Epochs': 210}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 171/230 - train_loss: 0.2419 - test_loss: 0.107389\n",
      "Epoch:  0/380 - train_loss: 0.9168 - test_loss: 0.763166\n",
      "Epoch:  0/380 - train_loss: 0.8766 - test_loss: 0.632983\n",
      "Epoch: 268/270 - train_loss: 0.1338 - test_loss: 0.118844\n",
      "Epoch:  0/380 - train_loss: 1.0023 - test_loss: 0.699218\n",
      "Epoch: 269/270 - train_loss: 0.1329 - test_loss: 0.105236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:58:11,052]\u001b[0m Trial 7 finished with value: 15.481390651486414 and parameters: {'n layers': 3, 'Hidden size': 49, 'Learning rate': 0.0037640265700745602, 'Dropout rate': 0.402155128967028, 'Epochs': 380}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 201/270 - train_loss: 0.1309 - test_loss: 0.109589\n",
      "Epoch: 124/250 - train_loss: 0.1323 - test_loss: 0.105875\n",
      "Epoch:  0/500 - train_loss: 1.2034 - test_loss: 0.800556\n",
      "Epoch: 120/480 - train_loss: 0.1486 - test_loss: 0.109155\n",
      "Epoch: 368/370 - train_loss: 0.1488 - test_loss: 0.120821\n",
      "Epoch: 369/370 - train_loss: 0.1438 - test_loss: 0.116440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:59:34,156]\u001b[0m Trial 26 finished with value: 15.758245649693563 and parameters: {'n layers': 3, 'Hidden size': 91, 'Learning rate': 0.00017013168707907881, 'Dropout rate': 0.4076816882377333, 'Epochs': 370}. Best is trial 12 with value: 14.322836093110263.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 228/230 - train_loss: 0.1324 - test_loss: 0.104057\n",
      "lookback 3\n",
      "Epoch: 229/230 - train_loss: 0.2333 - test_loss: 0.111488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:59:39,058]\u001b[0m Trial 31 finished with value: 13.739706866206879 and parameters: {'n layers': 3, 'Hidden size': 18, 'Learning rate': 0.009750886535333295, 'Dropout rate': 0.3087050500507645, 'Epochs': 230}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 186/250 - train_loss: 0.1336 - test_loss: 0.108153\n",
      "Epoch: 95/380 - train_loss: 0.1301 - test_loss: 0.109262\n",
      "Epoch: 125/500 - train_loss: 0.1327 - test_loss: 0.101118\n",
      "Epoch:  0/310 - train_loss: 0.7520 - test_loss: 0.618196\n",
      "Epoch: 95/380 - train_loss: 0.1408 - test_loss: 0.109870\n",
      "Epoch:  0/310 - train_loss: 1.1503 - test_loss: 0.703798\n",
      "Epoch: 95/380 - train_loss: 0.2247 - test_loss: 0.115250\n",
      "Epoch: 248/250 - train_loss: 0.1325 - test_loss: 0.103888\n",
      "Epoch: 249/250 - train_loss: 0.1314 - test_loss: 0.098877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:01:30,093]\u001b[0m Trial 32 finished with value: 13.869470059577067 and parameters: {'n layers': 3, 'Hidden size': 21, 'Learning rate': 0.009552315091109187, 'Dropout rate': 0.2922283000111322, 'Epochs': 250}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 120/480 - train_loss: 0.1328 - test_loss: 0.100072\n",
      "Epoch:  0/300 - train_loss: 0.8855 - test_loss: 0.614389\n",
      "Epoch: 190/380 - train_loss: 0.1301 - test_loss: 0.103378\n",
      "Epoch: 240/480 - train_loss: 0.1372 - test_loss: 0.102650\n",
      "Epoch: 77/310 - train_loss: 0.1440 - test_loss: 0.112482\n",
      "Epoch: 190/380 - train_loss: 0.1391 - test_loss: 0.116305\n",
      "Epoch: 250/500 - train_loss: 0.1344 - test_loss: 0.105792\n",
      "Epoch: 190/380 - train_loss: 0.1327 - test_loss: 0.105613\n",
      "Epoch: 77/310 - train_loss: 0.1356 - test_loss: 0.102861\n",
      "Epoch: 75/300 - train_loss: 0.1364 - test_loss: 0.112864\n",
      "Epoch: 285/380 - train_loss: 0.1348 - test_loss: 0.121705\n",
      "Epoch: 285/380 - train_loss: 0.1316 - test_loss: 0.104515\n",
      "Epoch: 154/310 - train_loss: 0.1332 - test_loss: 0.093424\n",
      "Epoch: 360/480 - train_loss: 0.1336 - test_loss: 0.102505\n",
      "Epoch: 150/300 - train_loss: 0.1345 - test_loss: 0.107950\n",
      "Epoch: 285/380 - train_loss: 0.1314 - test_loss: 0.106073\n",
      "Epoch: 375/500 - train_loss: 0.1296 - test_loss: 0.100224\n",
      "Epoch: 379/380 - train_loss: 0.1325 - test_loss: 0.105122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:05:01,735]\u001b[0m Trial 36 finished with value: 15.432037233930892 and parameters: {'n layers': 6, 'Hidden size': 15, 'Learning rate': 0.004536340248493833, 'Dropout rate': 0.18342299848213117, 'Epochs': 500}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 154/310 - train_loss: 0.1341 - test_loss: 0.106792\n",
      "lookback 3\n",
      "Epoch: 379/380 - train_loss: 0.1302 - test_loss: 0.102376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:05:40,408]\u001b[0m Trial 38 finished with value: 15.003435247151687 and parameters: {'n layers': 6, 'Hidden size': 19, 'Learning rate': 0.004578118889417134, 'Dropout rate': 0.1465577168507538, 'Epochs': 380}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 231/310 - train_loss: 0.1491 - test_loss: 0.109647\n",
      "Epoch: 225/300 - train_loss: 0.1302 - test_loss: 0.103012\n",
      "Epoch:  0/300 - train_loss: 0.8658 - test_loss: 0.606873\n",
      "Epoch: 240/480 - train_loss: 0.1313 - test_loss: 0.103397\n",
      "Epoch:  0/300 - train_loss: 0.7042 - test_loss: 0.609938\n",
      "Epoch: 379/380 - train_loss: 0.1379 - test_loss: 0.102573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:06:40,519]\u001b[0m Trial 37 finished with value: 16.322201725076074 and parameters: {'n layers': 6, 'Hidden size': 16, 'Learning rate': 0.004415219652811588, 'Dropout rate': 0.17585512187604913, 'Epochs': 380}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 479/480 - train_loss: 0.1319 - test_loss: 0.099393\n",
      "Epoch: 268/270 - train_loss: 0.1329 - test_loss: 0.106652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:06:53,892]\u001b[0m Trial 33 finished with value: 14.023804855809518 and parameters: {'n layers': 3, 'Hidden size': 17, 'Learning rate': 0.00917874486388097, 'Dropout rate': 0.3286200465424889, 'Epochs': 260}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 269/270 - train_loss: 0.1312 - test_loss: 0.104117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:06:58,302]\u001b[0m Trial 16 finished with value: 16.211718146831053 and parameters: {'n layers': 6, 'Hidden size': 26, 'Learning rate': 0.0015828881546066317, 'Dropout rate': 0.6138275380300154, 'Epochs': 270}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 125/500 - train_loss: 0.1330 - test_loss: 0.108501\n",
      "Epoch: 499/500 - train_loss: 0.1363 - test_loss: 0.116207\n",
      "Epoch: 67/270 - train_loss: 0.1329 - test_loss: 0.116847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:07:31,451]\u001b[0m Trial 35 finished with value: 14.195946293352927 and parameters: {'n layers': 6, 'Hidden size': 21, 'Learning rate': 0.009620416833182212, 'Dropout rate': 0.28759608992007735, 'Epochs': 500}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 231/310 - train_loss: 0.1347 - test_loss: 0.104153\n",
      "Epoch: 134/270 - train_loss: 0.2425 - test_loss: 0.221910\n",
      "Epoch:  0/300 - train_loss: 0.9019 - test_loss: 0.618384\n",
      "Epoch: 299/300 - train_loss: 0.1303 - test_loss: 0.100012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:08:12,799]\u001b[0m Trial 42 finished with value: 16.008661341905906 and parameters: {'n layers': 3, 'Hidden size': 24, 'Learning rate': 0.005780711600946167, 'Dropout rate': 0.17277420181756664, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 75/300 - train_loss: 0.1391 - test_loss: 0.103541\n",
      "Epoch:  0/300 - train_loss: 0.6983 - test_loss: 0.589042\n",
      "Epoch: 308/310 - train_loss: 0.1335 - test_loss: 0.102362\n",
      "Epoch:  0/300 - train_loss: 0.8762 - test_loss: 0.647373\n",
      "Epoch: 309/310 - train_loss: 0.1340 - test_loss: 0.107989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:08:41,404]\u001b[0m Trial 40 finished with value: 15.728813587065668 and parameters: {'n layers': 6, 'Hidden size': 23, 'Learning rate': 0.005205103812501504, 'Dropout rate': 0.7341304699340893, 'Epochs': 500}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/300 - train_loss: 1.0078 - test_loss: 0.657926\n",
      "Epoch:  0/300 - train_loss: 1.0142 - test_loss: 0.768922\n",
      "Epoch: 75/300 - train_loss: 0.2381 - test_loss: 0.112913\n",
      "Epoch: 150/300 - train_loss: 0.1319 - test_loss: 0.105358\n",
      "Epoch: 75/300 - train_loss: 0.1317 - test_loss: 0.099968\n",
      "Epoch: 308/310 - train_loss: 0.1343 - test_loss: 0.100764\n",
      "Epoch: 309/310 - train_loss: 0.1368 - test_loss: 0.106270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:10:11,930]\u001b[0m Trial 41 finished with value: 14.864145136479195 and parameters: {'n layers': 6, 'Hidden size': 15, 'Learning rate': 0.004926619750921087, 'Dropout rate': 0.17482126194628794, 'Epochs': 310}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/300 - train_loss: 0.1357 - test_loss: 0.108447\n",
      "Epoch: 75/300 - train_loss: 0.1460 - test_loss: 0.120217\n",
      "Epoch: 75/300 - train_loss: 0.1329 - test_loss: 0.106243\n",
      "Epoch: 150/300 - train_loss: 0.1440 - test_loss: 0.120858\n",
      "Epoch: 360/480 - train_loss: 0.1331 - test_loss: 0.098429\n",
      "Epoch: 225/300 - train_loss: 0.1333 - test_loss: 0.107384\n",
      "Epoch: 150/300 - train_loss: 0.1397 - test_loss: 0.101804\n",
      "Epoch: 150/300 - train_loss: 0.1398 - test_loss: 0.108069\n",
      "Epoch: 150/300 - train_loss: 0.1364 - test_loss: 0.127841\n",
      "Epoch: 150/300 - train_loss: 0.1327 - test_loss: 0.109559\n",
      "Epoch: 225/300 - train_loss: 0.1315 - test_loss: 0.109642\n",
      "Epoch: 250/500 - train_loss: 0.1299 - test_loss: 0.097021\n",
      "Epoch: 299/300 - train_loss: 0.1379 - test_loss: 0.105485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:12:48,740]\u001b[0m Trial 43 finished with value: 14.013980700183035 and parameters: {'n layers': 3, 'Hidden size': 26, 'Learning rate': 0.005947611479125394, 'Dropout rate': 0.16338909585305791, 'Epochs': 280}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 225/300 - train_loss: 0.1343 - test_loss: 0.106973\n",
      "Epoch: 75/300 - train_loss: 0.1341 - test_loss: 0.112153\n",
      "Epoch: 225/300 - train_loss: 0.1343 - test_loss: 0.112416\n",
      "Epoch: 225/300 - train_loss: 0.1328 - test_loss: 0.110559\n",
      "Epoch: 225/300 - train_loss: 0.1344 - test_loss: 0.101956\n",
      "Epoch: 299/300 - train_loss: 0.1305 - test_loss: 0.104363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:13:31,640]\u001b[0m Trial 44 finished with value: 15.054481040634945 and parameters: {'n layers': 3, 'Hidden size': 34, 'Learning rate': 0.006605217261435151, 'Dropout rate': 0.7435774714856769, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 479/480 - train_loss: 0.1315 - test_loss: 0.102203\n",
      "Epoch: 201/270 - train_loss: 0.1592 - test_loss: 0.138482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:13:55,053]\u001b[0m Trial 34 finished with value: 14.493842614247336 and parameters: {'n layers': 6, 'Hidden size': 17, 'Learning rate': 0.00877576803363657, 'Dropout rate': 0.29179386548673164, 'Epochs': 480}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/270 - train_loss: 0.1389 - test_loss: 0.102378\n",
      "Epoch: 67/270 - train_loss: 0.1563 - test_loss: 0.118347\n",
      "Epoch: 299/300 - train_loss: 0.1352 - test_loss: 0.105949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:14:24,825]\u001b[0m Trial 48 finished with value: 14.283712210647513 and parameters: {'n layers': 3, 'Hidden size': 32, 'Learning rate': 0.006585808065752023, 'Dropout rate': 0.3718233434199389, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/300 - train_loss: 0.2328 - test_loss: 0.104968\n",
      "Epoch: 299/300 - train_loss: 0.1335 - test_loss: 0.103891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:14:45,742]\u001b[0m Trial 46 finished with value: 15.823678839371643 and parameters: {'n layers': 3, 'Hidden size': 29, 'Learning rate': 0.007206524207055406, 'Dropout rate': 0.37950284765768116, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 02:14:46,520]\u001b[0m Trial 49 finished with value: 15.605626570551513 and parameters: {'n layers': 3, 'Hidden size': 12, 'Learning rate': 0.002932593342634377, 'Dropout rate': 0.35330711228051637, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134/270 - train_loss: 0.1330 - test_loss: 0.111077\n",
      "Epoch: 299/300 - train_loss: 0.1303 - test_loss: 0.106349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:14:54,818]\u001b[0m Trial 45 finished with value: 14.205339189897002 and parameters: {'n layers': 3, 'Hidden size': 30, 'Learning rate': 0.0063564162307480744, 'Dropout rate': 0.364757864796144, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/300 - train_loss: 0.2335 - test_loss: 0.109811\n",
      "Epoch: 67/270 - train_loss: 0.4538 - test_loss: 0.438367\n",
      "Epoch: 268/270 - train_loss: 0.1355 - test_loss: 0.113494\n",
      "Epoch: 269/270 - train_loss: 0.1341 - test_loss: 0.109072\n",
      "Epoch: 375/500 - train_loss: 0.1330 - test_loss: 0.098514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:15:24,301]\u001b[0m Trial 3 finished with value: 16.051228784515043 and parameters: {'n layers': 3, 'Hidden size': 6, 'Learning rate': 0.0002699351205800159, 'Dropout rate': 0.56862922396273, 'Epochs': 230}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134/270 - train_loss: 0.1340 - test_loss: 0.106136\n",
      "Epoch: 201/270 - train_loss: 0.1392 - test_loss: 0.101057\n",
      "Epoch: 134/270 - train_loss: 0.1340 - test_loss: 0.100146\n",
      "Epoch: 67/270 - train_loss: 0.1337 - test_loss: 0.134999\n",
      "Epoch: 67/270 - train_loss: 0.2042 - test_loss: 0.206576\n",
      "Epoch: 225/300 - train_loss: 0.1323 - test_loss: 0.104235\n",
      "Epoch: 134/270 - train_loss: 0.2723 - test_loss: 0.260344\n",
      "Epoch: 201/270 - train_loss: 0.1307 - test_loss: 0.097114\n",
      "Epoch: 268/270 - train_loss: 0.1340 - test_loss: 0.113526\n",
      "Epoch: 269/270 - train_loss: 0.1331 - test_loss: 0.102699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:17:17,040]\u001b[0m Trial 0 finished with value: 15.038870617529895 and parameters: {'n layers': 5, 'Hidden size': 18, 'Learning rate': 0.003964140998210158, 'Dropout rate': 0.028437586582920872, 'Epochs': 100}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/270 - train_loss: 0.1306 - test_loss: 0.104037\n",
      "Epoch: 499/500 - train_loss: 0.1311 - test_loss: 0.099049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:17:33,822]\u001b[0m Trial 39 finished with value: 16.067360861866714 and parameters: {'n layers': 6, 'Hidden size': 18, 'Learning rate': 0.004916695986253496, 'Dropout rate': 0.1918391003138243, 'Epochs': 500}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/300 - train_loss: 0.1398 - test_loss: 0.126078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:17:39,133]\u001b[0m Trial 47 finished with value: 14.829244920061186 and parameters: {'n layers': 3, 'Hidden size': 33, 'Learning rate': 0.006190062622104997, 'Dropout rate': 0.3691346668426726, 'Epochs': 300}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134/270 - train_loss: 0.1332 - test_loss: 0.104339\n",
      "Epoch: 67/270 - train_loss: 0.1347 - test_loss: 0.103259\n",
      "Epoch: 201/270 - train_loss: 0.2329 - test_loss: 0.156328\n",
      "Epoch: 134/270 - train_loss: 0.2268 - test_loss: 0.116939\n",
      "Epoch: 67/270 - train_loss: 0.1440 - test_loss: 0.116160\n",
      "Epoch: 268/270 - train_loss: 0.1339 - test_loss: 0.106913\n",
      "Epoch: 269/270 - train_loss: 0.1313 - test_loss: 0.105081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:18:18,430]\u001b[0m Trial 19 finished with value: 15.60566787704805 and parameters: {'n layers': 6, 'Hidden size': 175, 'Learning rate': 0.0025392086620266937, 'Dropout rate': 0.20226420699657907, 'Epochs': 270}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268/270 - train_loss: 0.1302 - test_loss: 0.105702\n",
      "Epoch: 269/270 - train_loss: 0.1339 - test_loss: 0.105883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:18:26,668]\u001b[0m Trial 13 finished with value: 15.613414075329908 and parameters: {'n layers': 5, 'Hidden size': 31, 'Learning rate': 0.0008339943351522286, 'Dropout rate': 0.5570980713129557, 'Epochs': 400}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/270 - train_loss: 0.1334 - test_loss: 0.107106\n",
      "Epoch: 268/270 - train_loss: 0.1444 - test_loss: 0.120921\n",
      "Epoch: 269/270 - train_loss: 0.1447 - test_loss: 0.117807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:18:48,239]\u001b[0m Trial 9 finished with value: 16.44865154032003 and parameters: {'n layers': 5, 'Hidden size': 6, 'Learning rate': 0.00024930139368800104, 'Dropout rate': 0.5354654638749318, 'Epochs': 140}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134/270 - train_loss: 0.1332 - test_loss: 0.106489\n",
      "Epoch: 201/270 - train_loss: 0.1310 - test_loss: 0.097607\n",
      "Epoch: 134/270 - train_loss: 0.1346 - test_loss: 0.103422\n",
      "Epoch: 268/270 - train_loss: 0.1332 - test_loss: 0.102627\n",
      "Epoch: 269/270 - train_loss: 0.1306 - test_loss: 0.102420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:19:19,688]\u001b[0m Trial 1 finished with value: 15.688196882673664 and parameters: {'n layers': 4, 'Hidden size': 81, 'Learning rate': 0.006726965278644507, 'Dropout rate': 0.7125731322483088, 'Epochs': 110}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/270 - train_loss: 0.1390 - test_loss: 0.104137\n",
      "Epoch: 268/270 - train_loss: 0.1309 - test_loss: 0.107826\n",
      "Epoch: 269/270 - train_loss: 0.1307 - test_loss: 0.108122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:19:29,310]\u001b[0m Trial 6 finished with value: 15.846906491258329 and parameters: {'n layers': 3, 'Hidden size': 131, 'Learning rate': 0.0006195227067587089, 'Dropout rate': 0.4377786595350605, 'Epochs': 360}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/270 - train_loss: 0.2346 - test_loss: 0.101963\n",
      "Epoch: 268/270 - train_loss: 0.1467 - test_loss: 0.113619\n",
      "Epoch: 269/270 - train_loss: 0.1434 - test_loss: 0.111585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:19:50,268]\u001b[0m Trial 2 finished with value: 15.121490948472891 and parameters: {'n layers': 5, 'Hidden size': 51, 'Learning rate': 0.0053409886456950275, 'Dropout rate': 0.7893088642984134, 'Epochs': 440}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268/270 - train_loss: 0.1318 - test_loss: 0.101380\n",
      "Epoch: 269/270 - train_loss: 0.2357 - test_loss: 0.108700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:19:58,408]\u001b[0m Trial 5 finished with value: 15.7745205465125 and parameters: {'n layers': 6, 'Hidden size': 11, 'Learning rate': 0.0011291587663975798, 'Dropout rate': 0.45665569289058755, 'Epochs': 130}. Best is trial 31 with value: 13.739706866206879.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 02:19:58,425]\u001b[0m A new study created in memory with name: no-name-b0d2bde9-6b5f-4622-9eca-139d381de0ca\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Thái Nguyên\n",
      "  Value:  13.739706866206879\n",
      "optimize result of city: Thái Nguyên\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3lookback 3\n",
      "\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/120 - train_loss: 0.9040 - test_loss: 0.797225\n",
      "Epoch:  0/120 - train_loss: 1.5666 - test_loss: 1.834305\n",
      "Epoch:  0/120 - train_loss: 1.4083 - test_loss: 0.772020\n",
      "Epoch:  0/120 - train_loss: 1.5163 - test_loss: 1.149582\n",
      "Epoch:  0/120 - train_loss: 0.9641 - test_loss: 0.791239Epoch:  0/120 - train_loss: 1.0337 - test_loss: 0.808489\n",
      "\n",
      "Epoch:  0/120 - train_loss: 1.4012 - test_loss: 0.731233\n",
      "Epoch:  0/120 - train_loss: 1.7123 - test_loss: 1.791046\n",
      "Epoch:  0/120 - train_loss: 1.3263 - test_loss: 1.073564\n",
      "Epoch:  0/120 - train_loss: 0.8679 - test_loss: 0.733898\n",
      "Epoch:  0/120 - train_loss: 1.3656 - test_loss: 1.186846\n",
      "Epoch:  0/120 - train_loss: 1.6120 - test_loss: 2.241190Epoch:  0/120 - train_loss: 0.9732 - test_loss: 0.723113\n",
      "\n",
      "Epoch:  0/120 - train_loss: 1.9073 - test_loss: 1.498386\n",
      "Epoch:  0/120 - train_loss: 1.5643 - test_loss: 0.750959\n",
      "Epoch:  0/120 - train_loss: 1.4822 - test_loss: 1.093811\n",
      "Epoch:  0/120 - train_loss: 1.2370 - test_loss: 0.946018\n",
      "Epoch:  0/120 - train_loss: 1.1232 - test_loss: 1.165078\n",
      "Epoch:  0/120 - train_loss: 1.5881 - test_loss: 0.853329\n",
      "Epoch:  0/120 - train_loss: 1.3921 - test_loss: 1.290773\n",
      "Epoch: 30/120 - train_loss: 0.4189 - test_loss: 0.591197\n",
      "Epoch: 30/120 - train_loss: 0.8996 - test_loss: 0.811088\n",
      "Epoch: 30/120 - train_loss: 0.3907 - test_loss: 0.579738\n",
      "Epoch: 30/120 - train_loss: 0.4256 - test_loss: 0.596414\n",
      "Epoch: 60/120 - train_loss: 0.4222 - test_loss: 0.711956\n",
      "Epoch: 60/120 - train_loss: 0.7185 - test_loss: 0.747797\n",
      "Epoch: 60/120 - train_loss: 0.3835 - test_loss: 0.619153\n",
      "Epoch: 60/120 - train_loss: 0.3841 - test_loss: 0.610271\n",
      "Epoch: 30/120 - train_loss: 0.8339 - test_loss: 0.813961\n",
      "Epoch: 90/120 - train_loss: 0.3844 - test_loss: 0.602012\n",
      "Epoch: 90/120 - train_loss: 0.6094 - test_loss: 0.666756\n",
      "Epoch: 90/120 - train_loss: 0.4313 - test_loss: 0.660712\n",
      "Epoch: 90/120 - train_loss: 0.4133 - test_loss: 0.577815\n",
      "Epoch: 119/120 - train_loss: 0.4393 - test_loss: 0.563857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:27:45,505]\u001b[0m Trial 11 finished with value: 52.787847582500056 and parameters: {'n layers': 6, 'Hidden size': 8, 'Learning rate': 0.009513645042809332, 'Dropout rate': 0.7065539890350437, 'Epochs': 500}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 119/120 - train_loss: 0.5612 - test_loss: 0.619704\n",
      "Epoch: 60/120 - train_loss: 0.7226 - test_loss: 0.699229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:27:50,222]\u001b[0m Trial 8 finished with value: 66.47320894459375 and parameters: {'n layers': 3, 'Hidden size': 25, 'Learning rate': 0.00019084280629148143, 'Dropout rate': 0.18414408889061837, 'Epochs': 420}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 119/120 - train_loss: 0.4218 - test_loss: 0.728791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:28:00,355]\u001b[0m Trial 12 finished with value: 56.86714579537209 and parameters: {'n layers': 3, 'Hidden size': 10, 'Learning rate': 0.0045609655747570555, 'Dropout rate': 0.2563575581246913, 'Epochs': 370}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 119/120 - train_loss: 0.4579 - test_loss: 0.705667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:28:33,830]\u001b[0m Trial 19 finished with value: 59.30891500738064 and parameters: {'n layers': 5, 'Hidden size': 130, 'Learning rate': 0.0031882555456812624, 'Dropout rate': 0.15503592957330908, 'Epochs': 120}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 30/120 - train_loss: 0.3999 - test_loss: 0.643343\n",
      "Epoch: 90/120 - train_loss: 0.6465 - test_loss: 0.671456\n",
      "Epoch:  0/200 - train_loss: 1.5839 - test_loss: 1.513746\n",
      "Epoch: 30/120 - train_loss: 0.4493 - test_loss: 0.587003\n",
      "Epoch: 30/120 - train_loss: 0.6199 - test_loss: 0.727803\n",
      "Epoch: 30/120 - train_loss: 0.6478 - test_loss: 0.615694\n",
      "Epoch: 30/120 - train_loss: 0.4067 - test_loss: 0.609663Epoch: 30/120 - train_loss: 0.4120 - test_loss: 0.607699\n",
      "\n",
      "Epoch: 30/120 - train_loss: 0.7013 - test_loss: 0.723153\n",
      "Epoch: 30/120 - train_loss: 0.3986 - test_loss: 0.657986\n",
      "Epoch: 30/120 - train_loss: 0.4115 - test_loss: 0.550470\n",
      "Epoch: 30/120 - train_loss: 0.7058 - test_loss: 0.702087\n",
      "Epoch:  0/200 - train_loss: 1.8005 - test_loss: 1.064567\n",
      "Epoch:  0/200 - train_loss: 1.1333 - test_loss: 0.767866\n",
      "Epoch:  0/200 - train_loss: 1.0619 - test_loss: 0.846496\n",
      "Epoch: 60/120 - train_loss: 0.3877 - test_loss: 0.700763\n",
      "Epoch: 119/120 - train_loss: 0.5991 - test_loss: 0.646831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:29:56,604]\u001b[0m Trial 15 finished with value: 62.77789013537417 and parameters: {'n layers': 3, 'Hidden size': 14, 'Learning rate': 0.00012550508165895473, 'Dropout rate': 0.7478692496773468, 'Epochs': 160}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 30/120 - train_loss: 0.4084 - test_loss: 0.595008\n",
      "Epoch: 30/120 - train_loss: 0.5097 - test_loss: 0.603801Epoch: 30/120 - train_loss: 1.0081 - test_loss: 0.692791\n",
      "\n",
      "Epoch: 60/120 - train_loss: 0.3922 - test_loss: 0.603507\n",
      "Epoch: 50/200 - train_loss: 0.5286 - test_loss: 0.600366\n",
      "Epoch: 50/200 - train_loss: 0.6210 - test_loss: 0.691326\n",
      "Epoch:  0/100 - train_loss: 1.5183 - test_loss: 1.728453\n",
      "Epoch: 90/120 - train_loss: 0.4121 - test_loss: 0.622181\n",
      "Epoch: 50/200 - train_loss: 0.4072 - test_loss: 0.589460\n",
      "Epoch: 50/200 - train_loss: 0.4267 - test_loss: 0.651417\n",
      "Epoch: 25/100 - train_loss: 0.5564 - test_loss: 0.622818\n",
      "Epoch: 90/120 - train_loss: 0.4168 - test_loss: 0.605426\n",
      "Epoch: 119/120 - train_loss: 0.4066 - test_loss: 0.702315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:31:18,060]\u001b[0m Trial 5 finished with value: 55.1489913245747 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.003687722992432094, 'Dropout rate': 0.6880038852978619, 'Epochs': 120}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 100/200 - train_loss: 0.4037 - test_loss: 0.568141\n",
      "Epoch: 30/120 - train_loss: 0.5123 - test_loss: 0.607679\n",
      "Epoch: 100/200 - train_loss: 0.4714 - test_loss: 0.571516\n",
      "Epoch: 100/200 - train_loss: 0.4425 - test_loss: 0.696187\n",
      "Epoch: 50/100 - train_loss: 0.4528 - test_loss: 0.563589\n",
      "Epoch:  0/380 - train_loss: 1.0849 - test_loss: 0.939518\n",
      "Epoch: 100/200 - train_loss: 0.3915 - test_loss: 0.508053\n",
      "Epoch: 119/120 - train_loss: 0.4681 - test_loss: 0.605565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:32:12,706]\u001b[0m Trial 3 finished with value: 60.70474124593846 and parameters: {'n layers': 3, 'Hidden size': 14, 'Learning rate': 0.0012827208743011944, 'Dropout rate': 0.3193662615393375, 'Epochs': 220}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 75/100 - train_loss: 0.4086 - test_loss: 0.581968\n",
      "Epoch: 150/200 - train_loss: 0.3914 - test_loss: 0.632473\n",
      "Epoch: 150/200 - train_loss: 0.4137 - test_loss: 0.589685\n",
      "Epoch:  0/260 - train_loss: 1.3504 - test_loss: 0.875033\n",
      "Epoch: 150/200 - train_loss: 0.3838 - test_loss: 0.592487\n",
      "Epoch: 60/120 - train_loss: 0.3975 - test_loss: 0.584796\n",
      "Epoch: 60/120 - train_loss: 0.4832 - test_loss: 0.634499\n",
      "Epoch: 99/100 - train_loss: 0.3930 - test_loss: 0.560148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:32:57,948]\u001b[0m Trial 24 finished with value: 62.68524665102904 and parameters: {'n layers': 3, 'Hidden size': 7, 'Learning rate': 0.0006618980364270635, 'Dropout rate': 0.2682224580277502, 'Epochs': 100}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/200 - train_loss: 0.4152 - test_loss: 0.643443\n",
      "Epoch:  0/120 - train_loss: 1.3304 - test_loss: 0.905301\n",
      "Epoch: 199/200 - train_loss: 0.4124 - test_loss: 0.614268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:33:44,178]\u001b[0m Trial 20 finished with value: 60.227738893532866 and parameters: {'n layers': 3, 'Hidden size': 209, 'Learning rate': 0.0005061338494658565, 'Dropout rate': 0.10684933583390409, 'Epochs': 400}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 199/200 - train_loss: 0.3959 - test_loss: 0.562169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:33:56,920]\u001b[0m Trial 21 finished with value: 60.89835244292649 and parameters: {'n layers': 5, 'Hidden size': 61, 'Learning rate': 0.00030116820608203624, 'Dropout rate': 0.20387458347100001, 'Epochs': 270}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 90/120 - train_loss: 0.4440 - test_loss: 0.614411\n",
      "Epoch: 60/120 - train_loss: 0.4472 - test_loss: 0.590529\n",
      "Epoch: 60/120 - train_loss: 0.4567 - test_loss: 0.629960\n",
      "Epoch: 60/120 - train_loss: 0.3955 - test_loss: 0.580758\n",
      "Epoch: 60/120 - train_loss: 0.4996 - test_loss: 0.603742\n",
      "Epoch: 60/120 - train_loss: 0.4123 - test_loss: 0.665207\n",
      "Epoch: 60/120 - train_loss: 0.5936 - test_loss: 0.670912\n",
      "Epoch: 199/200 - train_loss: 0.3984 - test_loss: 0.644303\n",
      "Epoch: 90/120 - train_loss: 0.4144 - test_loss: 0.613891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:34:16,227]\u001b[0m Trial 22 finished with value: 56.463258751266075 and parameters: {'n layers': 5, 'Hidden size': 13, 'Learning rate': 0.0067508643462943175, 'Dropout rate': 0.2646652413693725, 'Epochs': 210}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 30/120 - train_loss: 0.4487 - test_loss: 0.582289\n",
      "Epoch:  0/470 - train_loss: 1.5019 - test_loss: 1.035942\n",
      "Epoch: 95/380 - train_loss: 0.3859 - test_loss: 0.524885\n",
      "Epoch: 199/200 - train_loss: 0.3964 - test_loss: 0.614721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:01,007]\u001b[0m Trial 23 finished with value: 53.54388679343191 and parameters: {'n layers': 4, 'Hidden size': 76, 'Learning rate': 0.00310782495581388, 'Dropout rate': 0.7451818023213083, 'Epochs': 200}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/480 - train_loss: 0.9206 - test_loss: 0.815847\n",
      "Epoch: 65/260 - train_loss: 0.4017 - test_loss: 0.643143\n",
      "Epoch: 119/120 - train_loss: 0.3966 - test_loss: 0.592907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:19,371]\u001b[0m Trial 9 finished with value: 55.44142788060325 and parameters: {'n layers': 6, 'Hidden size': 12, 'Learning rate': 0.002021440878339776, 'Dropout rate': 0.621690615550958, 'Epochs': 310}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/480 - train_loss: 0.8813 - test_loss: 0.733071\n",
      "Epoch: 119/120 - train_loss: 0.3939 - test_loss: 0.575555\n",
      "Epoch: 90/120 - train_loss: 0.4058 - test_loss: 0.699715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:41,709]\u001b[0m Trial 6 finished with value: 64.82741826513383 and parameters: {'n layers': 6, 'Hidden size': 296, 'Learning rate': 0.0003946990363118002, 'Dropout rate': 0.7054593644860414, 'Epochs': 240}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 60/120 - train_loss: 0.3905 - test_loss: 0.613160\n",
      "Epoch:  0/460 - train_loss: 1.0418 - test_loss: 0.892414\n",
      "Epoch:  0/460 - train_loss: 0.8820 - test_loss: 0.717967\n",
      "Epoch:  0/460 - train_loss: 1.1719 - test_loss: 0.701713\n",
      "Epoch: 90/120 - train_loss: 0.3861 - test_loss: 0.594833\n",
      "Epoch: 130/260 - train_loss: 0.3837 - test_loss: 0.586467\n",
      "Epoch: 119/120 - train_loss: 0.4124 - test_loss: 0.573130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:37:21,844]\u001b[0m Trial 27 finished with value: 61.99309406033385 and parameters: {'n layers': 4, 'Hidden size': 20, 'Learning rate': 0.0010882685749466234, 'Dropout rate': 0.6569647219108882, 'Epochs': 120}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 119/120 - train_loss: 0.4388 - test_loss: 0.635621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:37:26,633]\u001b[0m Trial 14 finished with value: 54.025985058649745 and parameters: {'n layers': 3, 'Hidden size': 236, 'Learning rate': 0.008377281731851389, 'Dropout rate': 0.01602503042905161, 'Epochs': 360}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 190/380 - train_loss: 0.4082 - test_loss: 0.538306\n",
      "Epoch: 117/470 - train_loss: 0.3947 - test_loss: 0.615288\n",
      "Epoch:  0/480 - train_loss: 0.8759 - test_loss: 0.795835\n",
      "Epoch: 120/480 - train_loss: 0.4273 - test_loss: 0.692298\n",
      "Epoch:  0/480 - train_loss: 1.0941 - test_loss: 0.809932\n",
      "Epoch: 120/480 - train_loss: 0.3949 - test_loss: 0.605157\n",
      "Epoch: 115/460 - train_loss: 0.4177 - test_loss: 0.629308\n",
      "Epoch: 195/260 - train_loss: 0.3998 - test_loss: 0.624058\n",
      "Epoch: 285/380 - train_loss: 0.4061 - test_loss: 0.616845\n",
      "Epoch: 115/460 - train_loss: 0.4075 - test_loss: 0.578030\n",
      "Epoch: 234/470 - train_loss: 0.3930 - test_loss: 0.569370\n",
      "Epoch: 240/480 - train_loss: 0.4047 - test_loss: 0.589217\n",
      "Epoch: 90/120 - train_loss: 0.3875 - test_loss: 0.567665\n",
      "Epoch: 120/480 - train_loss: 0.3926 - test_loss: 0.652155\n",
      "Epoch: 259/260 - train_loss: 0.4049 - test_loss: 0.574412\n",
      "Epoch: 240/480 - train_loss: 0.3819 - test_loss: 0.604576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:40:25,808]\u001b[0m Trial 26 finished with value: 60.652191434576174 and parameters: {'n layers': 3, 'Hidden size': 20, 'Learning rate': 0.0016341683066010064, 'Dropout rate': 0.3148766823045718, 'Epochs': 260}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 230/460 - train_loss: 0.3840 - test_loss: 0.600639\n",
      "Epoch:  0/480 - train_loss: 1.0902 - test_loss: 0.855995\n",
      "Epoch: 379/380 - train_loss: 0.4194 - test_loss: 0.607000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:41:36,675]\u001b[0m Trial 25 finished with value: 55.64604533348707 and parameters: {'n layers': 3, 'Hidden size': 41, 'Learning rate': 0.002657658812322784, 'Dropout rate': 0.12288788470270347, 'Epochs': 380}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 115/460 - train_loss: 0.4089 - test_loss: 0.582360\n",
      "Epoch: 351/470 - train_loss: 0.4032 - test_loss: 0.580264\n",
      "Epoch: 90/120 - train_loss: 0.5235 - test_loss: 0.613342\n",
      "Epoch:  0/490 - train_loss: 1.4088 - test_loss: 0.757807\n",
      "Epoch: 360/480 - train_loss: 0.4444 - test_loss: 0.549296\n",
      "Epoch: 360/480 - train_loss: 0.3950 - test_loss: 0.561620\n",
      "Epoch: 240/480 - train_loss: 0.3954 - test_loss: 0.636325\n",
      "Epoch: 345/460 - train_loss: 0.3909 - test_loss: 0.633894\n",
      "Epoch: 230/460 - train_loss: 0.3850 - test_loss: 0.608013\n",
      "Epoch: 120/480 - train_loss: 0.3945 - test_loss: 0.592172\n",
      "Epoch: 468/470 - train_loss: 0.3889 - test_loss: 0.601007\n",
      "Epoch: 469/470 - train_loss: 0.4231 - test_loss: 0.649320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:43:43,340]\u001b[0m Trial 28 finished with value: 59.331132460275995 and parameters: {'n layers': 4, 'Hidden size': 173, 'Learning rate': 0.0014935200520171737, 'Dropout rate': 0.13776532204984196, 'Epochs': 210}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 119/120 - train_loss: 0.3889 - test_loss: 0.638020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:43:49,085]\u001b[0m Trial 2 finished with value: 56.216567905843114 and parameters: {'n layers': 4, 'Hidden size': 13, 'Learning rate': 0.005350317805847308, 'Dropout rate': 0.5892547844905761, 'Epochs': 210}. Best is trial 11 with value: 52.787847582500056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 479/480 - train_loss: 0.4003 - test_loss: 0.607039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:44:24,388]\u001b[0m Trial 29 finished with value: 52.48480400416952 and parameters: {'n layers': 6, 'Hidden size': 47, 'Learning rate': 0.008922142954424341, 'Dropout rate': 0.550395776622815, 'Epochs': 480}. Best is trial 29 with value: 52.48480400416952.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/500 - train_loss: 1.0088 - test_loss: 0.876546\n",
      "Epoch: 479/480 - train_loss: 0.3961 - test_loss: 0.585084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:45:03,123]\u001b[0m Trial 30 finished with value: 53.27638927116406 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.009851042097926685, 'Dropout rate': 0.6917718264359131, 'Epochs': 470}. Best is trial 29 with value: 52.48480400416952.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/500 - train_loss: 0.8977 - test_loss: 0.820185\n",
      "Epoch: 122/490 - train_loss: 0.3873 - test_loss: 0.576841\n",
      "Epoch: 90/120 - train_loss: 0.4769 - test_loss: 0.581987\n",
      "Epoch: 90/120 - train_loss: 0.4081 - test_loss: 0.602432\n",
      "Epoch: 90/120 - train_loss: 0.4265 - test_loss: 0.611726\n",
      "Epoch: 459/460 - train_loss: 0.3891 - test_loss: 0.582090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:45:20,063]\u001b[0m Trial 31 finished with value: 51.339242829673196 and parameters: {'n layers': 6, 'Hidden size': 57, 'Learning rate': 0.00891592363792488, 'Dropout rate': 0.5935920288537133, 'Epochs': 480}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 360/480 - train_loss: 0.3954 - test_loss: 0.606307\n",
      "Epoch: 119/120 - train_loss: 0.4705 - test_loss: 0.591228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:45:45,864]\u001b[0m Trial 4 finished with value: 63.82167155451469 and parameters: {'n layers': 6, 'Hidden size': 130, 'Learning rate': 0.0002232205269805427, 'Dropout rate': 0.6594571768670721, 'Epochs': 400}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/500 - train_loss: 0.9549 - test_loss: 0.784101\n",
      "Epoch: 120/480 - train_loss: 0.3990 - test_loss: 0.601729\n",
      "Epoch: 230/460 - train_loss: 0.3855 - test_loss: 0.553130\n",
      "Epoch:  0/500 - train_loss: 1.0173 - test_loss: 0.779311\n",
      "Epoch:  0/500 - train_loss: 1.3072 - test_loss: 0.744021\n",
      "Epoch: 345/460 - train_loss: 0.3899 - test_loss: 0.586747\n",
      "Epoch: 240/480 - train_loss: 0.4086 - test_loss: 0.647388\n",
      "Epoch:  0/500 - train_loss: 0.9304 - test_loss: 0.823030\n",
      "Epoch: 125/500 - train_loss: 0.3930 - test_loss: 0.570067\n",
      "Epoch: 244/490 - train_loss: 0.3881 - test_loss: 0.691781\n",
      "Epoch: 479/480 - train_loss: 0.4159 - test_loss: 0.593107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:48:26,111]\u001b[0m Trial 34 finished with value: 53.36704416433148 and parameters: {'n layers': 4, 'Hidden size': 64, 'Learning rate': 0.008712651373965062, 'Dropout rate': 0.522595310905422, 'Epochs': 470}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 125/500 - train_loss: 0.4152 - test_loss: 0.532311\n",
      "Epoch: 125/500 - train_loss: 0.4072 - test_loss: 0.632792\n",
      "Epoch:  0/490 - train_loss: 1.4862 - test_loss: 0.837013\n",
      "Epoch: 125/500 - train_loss: 0.3827 - test_loss: 0.625866\n",
      "Epoch: 250/500 - train_loss: 0.4020 - test_loss: 0.550653\n",
      "Epoch: 360/480 - train_loss: 0.3974 - test_loss: 0.620599\n",
      "Epoch: 459/460 - train_loss: 0.4019 - test_loss: 0.643728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:50:46,889]\u001b[0m Trial 32 finished with value: 56.64315970378644 and parameters: {'n layers': 4, 'Hidden size': 63, 'Learning rate': 0.008769565853729545, 'Dropout rate': 0.5323794569225122, 'Epochs': 480}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 250/500 - train_loss: 0.4055 - test_loss: 0.611642\n",
      "Epoch: 366/490 - train_loss: 0.3943 - test_loss: 0.624878\n",
      "Epoch:  0/500 - train_loss: 0.9329 - test_loss: 0.785982\n",
      "Epoch: 250/500 - train_loss: 0.3852 - test_loss: 0.642525\n",
      "Epoch: 122/490 - train_loss: 0.3983 - test_loss: 0.553125\n",
      "Epoch: 345/460 - train_loss: 0.4052 - test_loss: 0.581693\n",
      "Epoch: 250/500 - train_loss: 0.3916 - test_loss: 0.532431\n",
      "Epoch: 375/500 - train_loss: 0.3818 - test_loss: 0.614167\n",
      "Epoch: 375/500 - train_loss: 0.3948 - test_loss: 0.603621\n",
      "Epoch: 479/480 - train_loss: 0.4311 - test_loss: 0.604165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:53:39,199]\u001b[0m Trial 36 finished with value: 57.16171899017254 and parameters: {'n layers': 4, 'Hidden size': 55, 'Learning rate': 0.008302551251044892, 'Dropout rate': 0.5030353884835812, 'Epochs': 480}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 375/500 - train_loss: 0.4032 - test_loss: 0.619278\n",
      "Epoch: 488/490 - train_loss: 0.3924 - test_loss: 0.620334\n",
      "Epoch: 489/490 - train_loss: 0.3925 - test_loss: 0.562857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:54:09,121]\u001b[0m Trial 37 finished with value: 54.6083182826269 and parameters: {'n layers': 4, 'Hidden size': 80, 'Learning rate': 0.0065588871271720205, 'Dropout rate': 0.5425728898528391, 'Epochs': 490}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/440 - train_loss: 1.0096 - test_loss: 0.859520\n",
      "Epoch: 244/490 - train_loss: 0.4075 - test_loss: 0.496108\n",
      "Epoch: 375/500 - train_loss: 0.4012 - test_loss: 0.648613\n",
      "Epoch:  0/440 - train_loss: 1.0799 - test_loss: 0.755283\n",
      "Epoch: 499/500 - train_loss: 0.3889 - test_loss: 0.631566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:55:39,885]\u001b[0m Trial 38 finished with value: 55.95212466914768 and parameters: {'n layers': 4, 'Hidden size': 88, 'Learning rate': 0.009848689869042221, 'Dropout rate': 0.535512892974014, 'Epochs': 470}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 240/480 - train_loss: 0.3967 - test_loss: 0.574164\n",
      "Epoch: 125/500 - train_loss: 0.3974 - test_loss: 0.591528\n",
      "Epoch:  0/440 - train_loss: 1.2061 - test_loss: 0.928965\n",
      "Epoch: 499/500 - train_loss: 0.3860 - test_loss: 0.562731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:56:26,896]\u001b[0m Trial 40 finished with value: 57.00206313906069 and parameters: {'n layers': 6, 'Hidden size': 86, 'Learning rate': 0.006610174404687891, 'Dropout rate': 0.5129477244924198, 'Epochs': 500}. Best is trial 31 with value: 51.339242829673196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/440 - train_loss: 0.8607 - test_loss: 0.763186\n",
      "Epoch: 499/500 - train_loss: 0.4245 - test_loss: 0.597187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:57:08,626]\u001b[0m Trial 41 finished with value: 48.49993492717417 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.009897755871636804, 'Dropout rate': 0.5059107337645553, 'Epochs': 490}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 459/460 - train_loss: 0.4342 - test_loss: 0.630438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:57:13,046]\u001b[0m Trial 33 finished with value: 51.899024264887125 and parameters: {'n layers': 4, 'Hidden size': 64, 'Learning rate': 0.009135752443053136, 'Dropout rate': 0.5211800423301448, 'Epochs': 460}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 366/490 - train_loss: 0.3993 - test_loss: 0.681983\n",
      "Epoch: 499/500 - train_loss: 0.3870 - test_loss: 0.589639\n",
      "Epoch: 110/440 - train_loss: 0.4236 - test_loss: 0.589445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:57:32,700]\u001b[0m Trial 42 finished with value: 56.7387164600531 and parameters: {'n layers': 6, 'Hidden size': 40, 'Learning rate': 0.0063001636641731, 'Dropout rate': 0.5109802433889925, 'Epochs': 500}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110/440 - train_loss: 0.4402 - test_loss: 0.651083\n",
      "Epoch: 125/500 - train_loss: 0.4166 - test_loss: 0.543009\n",
      "Epoch: 110/440 - train_loss: 0.3975 - test_loss: 0.594731\n",
      "Epoch: 110/440 - train_loss: 0.4085 - test_loss: 0.762800\n",
      "Epoch: 250/500 - train_loss: 0.3941 - test_loss: 0.586858\n",
      "Epoch: 119/120 - train_loss: 0.3936 - test_loss: 0.566582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:59:37,918]\u001b[0m Trial 18 finished with value: 61.22953764476916 and parameters: {'n layers': 5, 'Hidden size': 16, 'Learning rate': 0.0009955865882564348, 'Dropout rate': 0.5222256538892796, 'Epochs': 410}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 488/490 - train_loss: 0.3880 - test_loss: 0.588425\n",
      "Epoch: 220/440 - train_loss: 0.4000 - test_loss: 0.637783\n",
      "Epoch: 489/490 - train_loss: 0.4174 - test_loss: 0.602607\n",
      "Epoch: 360/480 - train_loss: 0.3953 - test_loss: 0.630459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:59:48,686]\u001b[0m Trial 44 finished with value: 52.93437464669419 and parameters: {'n layers': 6, 'Hidden size': 39, 'Learning rate': 0.00606879565021261, 'Dropout rate': 0.48210726597046627, 'Epochs': 490}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220/440 - train_loss: 0.3996 - test_loss: 0.732735\n",
      "Epoch: 220/440 - train_loss: 0.3958 - test_loss: 0.667443\n",
      "Epoch: 119/120 - train_loss: 0.3996 - test_loss: 0.641043\n",
      "Epoch: 119/120 - train_loss: 0.4198 - test_loss: 0.543249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:00:59,957]\u001b[0m Trial 16 finished with value: 59.897734306830024 and parameters: {'n layers': 6, 'Hidden size': 24, 'Learning rate': 0.00043810090947051677, 'Dropout rate': 0.2248359833010295, 'Epochs': 450}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 03:00:59,973]\u001b[0m Trial 10 finished with value: 55.91855051487088 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.0004450881250988619, 'Dropout rate': 0.7325992215816836, 'Epochs': 170}. Best is trial 41 with value: 48.49993492717417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/120 - train_loss: 0.4196 - test_loss: 0.587741\n",
      "Epoch: 60/120 - train_loss: 0.3957 - test_loss: 0.563688\n",
      "Epoch: 60/120 - train_loss: 0.8524 - test_loss: 0.682918\n",
      "Epoch: 220/440 - train_loss: 0.4443 - test_loss: 0.607838\n",
      "Epoch: 375/500 - train_loss: 0.3986 - test_loss: 0.659891\n",
      "Epoch: 30/120 - train_loss: 0.4152 - test_loss: 0.553758\n",
      "Epoch: 330/440 - train_loss: 0.4140 - test_loss: 0.574979\n",
      "Epoch: 330/440 - train_loss: 0.4081 - test_loss: 0.616242\n",
      "Epoch: 125/500 - train_loss: 0.4005 - test_loss: 0.657114\n",
      "Epoch: 250/500 - train_loss: 0.4135 - test_loss: 0.600718\n",
      "Epoch: 330/440 - train_loss: 0.3858 - test_loss: 0.632781\n",
      "Epoch: 479/480 - train_loss: 0.3941 - test_loss: 0.568228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:02:38,510]\u001b[0m Trial 35 finished with value: 48.13259650028406 and parameters: {'n layers': 4, 'Hidden size': 61, 'Learning rate': 0.00991399424990794, 'Dropout rate': 0.4994707258181685, 'Epochs': 480}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330/440 - train_loss: 0.3888 - test_loss: 0.576142\n",
      "Epoch: 90/120 - train_loss: 0.3983 - test_loss: 0.608297\n",
      "Epoch: 90/120 - train_loss: 0.7814 - test_loss: 0.676297\n",
      "Epoch: 439/440 - train_loss: 0.3950 - test_loss: 0.605049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:00,483]\u001b[0m Trial 47 finished with value: 56.385322024324374 and parameters: {'n layers': 6, 'Hidden size': 36, 'Learning rate': 0.004806139995108461, 'Dropout rate': 0.4352970815408922, 'Epochs': 440}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 439/440 - train_loss: 0.4033 - test_loss: 0.674277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:11,149]\u001b[0m Trial 46 finished with value: 53.31013752329462 and parameters: {'n layers': 6, 'Hidden size': 33, 'Learning rate': 0.005726742400798988, 'Dropout rate': 0.4170574463609653, 'Epochs': 500}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/120 - train_loss: 0.4094 - test_loss: 0.602756\n",
      "Epoch: 90/120 - train_loss: 0.3981 - test_loss: 0.678949\n",
      "Epoch: 499/500 - train_loss: 0.4072 - test_loss: 0.596797\n",
      "Epoch: 119/120 - train_loss: 0.3959 - test_loss: 0.617814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:22,718]\u001b[0m Trial 45 finished with value: 56.382369395402286 and parameters: {'n layers': 6, 'Hidden size': 34, 'Learning rate': 0.0051007759294076326, 'Dropout rate': 0.4589471078391436, 'Epochs': 500}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 03:04:23,332]\u001b[0m Trial 7 finished with value: 66.20524384536976 and parameters: {'n layers': 6, 'Hidden size': 16, 'Learning rate': 0.0006794788943703221, 'Dropout rate': 0.21612657233680344, 'Epochs': 110}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 439/440 - train_loss: 0.3975 - test_loss: 0.636868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:35,117]\u001b[0m Trial 48 finished with value: 53.990680067575 and parameters: {'n layers': 6, 'Hidden size': 39, 'Learning rate': 0.00507439226614785, 'Dropout rate': 0.44023141444385094, 'Epochs': 440}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119/120 - train_loss: 0.6813 - test_loss: 0.665771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:41,874]\u001b[0m Trial 17 finished with value: 62.140990296636055 and parameters: {'n layers': 4, 'Hidden size': 210, 'Learning rate': 0.00010145117219232342, 'Dropout rate': 0.2794559834450259, 'Epochs': 160}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119/120 - train_loss: 0.4122 - test_loss: 0.650252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:53,178]\u001b[0m Trial 0 finished with value: 56.52498732142061 and parameters: {'n layers': 3, 'Hidden size': 92, 'Learning rate': 0.0017300106350474176, 'Dropout rate': 0.6067262701541284, 'Epochs': 430}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/120 - train_loss: 0.4100 - test_loss: 0.631796\n",
      "Epoch: 60/120 - train_loss: 0.3978 - test_loss: 0.593731\n",
      "Epoch: 375/500 - train_loss: 0.3914 - test_loss: 0.605634\n",
      "Epoch: 439/440 - train_loss: 0.3893 - test_loss: 0.610655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:05:02,102]\u001b[0m Trial 49 finished with value: 57.948566132867704 and parameters: {'n layers': 5, 'Hidden size': 33, 'Learning rate': 0.004969077503940356, 'Dropout rate': 0.7978660263400452, 'Epochs': 440}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/500 - train_loss: 0.4392 - test_loss: 0.611128\n",
      "Epoch: 119/120 - train_loss: 0.3912 - test_loss: 0.583839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:05:14,914]\u001b[0m Trial 13 finished with value: 60.190387680526065 and parameters: {'n layers': 4, 'Hidden size': 285, 'Learning rate': 0.0006946720968645078, 'Dropout rate': 0.31099256506913453, 'Epochs': 420}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/120 - train_loss: 0.3940 - test_loss: 0.566421\n",
      "Epoch: 119/120 - train_loss: 0.3924 - test_loss: 0.634278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:05:30,070]\u001b[0m Trial 1 finished with value: 60.681196250091375 and parameters: {'n layers': 5, 'Hidden size': 46, 'Learning rate': 0.0012749844170617175, 'Dropout rate': 0.01565953697975292, 'Epochs': 360}. Best is trial 35 with value: 48.13259650028406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499/500 - train_loss: 0.3926 - test_loss: 0.519359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:05:48,027]\u001b[0m Trial 39 finished with value: 38.212871034322404 and parameters: {'n layers': 6, 'Hidden size': 88, 'Learning rate': 0.009134818678506232, 'Dropout rate': 0.5147732102057123, 'Epochs': 500}. Best is trial 39 with value: 38.212871034322404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 375/500 - train_loss: 0.3877 - test_loss: 0.586893\n",
      "Epoch: 499/500 - train_loss: 0.4023 - test_loss: 0.612146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:06:22,430]\u001b[0m Trial 43 finished with value: 57.351255474949966 and parameters: {'n layers': 6, 'Hidden size': 41, 'Learning rate': 0.006609535915571236, 'Dropout rate': 0.5219164554990016, 'Epochs': 500}. Best is trial 39 with value: 38.212871034322404.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 03:06:22,445]\u001b[0m A new study created in memory with name: no-name-9dde5682-e5f8-4b71-82ab-c884aec2eafc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Tiền Giang\n",
      "  Value:  38.212871034322404\n",
      "optimize result of city: Tiền Giang\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookbacklookback 3\n",
      " lookback 3\n",
      "3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/450 - train_loss: 1.2012 - test_loss: 0.871473\n",
      "Epoch:  0/450 - train_loss: 1.0765 - test_loss: 0.806182\n",
      "Epoch:  0/450 - train_loss: 1.5744 - test_loss: 1.394253\n",
      "Epoch:  0/450 - train_loss: 1.1421 - test_loss: 0.848683\n",
      "Epoch:  0/450 - train_loss: 0.9899 - test_loss: 0.634030\n",
      "Epoch:  0/450 - train_loss: 0.7914 - test_loss: 0.583527\n",
      "Epoch:  0/450 - train_loss: 1.2613 - test_loss: 0.736559\n",
      "Epoch:  0/450 - train_loss: 0.8420 - test_loss: 0.709557\n",
      "Epoch:  0/450 - train_loss: 1.1777 - test_loss: 1.004093\n",
      "Epoch:  0/450 - train_loss: 1.5716 - test_loss: 2.240138\n",
      "Epoch:  0/450 - train_loss: 1.3165 - test_loss: 1.520381\n",
      "Epoch:  0/450 - train_loss: 1.2151 - test_loss: 1.311261\n",
      "Epoch:  0/450 - train_loss: 1.7011 - test_loss: 1.970776Epoch:  0/450 - train_loss: 0.9898 - test_loss: 0.732217\n",
      "\n",
      "Epoch:  0/450 - train_loss: 0.9690 - test_loss: 0.756560\n",
      "Epoch:  0/450 - train_loss: 0.9978 - test_loss: 0.720496\n",
      "Epoch:  0/450 - train_loss: 1.1433 - test_loss: 0.689995\n",
      "Epoch:  0/450 - train_loss: 1.0099 - test_loss: 1.263906\n",
      "Epoch:  0/450 - train_loss: 1.0292 - test_loss: 0.969850\n",
      "Epoch:  0/450 - train_loss: 0.9200 - test_loss: 0.692114\n",
      "Epoch: 112/450 - train_loss: 0.1752 - test_loss: 0.123081\n",
      "Epoch: 112/450 - train_loss: 0.2001 - test_loss: 0.147123\n",
      "Epoch: 112/450 - train_loss: 0.1540 - test_loss: 0.079958\n",
      "Epoch: 112/450 - train_loss: 0.1537 - test_loss: 0.085615\n",
      "Epoch: 112/450 - train_loss: 0.1532 - test_loss: 0.079466\n",
      "Epoch: 112/450 - train_loss: 0.2219 - test_loss: 0.084484\n",
      "Epoch: 112/450 - train_loss: 0.1549 - test_loss: 0.084203\n",
      "Epoch: 224/450 - train_loss: 0.1579 - test_loss: 0.082587\n",
      "Epoch: 224/450 - train_loss: 0.3031 - test_loss: 0.090402\n",
      "Epoch: 224/450 - train_loss: 0.1534 - test_loss: 0.088245\n",
      "Epoch: 112/450 - train_loss: 0.2672 - test_loss: 0.235491\n",
      "Epoch: 224/450 - train_loss: 0.1530 - test_loss: 0.084591\n",
      "Epoch: 224/450 - train_loss: 0.1548 - test_loss: 0.081960\n",
      "Epoch: 336/450 - train_loss: 0.1542 - test_loss: 0.087405\n",
      "Epoch: 224/450 - train_loss: 0.1537 - test_loss: 0.084781\n",
      "Epoch: 336/450 - train_loss: 0.1543 - test_loss: 0.086272\n",
      "Epoch: 336/450 - train_loss: 0.1531 - test_loss: 0.085267\n",
      "Epoch: 336/450 - train_loss: 0.1626 - test_loss: 0.084660\n",
      "Epoch: 224/450 - train_loss: 0.1535 - test_loss: 0.082583\n",
      "Epoch: 112/450 - train_loss: 0.1546 - test_loss: 0.084618\n",
      "Epoch: 336/450 - train_loss: 0.1547 - test_loss: 0.080378\n",
      "Epoch: 448/450 - train_loss: 0.1525 - test_loss: 0.082675\n",
      "Epoch: 449/450 - train_loss: 0.1616 - test_loss: 0.083696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:19:17,667]\u001b[0m Trial 11 finished with value: 21.830557543029823 and parameters: {'n layers': 3, 'Hidden size': 24, 'Learning rate': 0.0005096909350018998, 'Dropout rate': 0.5683922750440938, 'Epochs': 370}. Best is trial 11 with value: 21.830557543029823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 448/450 - train_loss: 0.1619 - test_loss: 0.084598\n",
      "Epoch: 449/450 - train_loss: 0.1603 - test_loss: 0.089405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:19:35,731]\u001b[0m Trial 16 finished with value: 23.968464338272707 and parameters: {'n layers': 4, 'Hidden size': 273, 'Learning rate': 0.00044730529278578856, 'Dropout rate': 0.061806493400815475, 'Epochs': 330}. Best is trial 11 with value: 21.830557543029823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 448/450 - train_loss: 0.1530 - test_loss: 0.084279\n",
      "Epoch: 449/450 - train_loss: 0.1531 - test_loss: 0.081400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:20:02,727]\u001b[0m Trial 12 finished with value: 21.86864316989245 and parameters: {'n layers': 5, 'Hidden size': 68, 'Learning rate': 0.003241938202896938, 'Dropout rate': 0.3909808937832427, 'Epochs': 290}. Best is trial 11 with value: 21.830557543029823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/290 - train_loss: 0.9298 - test_loss: 0.637743\n",
      "Epoch: 224/450 - train_loss: 0.1604 - test_loss: 0.097536\n",
      "Epoch: 336/450 - train_loss: 0.1551 - test_loss: 0.077143\n",
      "Epoch:  0/210 - train_loss: 0.9743 - test_loss: 0.732298\n",
      "Epoch:  0/210 - train_loss: 1.1638 - test_loss: 0.859077\n",
      "Epoch: 448/450 - train_loss: 0.1529 - test_loss: 0.079560\n",
      "Epoch: 449/450 - train_loss: 0.1537 - test_loss: 0.083444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:20:54,342]\u001b[0m Trial 17 finished with value: 10.000598787948489 and parameters: {'n layers': 4, 'Hidden size': 117, 'Learning rate': 0.005145692239868131, 'Dropout rate': 0.5237819514623158, 'Epochs': 180}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/430 - train_loss: 1.0440 - test_loss: 0.634295\n",
      "Epoch: 336/450 - train_loss: 0.1537 - test_loss: 0.078307\n",
      "Epoch: 52/210 - train_loss: 0.1675 - test_loss: 0.110881\n",
      "Epoch: 72/290 - train_loss: 0.1551 - test_loss: 0.081186\n",
      "Epoch: 448/450 - train_loss: 0.2169 - test_loss: 0.075770\n",
      "Epoch: 449/450 - train_loss: 0.1551 - test_loss: 0.100192\n",
      "Epoch: 52/210 - train_loss: 0.7082 - test_loss: 0.683420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:21:53,672]\u001b[0m Trial 19 finished with value: 22.01484217055126 and parameters: {'n layers': 3, 'Hidden size': 287, 'Learning rate': 0.0017928106805522555, 'Dropout rate': 0.08037686259018854, 'Epochs': 450}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 112/450 - train_loss: 0.1555 - test_loss: 0.085019\n",
      "Epoch:  0/130 - train_loss: 1.0902 - test_loss: 0.713913\n",
      "Epoch: 104/210 - train_loss: 0.1571 - test_loss: 0.093786\n",
      "Epoch: 104/210 - train_loss: 0.5565 - test_loss: 0.517889\n",
      "Epoch: 448/450 - train_loss: 0.1568 - test_loss: 0.080770\n",
      "Epoch: 449/450 - train_loss: 0.1538 - test_loss: 0.078992\n",
      "Epoch: 32/130 - train_loss: 0.1542 - test_loss: 0.079709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:23:02,307]\u001b[0m Trial 1 finished with value: 20.546427283779376 and parameters: {'n layers': 3, 'Hidden size': 237, 'Learning rate': 0.00245153334242447, 'Dropout rate': 0.43616563678523185, 'Epochs': 290}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 144/290 - train_loss: 0.1571 - test_loss: 0.081776\n",
      "Epoch: 224/450 - train_loss: 0.2136 - test_loss: 0.084491\n",
      "Epoch: 107/430 - train_loss: 0.1666 - test_loss: 0.085884\n",
      "Epoch: 156/210 - train_loss: 0.1568 - test_loss: 0.078631\n",
      "Epoch: 336/450 - train_loss: 0.3109 - test_loss: 0.084569\n",
      "Epoch: 64/130 - train_loss: 0.1628 - test_loss: 0.089375\n",
      "Epoch:  0/260 - train_loss: 1.0688 - test_loss: 0.766272\n",
      "Epoch: 156/210 - train_loss: 0.4267 - test_loss: 0.393542\n",
      "Epoch: 96/130 - train_loss: 0.1571 - test_loss: 0.085904\n",
      "Epoch: 448/450 - train_loss: 0.3215 - test_loss: 0.088769\n",
      "Epoch: 449/450 - train_loss: 0.1659 - test_loss: 0.122357\n",
      "Epoch: 216/290 - train_loss: 0.1536 - test_loss: 0.082400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:25:01,273]\u001b[0m Trial 15 finished with value: 18.894979742527614 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.008806441640388742, 'Dropout rate': 0.723832583693942, 'Epochs': 190}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 208/210 - train_loss: 0.1543 - test_loss: 0.085292\n",
      "Epoch: 209/210 - train_loss: 0.1540 - test_loss: 0.082042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:25:26,704]\u001b[0m Trial 21 finished with value: 10.240058940954365 and parameters: {'n layers': 3, 'Hidden size': 12, 'Learning rate': 0.0011352279608196013, 'Dropout rate': 0.5080888953782443, 'Epochs': 290}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 208/210 - train_loss: 0.3519 - test_loss: 0.316741\n",
      "Epoch: 209/210 - train_loss: 0.3499 - test_loss: 0.315230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:26:22,694]\u001b[0m Trial 22 finished with value: 31.321529957019113 and parameters: {'n layers': 4, 'Hidden size': 6, 'Learning rate': 0.00012140037683830672, 'Dropout rate': 0.41836761124552835, 'Epochs': 210}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 128/130 - train_loss: 0.1613 - test_loss: 0.096025\n",
      "Epoch: 129/130 - train_loss: 0.1564 - test_loss: 0.098724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:26:47,709]\u001b[0m Trial 24 finished with value: 24.734663878970323 and parameters: {'n layers': 4, 'Hidden size': 17, 'Learning rate': 0.005377487747034617, 'Dropout rate': 0.20985336725248854, 'Epochs': 130}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 65/260 - train_loss: 0.6296 - test_loss: 0.583674\n",
      "Epoch:  0/110 - train_loss: 0.8378 - test_loss: 0.623409\n",
      "Epoch:  0/110 - train_loss: 0.8357 - test_loss: 0.678114\n",
      "Epoch: 214/430 - train_loss: 0.1549 - test_loss: 0.089304\n",
      "Epoch:  0/110 - train_loss: 0.8643 - test_loss: 0.619920\n",
      "Epoch: 27/110 - train_loss: 0.1663 - test_loss: 0.086793\n",
      "Epoch:  0/110 - train_loss: 0.8188 - test_loss: 0.571276\n",
      "Epoch: 288/290 - train_loss: 0.1579 - test_loss: 0.079589\n",
      "Epoch: 289/290 - train_loss: 0.1568 - test_loss: 0.083876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:29:42,168]\u001b[0m Trial 20 finished with value: 14.864405127669528 and parameters: {'n layers': 4, 'Hidden size': 96, 'Learning rate': 0.006287711345607108, 'Dropout rate': 0.7838338889488908, 'Epochs': 180}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 27/110 - train_loss: 0.3175 - test_loss: 0.279247\n",
      "Epoch: 27/110 - train_loss: 0.1572 - test_loss: 0.089528\n",
      "Epoch: 27/110 - train_loss: 0.1709 - test_loss: 0.091249\n",
      "Epoch: 54/110 - train_loss: 0.1543 - test_loss: 0.075796\n",
      "Epoch: 54/110 - train_loss: 0.1743 - test_loss: 0.117180\n",
      "Epoch: 448/450 - train_loss: 0.1573 - test_loss: 0.082985\n",
      "Epoch: 130/260 - train_loss: 0.5797 - test_loss: 0.482750\n",
      "Epoch: 449/450 - train_loss: 0.1582 - test_loss: 0.084150\n",
      "Epoch: 112/450 - train_loss: 0.1554 - test_loss: 0.085248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:31:13,251]\u001b[0m Trial 4 finished with value: 25.399029773918823 and parameters: {'n layers': 6, 'Hidden size': 17, 'Learning rate': 0.00030198648404804353, 'Dropout rate': 0.3739035759085522, 'Epochs': 430}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 336/450 - train_loss: 0.1547 - test_loss: 0.092972\n",
      "Epoch:  0/100 - train_loss: 1.0247 - test_loss: 0.917947\n",
      "Epoch: 54/110 - train_loss: 0.1561 - test_loss: 0.083563\n",
      "Epoch: 54/110 - train_loss: 0.1563 - test_loss: 0.079661\n",
      "Epoch: 81/110 - train_loss: 0.1540 - test_loss: 0.079586\n",
      "Epoch: 81/110 - train_loss: 0.1555 - test_loss: 0.088551\n",
      "Epoch: 224/450 - train_loss: 0.1548 - test_loss: 0.087708\n",
      "Epoch: 25/100 - train_loss: 0.3482 - test_loss: 0.310985\n",
      "Epoch: 81/110 - train_loss: 0.1543 - test_loss: 0.081546\n",
      "Epoch:  0/100 - train_loss: 1.3143 - test_loss: 1.072750\n",
      "Epoch: 81/110 - train_loss: 0.1573 - test_loss: 0.076429\n",
      "Epoch: 108/110 - train_loss: 0.1557 - test_loss: 0.079686\n",
      "Epoch: 109/110 - train_loss: 0.1551 - test_loss: 0.078347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:33:27,506]\u001b[0m Trial 27 finished with value: 21.20327827940864 and parameters: {'n layers': 5, 'Hidden size': 32, 'Learning rate': 0.0011043554665333454, 'Dropout rate': 0.6587100781956392, 'Epochs': 390}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/100 - train_loss: 0.1927 - test_loss: 0.141572\n",
      "Epoch: 108/110 - train_loss: 0.1549 - test_loss: 0.082430\n",
      "Epoch: 109/110 - train_loss: 0.1546 - test_loss: 0.082819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:33:45,470]\u001b[0m Trial 26 finished with value: 17.226423720535028 and parameters: {'n layers': 3, 'Hidden size': 18, 'Learning rate': 0.004898725202755062, 'Dropout rate': 0.6328973495922743, 'Epochs': 450}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 321/430 - train_loss: 0.1564 - test_loss: 0.076366\n",
      "Epoch: 108/110 - train_loss: 0.1538 - test_loss: 0.091197\n",
      "Epoch: 109/110 - train_loss: 0.1604 - test_loss: 0.087647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:34:21,421]\u001b[0m Trial 28 finished with value: 13.577486237907076 and parameters: {'n layers': 5, 'Hidden size': 140, 'Learning rate': 0.005134209229348241, 'Dropout rate': 0.5454529415382838, 'Epochs': 260}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 195/260 - train_loss: 0.4257 - test_loss: 0.395255\n",
      "Epoch: 25/100 - train_loss: 0.3247 - test_loss: 0.267497\n",
      "Epoch: 108/110 - train_loss: 0.1541 - test_loss: 0.078003\n",
      "Epoch: 109/110 - train_loss: 0.1535 - test_loss: 0.084807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:35:10,280]\u001b[0m Trial 29 finished with value: 21.844973103567067 and parameters: {'n layers': 6, 'Hidden size': 94, 'Learning rate': 0.009088994476419268, 'Dropout rate': 0.7915544968573814, 'Epochs': 110}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 75/100 - train_loss: 0.1661 - test_loss: 0.100383\n",
      "Epoch: 112/450 - train_loss: 0.1536 - test_loss: 0.077355\n",
      "Epoch:  0/240 - train_loss: 1.1954 - test_loss: 1.022639\n",
      "Epoch:  0/240 - train_loss: 1.2937 - test_loss: 1.228040\n",
      "Epoch: 50/100 - train_loss: 0.1774 - test_loss: 0.115674\n",
      "Epoch: 99/100 - train_loss: 0.1536 - test_loss: 0.082110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:37:40,598]\u001b[0m Trial 30 finished with value: 22.684048446537673 and parameters: {'n layers': 6, 'Hidden size': 15, 'Learning rate': 0.001010001205662267, 'Dropout rate': 0.5859096287042604, 'Epochs': 100}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/240 - train_loss: 1.3659 - test_loss: 0.839069\n",
      "Epoch:  0/240 - train_loss: 1.4665 - test_loss: 1.291627\n",
      "Epoch: 75/100 - train_loss: 0.1637 - test_loss: 0.085528\n",
      "Epoch: 259/260 - train_loss: 0.3483 - test_loss: 0.320221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:39:26,464]\u001b[0m Trial 25 finished with value: 26.63099787508591 and parameters: {'n layers': 3, 'Hidden size': 186, 'Learning rate': 0.00010018735847601163, 'Dropout rate': 0.22933030643769267, 'Epochs': 260}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/500 - train_loss: 1.2481 - test_loss: 1.261891\n",
      "Epoch: 60/240 - train_loss: 0.1581 - test_loss: 0.097349\n",
      "Epoch: 448/450 - train_loss: 0.1576 - test_loss: 0.083671\n",
      "Epoch: 449/450 - train_loss: 0.2567 - test_loss: 0.080335\n",
      "Epoch: 99/100 - train_loss: 0.1654 - test_loss: 0.093435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:40:21,683]\u001b[0m Trial 7 finished with value: 20.676614060157576 and parameters: {'n layers': 6, 'Hidden size': 8, 'Learning rate': 0.0020856884355309265, 'Dropout rate': 0.4763060962670064, 'Epochs': 210}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:40:24,369]\u001b[0m Trial 31 finished with value: 25.33143965294039 and parameters: {'n layers': 5, 'Hidden size': 115, 'Learning rate': 0.0011274755803168538, 'Dropout rate': 0.5789208670273063, 'Epochs': 100}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 60/240 - train_loss: 0.1684 - test_loss: 0.102446\n",
      "Epoch: 60/240 - train_loss: 0.1755 - test_loss: 0.115347\n",
      "Epoch: 428/430 - train_loss: 0.1525 - test_loss: 0.080504\n",
      "Epoch: 429/430 - train_loss: 0.2542 - test_loss: 0.088663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:41:40,143]\u001b[0m Trial 23 finished with value: 23.14412281202372 and parameters: {'n layers': 6, 'Hidden size': 284, 'Learning rate': 0.008991804953983551, 'Dropout rate': 0.08475123890592384, 'Epochs': 430}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/260 - train_loss: 1.0501 - test_loss: 0.864127\n",
      "Epoch: 60/240 - train_loss: 0.2996 - test_loss: 0.104933\n",
      "Epoch: 336/450 - train_loss: 0.1529 - test_loss: 0.084007\n",
      "Epoch:  0/260 - train_loss: 1.2681 - test_loss: 1.185924\n",
      "Epoch:  0/260 - train_loss: 1.4867 - test_loss: 1.360127\n",
      "Epoch:  0/260 - train_loss: 0.9839 - test_loss: 0.704944\n",
      "Epoch: 120/240 - train_loss: 0.1538 - test_loss: 0.081746\n",
      "Epoch: 120/240 - train_loss: 0.1543 - test_loss: 0.083450\n",
      "Epoch: 120/240 - train_loss: 0.1532 - test_loss: 0.091005\n",
      "Epoch: 120/240 - train_loss: 0.1528 - test_loss: 0.080898\n",
      "Epoch: 65/260 - train_loss: 0.1545 - test_loss: 0.087398\n",
      "Epoch: 224/450 - train_loss: 0.1544 - test_loss: 0.077467\n",
      "Epoch: 125/500 - train_loss: 0.1584 - test_loss: 0.078295\n",
      "Epoch: 180/240 - train_loss: 0.1547 - test_loss: 0.085006\n",
      "Epoch: 65/260 - train_loss: 0.1736 - test_loss: 0.096248\n",
      "Epoch: 180/240 - train_loss: 0.1541 - test_loss: 0.082706\n",
      "Epoch: 180/240 - train_loss: 0.1537 - test_loss: 0.085341\n",
      "Epoch: 65/260 - train_loss: 0.2133 - test_loss: 0.161101\n",
      "Epoch: 180/240 - train_loss: 0.1539 - test_loss: 0.082131\n",
      "Epoch: 239/240 - train_loss: 0.1578 - test_loss: 0.089839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:44:40,944]\u001b[0m Trial 32 finished with value: 21.490227339219654 and parameters: {'n layers': 5, 'Hidden size': 106, 'Learning rate': 0.0012312067930658425, 'Dropout rate': 0.5457959268495074, 'Epochs': 100}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 130/260 - train_loss: 0.2136 - test_loss: 0.088739\n",
      "Epoch: 130/260 - train_loss: 0.1541 - test_loss: 0.089039\n",
      "Epoch: 239/240 - train_loss: 0.1557 - test_loss: 0.081174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:45:14,318]\u001b[0m Trial 34 finished with value: 19.180988026064487 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0009689552846921781, 'Dropout rate': 0.2759678503408224, 'Epochs': 100}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 65/260 - train_loss: 0.2353 - test_loss: 0.185784\n",
      "Epoch:  0/250 - train_loss: 0.9466 - test_loss: 0.636508\n",
      "Epoch: 239/240 - train_loss: 0.1574 - test_loss: 0.083093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:45:48,856]\u001b[0m Trial 35 finished with value: 22.424718854356783 and parameters: {'n layers': 4, 'Hidden size': 10, 'Learning rate': 0.0010335646333640754, 'Dropout rate': 0.28097153197247404, 'Epochs': 240}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/330 - train_loss: 0.8923 - test_loss: 0.636379\n",
      "Epoch: 239/240 - train_loss: 0.1523 - test_loss: 0.082420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:46:24,483]\u001b[0m Trial 33 finished with value: 14.708724634575285 and parameters: {'n layers': 5, 'Hidden size': 127, 'Learning rate': 0.0010497602073311259, 'Dropout rate': 0.521973178462783, 'Epochs': 100}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 250/500 - train_loss: 0.1522 - test_loss: 0.081159\n",
      "Epoch: 112/450 - train_loss: 0.1552 - test_loss: 0.083998\n",
      "Epoch: 130/260 - train_loss: 0.1543 - test_loss: 0.085788\n",
      "Epoch: 195/260 - train_loss: 0.1559 - test_loss: 0.089974\n",
      "Epoch: 195/260 - train_loss: 0.1542 - test_loss: 0.082236\n",
      "Epoch:  0/330 - train_loss: 1.0658 - test_loss: 0.692211\n",
      "Epoch:  0/330 - train_loss: 1.0678 - test_loss: 0.838439\n",
      "Epoch: 62/250 - train_loss: 0.1555 - test_loss: 0.086377\n",
      "Epoch: 130/260 - train_loss: 0.1554 - test_loss: 0.087757\n",
      "Epoch: 259/260 - train_loss: 0.2113 - test_loss: 0.096291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:47:58,223]\u001b[0m Trial 40 finished with value: 21.93107056120316 and parameters: {'n layers': 5, 'Hidden size': 50, 'Learning rate': 0.003619065801105853, 'Dropout rate': 0.5055334789728846, 'Epochs': 260}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 82/330 - train_loss: 0.1554 - test_loss: 0.081977\n",
      "Epoch: 259/260 - train_loss: 0.1540 - test_loss: 0.086873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:48:07,558]\u001b[0m Trial 37 finished with value: 16.945961296420737 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0018706337595288274, 'Dropout rate': 0.47650273710914015, 'Epochs': 500}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 124/250 - train_loss: 0.1542 - test_loss: 0.083775\n",
      "Epoch: 448/450 - train_loss: 0.1539 - test_loss: 0.077638\n",
      "Epoch: 195/260 - train_loss: 0.1535 - test_loss: 0.083383\n",
      "Epoch: 449/450 - train_loss: 0.1538 - test_loss: 0.081875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:48:41,828]\u001b[0m Trial 14 finished with value: 21.81461704832019 and parameters: {'n layers': 6, 'Hidden size': 74, 'Learning rate': 0.0008243650423048061, 'Dropout rate': 0.7988572266999784, 'Epochs': 400}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 82/330 - train_loss: 0.2591 - test_loss: 0.084314\n",
      "Epoch:  0/340 - train_loss: 0.8562 - test_loss: 0.644582\n",
      "Epoch:  0/340 - train_loss: 0.7969 - test_loss: 0.655082\n",
      "Epoch: 375/500 - train_loss: 0.2128 - test_loss: 0.082590\n",
      "Epoch: 82/330 - train_loss: 0.1599 - test_loss: 0.081791\n",
      "Epoch:  0/340 - train_loss: 1.0191 - test_loss: 0.776238\n",
      "Epoch: 186/250 - train_loss: 0.2575 - test_loss: 0.082169\n",
      "Epoch: 164/330 - train_loss: 0.1563 - test_loss: 0.078865\n",
      "Epoch: 164/330 - train_loss: 0.1553 - test_loss: 0.084873\n",
      "Epoch: 85/340 - train_loss: 0.1569 - test_loss: 0.083794\n",
      "Epoch: 259/260 - train_loss: 0.1545 - test_loss: 0.085078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:50:39,641]\u001b[0m Trial 39 finished with value: 24.457233753243127 and parameters: {'n layers': 4, 'Hidden size': 46, 'Learning rate': 0.0006362342478806367, 'Dropout rate': 0.30207277914470604, 'Epochs': 490}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 195/260 - train_loss: 0.1537 - test_loss: 0.083521\n",
      "Epoch: 85/340 - train_loss: 0.1660 - test_loss: 0.081093\n",
      "Epoch: 248/250 - train_loss: 0.1528 - test_loss: 0.082748\n",
      "Epoch: 249/250 - train_loss: 0.1534 - test_loss: 0.084177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:51:21,469]\u001b[0m Trial 41 finished with value: 13.626860751112359 and parameters: {'n layers': 4, 'Hidden size': 53, 'Learning rate': 0.0038842028598948313, 'Dropout rate': 0.49843051962972323, 'Epochs': 240}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 164/330 - train_loss: 0.1535 - test_loss: 0.091367\n",
      "Epoch:  0/320 - train_loss: 1.0771 - test_loss: 0.773018\n",
      "Epoch: 499/500 - train_loss: 0.1534 - test_loss: 0.080597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:52:28,841]\u001b[0m Trial 36 finished with value: 21.160658661087243 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0019094864048404762, 'Dropout rate': 0.28484394513639144, 'Epochs': 240}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224/450 - train_loss: 0.1534 - test_loss: 0.084469\n",
      "Epoch: 246/330 - train_loss: 0.1554 - test_loss: 0.085903\n",
      "Epoch:  0/320 - train_loss: 1.2093 - test_loss: 0.911109\n",
      "Epoch: 336/450 - train_loss: 0.1652 - test_loss: 0.078725\n",
      "Epoch: 246/330 - train_loss: 0.1559 - test_loss: 0.086325\n",
      "Epoch: 170/340 - train_loss: 0.1582 - test_loss: 0.082921\n",
      "Epoch: 259/260 - train_loss: 0.1536 - test_loss: 0.086987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:53:17,407]\u001b[0m Trial 38 finished with value: 24.10182199257713 and parameters: {'n layers': 4, 'Hidden size': 51, 'Learning rate': 0.0006074552094894655, 'Dropout rate': 0.30408173454499776, 'Epochs': 160}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170/340 - train_loss: 0.1546 - test_loss: 0.086757\n",
      "Epoch: 328/330 - train_loss: 0.1546 - test_loss: 0.081235\n",
      "Epoch: 329/330 - train_loss: 0.1540 - test_loss: 0.086017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:53:46,276]\u001b[0m Trial 42 finished with value: 19.08293545209725 and parameters: {'n layers': 5, 'Hidden size': 45, 'Learning rate': 0.004000293977218475, 'Dropout rate': 0.497212765668674, 'Epochs': 250}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 246/330 - train_loss: 0.1651 - test_loss: 0.117606\n",
      "Epoch: 80/320 - train_loss: 0.1552 - test_loss: 0.080690\n",
      "Epoch: 85/340 - train_loss: 0.1542 - test_loss: 0.077569\n",
      "Epoch: 80/320 - train_loss: 0.1572 - test_loss: 0.089491\n",
      "Epoch: 328/330 - train_loss: 0.1606 - test_loss: 0.098315\n",
      "Epoch: 329/330 - train_loss: 0.1562 - test_loss: 0.087470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:54:07,404]\u001b[0m Trial 43 finished with value: 20.945226771701375 and parameters: {'n layers': 5, 'Hidden size': 50, 'Learning rate': 0.004635992595374471, 'Dropout rate': 0.4908697966668282, 'Epochs': 330}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 255/340 - train_loss: 0.1536 - test_loss: 0.078739\n",
      "Epoch: 255/340 - train_loss: 0.1540 - test_loss: 0.078134\n",
      "Epoch: 160/320 - train_loss: 0.1570 - test_loss: 0.081594\n",
      "Epoch: 328/330 - train_loss: 0.1537 - test_loss: 0.081830\n",
      "Epoch: 329/330 - train_loss: 0.1559 - test_loss: 0.081409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:54:51,437]\u001b[0m Trial 44 finished with value: 16.830615371190333 and parameters: {'n layers': 5, 'Hidden size': 55, 'Learning rate': 0.003828655638279179, 'Dropout rate': 0.48734823295505547, 'Epochs': 330}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160/320 - train_loss: 0.1538 - test_loss: 0.081422\n",
      "Epoch: 170/340 - train_loss: 0.2544 - test_loss: 0.087519\n",
      "Epoch: 339/340 - train_loss: 0.1559 - test_loss: 0.081087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:55:10,954]\u001b[0m Trial 45 finished with value: 18.720481189944078 and parameters: {'n layers': 4, 'Hidden size': 52, 'Learning rate': 0.003563448909169585, 'Dropout rate': 0.6689280290653344, 'Epochs': 330}. Best is trial 17 with value: 10.000598787948489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448/450 - train_loss: 0.1569 - test_loss: 0.082692\n",
      "Epoch: 449/450 - train_loss: 0.1556 - test_loss: 0.077380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:55:23,816]\u001b[0m Trial 5 finished with value: 6.806090501298981 and parameters: {'n layers': 6, 'Hidden size': 30, 'Learning rate': 0.00475784141367153, 'Dropout rate': 0.6892899172133032, 'Epochs': 160}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/340 - train_loss: 0.1553 - test_loss: 0.073975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:55:34,432]\u001b[0m Trial 46 finished with value: 13.900353823088771 and parameters: {'n layers': 5, 'Hidden size': 156, 'Learning rate': 0.003029365303265246, 'Dropout rate': 0.6514073754198617, 'Epochs': 150}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 336/450 - train_loss: 0.1534 - test_loss: 0.077895\n",
      "Epoch: 240/320 - train_loss: 0.1527 - test_loss: 0.082127\n",
      "Epoch: 112/450 - train_loss: 0.3209 - test_loss: 0.259681\n",
      "Epoch: 224/450 - train_loss: 0.1528 - test_loss: 0.084896\n",
      "Epoch: 240/320 - train_loss: 0.1550 - test_loss: 0.082037\n",
      "Epoch: 255/340 - train_loss: 0.1528 - test_loss: 0.077032\n",
      "Epoch: 319/320 - train_loss: 0.1544 - test_loss: 0.082083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:56:44,543]\u001b[0m Trial 49 finished with value: 19.802279834557694 and parameters: {'n layers': 3, 'Hidden size': 157, 'Learning rate': 0.002842920757730706, 'Dropout rate': 0.6597618263362017, 'Epochs': 320}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112/450 - train_loss: 0.1563 - test_loss: 0.095191\n",
      "Epoch: 112/450 - train_loss: 0.1547 - test_loss: 0.090967\n",
      "Epoch: 319/320 - train_loss: 0.1613 - test_loss: 0.088827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:56:58,502]\u001b[0m Trial 48 finished with value: 19.946332466367483 and parameters: {'n layers': 3, 'Hidden size': 384, 'Learning rate': 0.00297310749434808, 'Dropout rate': 0.6601197418594714, 'Epochs': 330}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448/450 - train_loss: 0.3175 - test_loss: 0.084319\n",
      "Epoch: 449/450 - train_loss: 0.1584 - test_loss: 0.112084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:57:09,573]\u001b[0m Trial 6 finished with value: 18.938107679995344 and parameters: {'n layers': 6, 'Hidden size': 7, 'Learning rate': 0.001965444920958677, 'Dropout rate': 0.259500659756649, 'Epochs': 150}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/340 - train_loss: 0.1529 - test_loss: 0.084104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:57:14,235]\u001b[0m Trial 47 finished with value: 14.80912406141107 and parameters: {'n layers': 5, 'Hidden size': 39, 'Learning rate': 0.0036397665946867872, 'Dropout rate': 0.64498581445396, 'Epochs': 340}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224/450 - train_loss: 0.2379 - test_loss: 0.109407\n",
      "Epoch: 336/450 - train_loss: 0.1524 - test_loss: 0.081768\n",
      "Epoch: 112/450 - train_loss: 0.4745 - test_loss: 0.417716\n",
      "Epoch: 224/450 - train_loss: 0.1533 - test_loss: 0.075474\n",
      "Epoch: 112/450 - train_loss: 0.1528 - test_loss: 0.083540\n",
      "Epoch: 224/450 - train_loss: 0.3108 - test_loss: 0.087728\n",
      "Epoch: 112/450 - train_loss: 0.3685 - test_loss: 0.343194\n",
      "Epoch: 336/450 - train_loss: 0.1563 - test_loss: 0.086342\n",
      "Epoch: 448/450 - train_loss: 0.1554 - test_loss: 0.082410\n",
      "Epoch: 449/450 - train_loss: 0.1535 - test_loss: 0.079770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:58:41,893]\u001b[0m Trial 10 finished with value: 24.45721644938457 and parameters: {'n layers': 5, 'Hidden size': 20, 'Learning rate': 0.0010575678132768954, 'Dropout rate': 0.7757938627256411, 'Epochs': 250}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224/450 - train_loss: 0.2323 - test_loss: 0.187590\n",
      "Epoch: 112/450 - train_loss: 0.3738 - test_loss: 0.334749\n",
      "Epoch: 336/450 - train_loss: 0.1546 - test_loss: 0.084653\n",
      "Epoch: 336/450 - train_loss: 0.1540 - test_loss: 0.079182\n",
      "Epoch: 224/450 - train_loss: 0.1561 - test_loss: 0.087634\n",
      "Epoch: 448/450 - train_loss: 0.1537 - test_loss: 0.084523\n",
      "Epoch: 449/450 - train_loss: 0.3105 - test_loss: 0.087213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:59:50,706]\u001b[0m Trial 9 finished with value: 25.64109059087258 and parameters: {'n layers': 4, 'Hidden size': 24, 'Learning rate': 0.0002634845899829183, 'Dropout rate': 0.040427793891819684, 'Epochs': 120}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224/450 - train_loss: 0.2083 - test_loss: 0.157223\n",
      "Epoch: 336/450 - train_loss: 0.1739 - test_loss: 0.105102\n",
      "Epoch: 448/450 - train_loss: 0.1533 - test_loss: 0.084690\n",
      "Epoch: 449/450 - train_loss: 0.1538 - test_loss: 0.085997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:00:28,689]\u001b[0m Trial 13 finished with value: 17.95711499389825 and parameters: {'n layers': 4, 'Hidden size': 269, 'Learning rate': 0.0020495014348287806, 'Dropout rate': 0.502012433616969, 'Epochs': 500}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448/450 - train_loss: 0.1621 - test_loss: 0.080343\n",
      "Epoch: 449/450 - train_loss: 0.1626 - test_loss: 0.086756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:00:38,420]\u001b[0m Trial 8 finished with value: 22.487700621479163 and parameters: {'n layers': 6, 'Hidden size': 39, 'Learning rate': 0.0006801887394867418, 'Dropout rate': 0.21255327059488868, 'Epochs': 340}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 336/450 - train_loss: 0.1538 - test_loss: 0.088208\n",
      "Epoch: 224/450 - train_loss: 0.2950 - test_loss: 0.152546\n",
      "Epoch: 448/450 - train_loss: 0.1542 - test_loss: 0.083724\n",
      "Epoch: 449/450 - train_loss: 0.1561 - test_loss: 0.083805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:00:57,341]\u001b[0m Trial 3 finished with value: 19.101842284462318 and parameters: {'n layers': 3, 'Hidden size': 34, 'Learning rate': 0.0001674249589251471, 'Dropout rate': 0.6173630088330655, 'Epochs': 210}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 336/450 - train_loss: 0.1548 - test_loss: 0.096986\n",
      "Epoch: 448/450 - train_loss: 0.1533 - test_loss: 0.081253\n",
      "Epoch: 449/450 - train_loss: 0.2158 - test_loss: 0.085745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:01:15,485]\u001b[0m Trial 2 finished with value: 21.76812139927048 and parameters: {'n layers': 5, 'Hidden size': 35, 'Learning rate': 0.0014814364323319908, 'Dropout rate': 0.3562858016609326, 'Epochs': 470}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 336/450 - train_loss: 0.1583 - test_loss: 0.097438\n",
      "Epoch: 448/450 - train_loss: 0.1521 - test_loss: 0.086452\n",
      "Epoch: 449/450 - train_loss: 0.3131 - test_loss: 0.086833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:01:26,058]\u001b[0m Trial 18 finished with value: 23.795232642263766 and parameters: {'n layers': 4, 'Hidden size': 26, 'Learning rate': 0.00021171177236022952, 'Dropout rate': 0.16641553267282025, 'Epochs': 240}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448/450 - train_loss: 0.1621 - test_loss: 0.083601\n",
      "Epoch: 449/450 - train_loss: 0.1566 - test_loss: 0.085245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:01:36,851]\u001b[0m Trial 0 finished with value: 24.04636352488568 and parameters: {'n layers': 6, 'Hidden size': 120, 'Learning rate': 0.00021239647204130497, 'Dropout rate': 0.30533793762956585, 'Epochs': 120}. Best is trial 5 with value: 6.806090501298981.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 04:01:36,875]\u001b[0m A new study created in memory with name: no-name-4fbc18a3-481c-4581-b42a-105129eaefd5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Trà Vinh\n",
      "  Value:  6.806090501298981\n",
      "optimize result of city: Trà Vinh\n",
      "lookback 3\n",
      "lookbacklookback 3\n",
      " 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback lookback 3\n",
      "3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/200 - train_loss: 1.2074 - test_loss: 0.707028\n",
      "Epoch:  0/200 - train_loss: 1.2508 - test_loss: 0.750110\n",
      "Epoch:  0/200 - train_loss: 2.0577 - test_loss: 1.565521\n",
      "Epoch:  0/200 - train_loss: 1.0925 - test_loss: 0.704356\n",
      "Epoch:  0/200 - train_loss: 1.8590 - test_loss: 1.594243\n",
      "Epoch:  0/200 - train_loss: 2.1905 - test_loss: 1.674495\n",
      "Epoch:  0/200 - train_loss: 1.3530 - test_loss: 1.049337\n",
      "Epoch:  0/200 - train_loss: 1.3607 - test_loss: 0.745501\n",
      "Epoch:  0/200 - train_loss: 1.4364 - test_loss: 0.873637\n",
      "Epoch:  0/200 - train_loss: 1.6298 - test_loss: 0.990382Epoch:  0/200 - train_loss: 2.0129 - test_loss: 1.786641Epoch:  0/200 - train_loss: 1.4374 - test_loss: 1.257611\n",
      "\n",
      "Epoch:  0/200 - train_loss: 1.7157 - test_loss: 0.963417\n",
      "\n",
      "Epoch:  0/200 - train_loss: 1.9829 - test_loss: 0.988712\n",
      "Epoch:  0/200 - train_loss: 1.1660 - test_loss: 0.724556\n",
      "Epoch:  0/200 - train_loss: 1.8095 - test_loss: 1.254190\n",
      "Epoch:  0/200 - train_loss: 1.7519 - test_loss: 0.880015\n",
      "Epoch:  0/200 - train_loss: 2.1048 - test_loss: 1.387012\n",
      "Epoch:  0/200 - train_loss: 0.9699 - test_loss: 0.796458\n",
      "Epoch:  0/200 - train_loss: 1.4500 - test_loss: 1.266986\n",
      "Epoch: 50/200 - train_loss: 0.4209 - test_loss: 0.323077\n",
      "Epoch: 50/200 - train_loss: 0.4339 - test_loss: 0.309007\n",
      "Epoch: 50/200 - train_loss: 0.8740 - test_loss: 0.740309\n",
      "Epoch: 50/200 - train_loss: 0.5202 - test_loss: 0.370575\n",
      "Epoch: 50/200 - train_loss: 0.4343 - test_loss: 0.371010\n",
      "Epoch: 50/200 - train_loss: 0.4324 - test_loss: 0.346547\n",
      "Epoch: 100/200 - train_loss: 0.4312 - test_loss: 0.381367\n",
      "Epoch: 50/200 - train_loss: 0.4461 - test_loss: 0.347271\n",
      "Epoch: 100/200 - train_loss: 0.4255 - test_loss: 0.302537\n",
      "Epoch: 100/200 - train_loss: 0.6926 - test_loss: 0.618076\n",
      "Epoch: 100/200 - train_loss: 0.4864 - test_loss: 0.324282\n",
      "Epoch: 100/200 - train_loss: 0.4218 - test_loss: 0.298031\n",
      "Epoch: 150/200 - train_loss: 0.4280 - test_loss: 0.315265\n",
      "Epoch: 50/200 - train_loss: 0.4314 - test_loss: 0.335468\n",
      "Epoch: 50/200 - train_loss: 0.4258 - test_loss: 0.328215\n",
      "Epoch: 100/200 - train_loss: 0.4308 - test_loss: 0.325897\n",
      "Epoch: 150/200 - train_loss: 0.4205 - test_loss: 0.309702\n",
      "Epoch: 150/200 - train_loss: 0.6033 - test_loss: 0.540623\n",
      "Epoch: 100/200 - train_loss: 0.4495 - test_loss: 0.321917\n",
      "Epoch: 150/200 - train_loss: 0.4247 - test_loss: 0.305134\n",
      "Epoch: 150/200 - train_loss: 0.4563 - test_loss: 0.313412\n",
      "Epoch: 199/200 - train_loss: 0.4873 - test_loss: 0.331389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:11:00,116]\u001b[0m Trial 18 finished with value: 20.36172907497497 and parameters: {'n layers': 6, 'Hidden size': 12, 'Learning rate': 0.005015140195363019, 'Dropout rate': 0.17891831023597463, 'Epochs': 410}. Best is trial 18 with value: 20.36172907497497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 199/200 - train_loss: 0.4435 - test_loss: 0.317662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:11:08,044]\u001b[0m Trial 15 finished with value: 21.12673575246391 and parameters: {'n layers': 4, 'Hidden size': 18, 'Learning rate': 0.00826427024107484, 'Dropout rate': 0.22220311571946735, 'Epochs': 430}. Best is trial 18 with value: 20.36172907497497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 199/200 - train_loss: 0.5750 - test_loss: 0.475723\n",
      "Epoch: 150/200 - train_loss: 0.4256 - test_loss: 0.316065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:11:18,461]\u001b[0m Trial 0 finished with value: 27.597580961155245 and parameters: {'n layers': 6, 'Hidden size': 23, 'Learning rate': 0.00010464054848635227, 'Dropout rate': 0.1381128744724357, 'Epochs': 310}. Best is trial 18 with value: 20.36172907497497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/200 - train_loss: 0.4348 - test_loss: 0.329117\n",
      "Epoch: 100/200 - train_loss: 0.4208 - test_loss: 0.351749\n",
      "Epoch: 199/200 - train_loss: 0.4125 - test_loss: 0.333279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:12:04,067]\u001b[0m Trial 6 finished with value: 23.627257645009934 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0007137752812190053, 'Dropout rate': 0.03380898763476376, 'Epochs': 430}. Best is trial 18 with value: 20.36172907497497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/200 - train_loss: 0.4570 - test_loss: 0.327292\n",
      "Epoch: 50/200 - train_loss: 0.5813 - test_loss: 0.512439\n",
      "Epoch: 100/200 - train_loss: 0.4233 - test_loss: 0.368754\n",
      "Epoch:  0/330 - train_loss: 1.5599 - test_loss: 0.978673\n",
      "Epoch:  0/330 - train_loss: 1.6631 - test_loss: 1.337317\n",
      "Epoch: 199/200 - train_loss: 0.4675 - test_loss: 0.287177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:12:53,687]\u001b[0m Trial 12 finished with value: 19.70741421594946 and parameters: {'n layers': 3, 'Hidden size': 8, 'Learning rate': 0.00990075945287789, 'Dropout rate': 0.3217297351997344, 'Epochs': 500}. Best is trial 12 with value: 19.70741421594946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/470 - train_loss: 1.5243 - test_loss: 1.110832\n",
      "Epoch: 199/200 - train_loss: 0.4269 - test_loss: 0.338119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:13:23,772]\u001b[0m Trial 5 finished with value: 20.154638593713294 and parameters: {'n layers': 3, 'Hidden size': 182, 'Learning rate': 0.0057591919320010825, 'Dropout rate': 0.20840439644573122, 'Epochs': 140}. Best is trial 12 with value: 19.70741421594946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/490 - train_loss: 1.8704 - test_loss: 1.353555\n",
      "Epoch: 100/200 - train_loss: 0.4211 - test_loss: 0.341076\n",
      "Epoch: 150/200 - train_loss: 0.4191 - test_loss: 0.337293\n",
      "Epoch: 50/200 - train_loss: 0.7567 - test_loss: 0.660413\n",
      "Epoch: 199/200 - train_loss: 0.4297 - test_loss: 0.316360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:14:08,901]\u001b[0m Trial 1 finished with value: 22.959990591969056 and parameters: {'n layers': 5, 'Hidden size': 185, 'Learning rate': 0.0008489168983931027, 'Dropout rate': 0.637809796721076, 'Epochs': 280}. Best is trial 12 with value: 19.70741421594946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/470 - train_loss: 1.5302 - test_loss: 0.908627\n",
      "Epoch: 150/200 - train_loss: 0.4639 - test_loss: 0.288640\n",
      "Epoch:  0/470 - train_loss: 1.7247 - test_loss: 1.102635\n",
      "Epoch: 100/200 - train_loss: 0.5215 - test_loss: 0.382773\n",
      "Epoch:  0/470 - train_loss: 1.3360 - test_loss: 0.997396\n",
      "Epoch: 82/330 - train_loss: 0.4233 - test_loss: 0.322350\n",
      "Epoch: 82/330 - train_loss: 0.4487 - test_loss: 0.330182\n",
      "Epoch: 199/200 - train_loss: 0.5000 - test_loss: 0.309472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:15:29,062]\u001b[0m Trial 16 finished with value: 19.509506603231046 and parameters: {'n layers': 3, 'Hidden size': 215, 'Learning rate': 0.003867987821921305, 'Dropout rate': 0.5160177288908941, 'Epochs': 500}. Best is trial 16 with value: 19.509506603231046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/200 - train_loss: 0.4164 - test_loss: 0.310013\n",
      "Epoch: 117/470 - train_loss: 0.4785 - test_loss: 0.379293\n",
      "Epoch: 199/200 - train_loss: 0.4423 - test_loss: 0.307460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:16:16,612]\u001b[0m Trial 8 finished with value: 22.586283848441685 and parameters: {'n layers': 4, 'Hidden size': 7, 'Learning rate': 0.0013476086073493099, 'Dropout rate': 0.7390767022960489, 'Epochs': 410}. Best is trial 16 with value: 19.509506603231046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/450 - train_loss: 1.4976 - test_loss: 1.011774\n",
      "Epoch: 50/200 - train_loss: 0.4817 - test_loss: 0.324861\n",
      "Epoch: 122/490 - train_loss: 0.5451 - test_loss: 0.419340\n",
      "Epoch: 164/330 - train_loss: 0.4290 - test_loss: 0.292695\n",
      "Epoch:  0/450 - train_loss: 1.3181 - test_loss: 0.777011\n",
      "Epoch: 164/330 - train_loss: 0.4822 - test_loss: 0.318032\n",
      "Epoch: 117/470 - train_loss: 0.4294 - test_loss: 0.300621\n",
      "Epoch: 117/470 - train_loss: 0.4224 - test_loss: 0.338815\n",
      "Epoch: 117/470 - train_loss: 0.4201 - test_loss: 0.302104\n",
      "Epoch: 246/330 - train_loss: 0.4434 - test_loss: 0.304388\n",
      "Epoch: 234/470 - train_loss: 0.4487 - test_loss: 0.318081\n",
      "Epoch: 246/330 - train_loss: 0.4718 - test_loss: 0.316417\n",
      "Epoch: 244/490 - train_loss: 0.4326 - test_loss: 0.315572\n",
      "Epoch: 199/200 - train_loss: 0.4263 - test_loss: 0.318986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:19:12,000]\u001b[0m Trial 7 finished with value: 18.886808522955423 and parameters: {'n layers': 5, 'Hidden size': 68, 'Learning rate': 0.009713128486170505, 'Dropout rate': 0.426071132659262, 'Epochs': 160}. Best is trial 7 with value: 18.886808522955423.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 234/470 - train_loss: 0.4588 - test_loss: 0.310133\n",
      "Epoch: 112/450 - train_loss: 0.5873 - test_loss: 0.532188\n",
      "Epoch: 234/470 - train_loss: 0.4270 - test_loss: 0.354801\n",
      "Epoch:  0/110 - train_loss: 1.5582 - test_loss: 1.202597\n",
      "Epoch: 328/330 - train_loss: 0.4481 - test_loss: 0.256188\n",
      "Epoch: 329/330 - train_loss: 0.4144 - test_loss: 0.332710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:20:15,927]\u001b[0m Trial 20 finished with value: 19.555638858138188 and parameters: {'n layers': 3, 'Hidden size': 129, 'Learning rate': 0.0031576946061326046, 'Dropout rate': 0.778358520124861, 'Epochs': 350}. Best is trial 7 with value: 18.886808522955423.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/200 - train_loss: 0.4227 - test_loss: 0.314848\n",
      "Epoch: 328/330 - train_loss: 0.4213 - test_loss: 0.321140\n",
      "Epoch: 329/330 - train_loss: 0.4286 - test_loss: 0.323354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:20:28,049]\u001b[0m Trial 21 finished with value: 22.291037442831026 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.0005879423472046944, 'Dropout rate': 0.4751593879498468, 'Epochs': 280}. Best is trial 7 with value: 18.886808522955423.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 234/470 - train_loss: 0.4162 - test_loss: 0.300156\n",
      "Epoch:  0/110 - train_loss: 1.6141 - test_loss: 1.043814\n",
      "Epoch: 351/470 - train_loss: 0.4215 - test_loss: 0.316729\n",
      "Epoch: 27/110 - train_loss: 0.7769 - test_loss: 0.611308\n",
      "Epoch:  0/110 - train_loss: 1.4506 - test_loss: 1.087707\n",
      "Epoch: 112/450 - train_loss: 0.4860 - test_loss: 0.350748\n",
      "Epoch: 27/110 - train_loss: 0.4687 - test_loss: 0.339191\n",
      "Epoch: 27/110 - train_loss: 0.4292 - test_loss: 0.338749\n",
      "Epoch: 366/490 - train_loss: 0.4231 - test_loss: 0.306057\n",
      "Epoch: 54/110 - train_loss: 0.4250 - test_loss: 0.347441\n",
      "Epoch: 351/470 - train_loss: 0.4207 - test_loss: 0.304597\n",
      "Epoch: 54/110 - train_loss: 0.4218 - test_loss: 0.317343\n",
      "Epoch: 81/110 - train_loss: 0.4180 - test_loss: 0.330228\n",
      "Epoch: 81/110 - train_loss: 0.4405 - test_loss: 0.304459\n",
      "Epoch: 351/470 - train_loss: 0.4246 - test_loss: 0.288653\n",
      "Epoch: 224/450 - train_loss: 0.4956 - test_loss: 0.391284\n",
      "Epoch: 108/110 - train_loss: 0.4326 - test_loss: 0.285828\n",
      "Epoch: 109/110 - train_loss: 0.4301 - test_loss: 0.306263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:23:10,708]\u001b[0m Trial 30 finished with value: 18.811080945663537 and parameters: {'n layers': 5, 'Hidden size': 54, 'Learning rate': 0.0022815965608593207, 'Dropout rate': 0.5074075023201232, 'Epochs': 100}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 54/110 - train_loss: 0.6223 - test_loss: 0.536293\n",
      "Epoch: 108/110 - train_loss: 0.4194 - test_loss: 0.327183\n",
      "Epoch: 468/470 - train_loss: 0.4401 - test_loss: 0.317216\n",
      "Epoch: 109/110 - train_loss: 0.4261 - test_loss: 0.336451\n",
      "Epoch: 469/470 - train_loss: 0.4284 - test_loss: 0.312272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:23:24,121]\u001b[0m Trial 31 finished with value: 21.725262097980135 and parameters: {'n layers': 5, 'Hidden size': 57, 'Learning rate': 0.002128409166092951, 'Dropout rate': 0.5014087253539138, 'Epochs': 110}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:23:25,156]\u001b[0m Trial 22 finished with value: 24.914223054692965 and parameters: {'n layers': 4, 'Hidden size': 68, 'Learning rate': 0.0002596410750248602, 'Dropout rate': 0.5736489076794683, 'Epochs': 100}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 100/200 - train_loss: 0.6146 - test_loss: 0.537753\n",
      "Epoch: 199/200 - train_loss: 0.4786 - test_loss: 0.312929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:24:23,750]\u001b[0m Trial 14 finished with value: 23.748903356500502 and parameters: {'n layers': 6, 'Hidden size': 13, 'Learning rate': 0.0003433754423106912, 'Dropout rate': 0.1660927638471931, 'Epochs': 410}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 351/470 - train_loss: 0.4315 - test_loss: 0.326915\n",
      "Epoch: 81/110 - train_loss: 0.5624 - test_loss: 0.460371\n",
      "Epoch:  0/180 - train_loss: 1.3146 - test_loss: 0.775930\n",
      "Epoch:  0/180 - train_loss: 1.5739 - test_loss: 1.083634\n",
      "Epoch:  0/180 - train_loss: 1.9742 - test_loss: 1.109788\n",
      "Epoch: 488/490 - train_loss: 0.4417 - test_loss: 0.316950\n",
      "Epoch: 489/490 - train_loss: 0.4383 - test_loss: 0.312356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:25:27,500]\u001b[0m Trial 23 finished with value: 21.96027557696861 and parameters: {'n layers': 6, 'Hidden size': 37, 'Learning rate': 0.0002028727573686659, 'Dropout rate': 0.07527652050588936, 'Epochs': 330}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 468/470 - train_loss: 0.4827 - test_loss: 0.292314\n",
      "Epoch:  0/200 - train_loss: 1.6624 - test_loss: 1.354473\n",
      "Epoch: 469/470 - train_loss: 0.4267 - test_loss: 0.303966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:25:46,302]\u001b[0m Trial 24 finished with value: 20.550774056105197 and parameters: {'n layers': 6, 'Hidden size': 14, 'Learning rate': 0.0048082940127571255, 'Dropout rate': 0.03512071658484387, 'Epochs': 470}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 108/110 - train_loss: 0.5035 - test_loss: 0.413924\n",
      "Epoch: 109/110 - train_loss: 0.5254 - test_loss: 0.414510\n",
      "Epoch: 45/180 - train_loss: 0.4170 - test_loss: 0.319789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:26:13,489]\u001b[0m Trial 29 finished with value: 26.401641036856404 and parameters: {'n layers': 5, 'Hidden size': 53, 'Learning rate': 0.00024297663126456392, 'Dropout rate': 0.4546945703304148, 'Epochs': 110}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 45/180 - train_loss: 0.4422 - test_loss: 0.298767\n",
      "Epoch: 45/180 - train_loss: 0.7091 - test_loss: 0.574612\n",
      "Epoch: 224/450 - train_loss: 0.4242 - test_loss: 0.335360\n",
      "Epoch:  0/190 - train_loss: 1.5991 - test_loss: 1.055050\n",
      "Epoch: 468/470 - train_loss: 0.4275 - test_loss: 0.303628\n",
      "Epoch: 469/470 - train_loss: 0.4210 - test_loss: 0.285868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:27:08,911]\u001b[0m Trial 25 finished with value: 21.05069182443856 and parameters: {'n layers': 5, 'Hidden size': 20, 'Learning rate': 0.001880082144266607, 'Dropout rate': 0.6424404289452513, 'Epochs': 490}. Best is trial 30 with value: 18.811080945663537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/190 - train_loss: 1.6785 - test_loss: 1.150477\n",
      "Epoch: 150/200 - train_loss: 0.5803 - test_loss: 0.462019\n",
      "Epoch:  0/200 - train_loss: 1.6703 - test_loss: 0.867582\n",
      "Epoch: 336/450 - train_loss: 0.4409 - test_loss: 0.328128\n",
      "Epoch: 90/180 - train_loss: 0.4155 - test_loss: 0.340047\n",
      "Epoch: 90/180 - train_loss: 0.4235 - test_loss: 0.311108\n",
      "Epoch: 90/180 - train_loss: 0.5311 - test_loss: 0.442039\n",
      "Epoch:  0/200 - train_loss: 1.5155 - test_loss: 0.944763\n",
      "Epoch: 47/190 - train_loss: 0.4313 - test_loss: 0.310589\n",
      "Epoch: 47/190 - train_loss: 0.4210 - test_loss: 0.340874\n",
      "Epoch: 468/470 - train_loss: 0.4302 - test_loss: 0.315448\n",
      "Epoch: 469/470 - train_loss: 0.4205 - test_loss: 0.304246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:28:32,913]\u001b[0m Trial 26 finished with value: 16.36386093376157 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.004906921373578736, 'Dropout rate': 0.06456594088927803, 'Epochs': 470}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 135/180 - train_loss: 0.4591 - test_loss: 0.324559\n",
      "Epoch: 135/180 - train_loss: 0.4301 - test_loss: 0.295230\n",
      "Epoch: 135/180 - train_loss: 0.4508 - test_loss: 0.355756\n",
      "Epoch: 50/200 - train_loss: 0.4375 - test_loss: 0.334598\n",
      "Epoch: 94/190 - train_loss: 0.4316 - test_loss: 0.303789\n",
      "Epoch: 50/200 - train_loss: 0.4426 - test_loss: 0.364626\n",
      "Epoch:  0/190 - train_loss: 1.3501 - test_loss: 0.720441\n",
      "Epoch: 94/190 - train_loss: 0.5003 - test_loss: 0.323605\n",
      "Epoch: 179/180 - train_loss: 0.4150 - test_loss: 0.321165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:29:45,506]\u001b[0m Trial 32 finished with value: 20.60573126641886 and parameters: {'n layers': 5, 'Hidden size': 66, 'Learning rate': 0.0018695681147860947, 'Dropout rate': 0.3604929721755151, 'Epochs': 100}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 179/180 - train_loss: 0.4418 - test_loss: 0.311423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:29:59,210]\u001b[0m Trial 34 finished with value: 22.020644272049378 and parameters: {'n layers': 5, 'Hidden size': 40, 'Learning rate': 0.0017039798647973921, 'Dropout rate': 0.35701397893610437, 'Epochs': 190}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 179/180 - train_loss: 0.4314 - test_loss: 0.334267\n",
      "Epoch: 100/200 - train_loss: 0.4229 - test_loss: 0.323675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:30:08,219]\u001b[0m Trial 33 finished with value: 25.198415050328958 and parameters: {'n layers': 5, 'Hidden size': 65, 'Learning rate': 0.00026592167621570297, 'Dropout rate': 0.36657954414552546, 'Epochs': 200}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/200 - train_loss: 0.4261 - test_loss: 0.324380\n",
      "Epoch: 141/190 - train_loss: 0.4861 - test_loss: 0.300401\n",
      "Epoch: 100/200 - train_loss: 0.4191 - test_loss: 0.300740\n",
      "Epoch: 47/190 - train_loss: 0.4216 - test_loss: 0.358180\n",
      "Epoch: 336/450 - train_loss: 0.4392 - test_loss: 0.283943\n",
      "Epoch:  0/200 - train_loss: 1.3415 - test_loss: 0.722789\n",
      "Epoch: 141/190 - train_loss: 0.4282 - test_loss: 0.321480\n",
      "Epoch: 448/450 - train_loss: 0.4097 - test_loss: 0.324391\n",
      "Epoch: 449/450 - train_loss: 0.4196 - test_loss: 0.325152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:31:32,095]\u001b[0m Trial 27 finished with value: 27.10363193554279 and parameters: {'n layers': 4, 'Hidden size': 43, 'Learning rate': 0.00012715725028642047, 'Dropout rate': 0.3308565197160223, 'Epochs': 200}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/200 - train_loss: 1.6215 - test_loss: 1.004982\n",
      "Epoch:  0/160 - train_loss: 1.2153 - test_loss: 0.729036\n",
      "Epoch: 188/190 - train_loss: 0.4364 - test_loss: 0.320365\n",
      "Epoch: 189/190 - train_loss: 0.4732 - test_loss: 0.294735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:32:20,693]\u001b[0m Trial 36 finished with value: 20.10901491491998 and parameters: {'n layers': 5, 'Hidden size': 87, 'Learning rate': 0.002246943087810335, 'Dropout rate': 0.36847021733267143, 'Epochs': 200}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/160 - train_loss: 0.9707 - test_loss: 0.728801\n",
      "Epoch: 150/200 - train_loss: 0.4245 - test_loss: 0.334641\n",
      "Epoch: 100/200 - train_loss: 0.4175 - test_loss: 0.292567\n",
      "Epoch: 188/190 - train_loss: 0.4225 - test_loss: 0.292977\n",
      "Epoch: 94/190 - train_loss: 0.4138 - test_loss: 0.342134\n",
      "Epoch: 189/190 - train_loss: 0.4295 - test_loss: 0.300331\n",
      "Epoch: 50/200 - train_loss: 0.4319 - test_loss: 0.316830\n",
      "Epoch: 100/200 - train_loss: 0.4239 - test_loss: 0.303830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:32:45,973]\u001b[0m Trial 37 finished with value: 23.558958373726355 and parameters: {'n layers': 5, 'Hidden size': 75, 'Learning rate': 0.0018260046699779587, 'Dropout rate': 0.3820475132032269, 'Epochs': 180}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 40/160 - train_loss: 0.4252 - test_loss: 0.329781\n",
      "Epoch: 50/200 - train_loss: 0.4322 - test_loss: 0.335472\n",
      "Epoch:  0/160 - train_loss: 1.1471 - test_loss: 0.718168\n",
      "Epoch:  0/160 - train_loss: 1.4727 - test_loss: 0.777525\n",
      "Epoch: 40/160 - train_loss: 0.4365 - test_loss: 0.337710\n",
      "Epoch: 80/160 - train_loss: 0.4266 - test_loss: 0.326401\n",
      "Epoch: 100/200 - train_loss: 0.4290 - test_loss: 0.291707\n",
      "Epoch: 199/200 - train_loss: 0.5335 - test_loss: 0.332586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:34:08,658]\u001b[0m Trial 39 finished with value: 21.91811801089553 and parameters: {'n layers': 5, 'Hidden size': 381, 'Learning rate': 0.0025288496556103925, 'Dropout rate': 0.3631828354474219, 'Epochs': 200}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 141/190 - train_loss: 0.4344 - test_loss: 0.300126\n",
      "Epoch: 100/200 - train_loss: 0.4273 - test_loss: 0.329649\n",
      "Epoch: 199/200 - train_loss: 0.5043 - test_loss: 0.399792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:34:27,367]\u001b[0m Trial 10 finished with value: 27.744441987259037 and parameters: {'n layers': 5, 'Hidden size': 19, 'Learning rate': 0.00013860332792689793, 'Dropout rate': 0.5339933438267718, 'Epochs': 360}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 40/160 - train_loss: 0.4565 - test_loss: 0.304897\n",
      "Epoch: 40/160 - train_loss: 0.4692 - test_loss: 0.310602\n",
      "Epoch: 120/160 - train_loss: 0.4388 - test_loss: 0.345103\n",
      "Epoch:  0/240 - train_loss: 1.8440 - test_loss: 1.105857\n",
      "Epoch: 80/160 - train_loss: 0.4181 - test_loss: 0.331148\n",
      "Epoch: 150/200 - train_loss: 0.4190 - test_loss: 0.304916\n",
      "Epoch: 150/200 - train_loss: 0.4899 - test_loss: 0.294148\n",
      "Epoch: 80/160 - train_loss: 0.4486 - test_loss: 0.328873\n",
      "Epoch: 188/190 - train_loss: 0.4220 - test_loss: 0.342878\n",
      "Epoch: 448/450 - train_loss: 0.4208 - test_loss: 0.319067\n",
      "Epoch: 189/190 - train_loss: 0.4226 - test_loss: 0.322825\n",
      "Epoch: 150/200 - train_loss: 0.4320 - test_loss: 0.320792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:35:40,040]\u001b[0m Trial 40 finished with value: 19.92170402039012 and parameters: {'n layers': 5, 'Hidden size': 103, 'Learning rate': 0.002581845622467325, 'Dropout rate': 0.372525277095365, 'Epochs': 190}. Best is trial 26 with value: 16.36386093376157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 449/450 - train_loss: 0.4167 - test_loss: 0.307749\n",
      "Epoch:  0/240 - train_loss: 1.3031 - test_loss: 0.779067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:35:42,937]\u001b[0m Trial 28 finished with value: 16.005045554923715 and parameters: {'n layers': 3, 'Hidden size': 41, 'Learning rate': 0.00631670167763886, 'Dropout rate': 0.608437208128078, 'Epochs': 450}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/160 - train_loss: 0.4273 - test_loss: 0.334952\n",
      "Epoch: 159/160 - train_loss: 0.4193 - test_loss: 0.325462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:36:06,295]\u001b[0m Trial 43 finished with value: 18.32771200773634 and parameters: {'n layers': 4, 'Hidden size': 114, 'Learning rate': 0.0031169853168137845, 'Dropout rate': 0.28291177453018956, 'Epochs': 200}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200 - train_loss: 0.4219 - test_loss: 0.317624\n",
      "Epoch: 120/160 - train_loss: 0.4280 - test_loss: 0.334058\n",
      "Epoch:  0/250 - train_loss: 0.8636 - test_loss: 0.674586\n",
      "Epoch: 120/160 - train_loss: 0.4172 - test_loss: 0.300696\n",
      "Epoch: 199/200 - train_loss: 0.4191 - test_loss: 0.337638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:36:39,273]\u001b[0m Trial 41 finished with value: 19.796888464352744 and parameters: {'n layers': 5, 'Hidden size': 103, 'Learning rate': 0.002711921722839895, 'Dropout rate': 0.31697158343692744, 'Epochs': 190}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/240 - train_loss: 0.4373 - test_loss: 0.335818\n",
      "Epoch: 199/200 - train_loss: 0.4194 - test_loss: 0.346664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:36:45,097]\u001b[0m Trial 42 finished with value: 19.53575104010392 and parameters: {'n layers': 5, 'Hidden size': 104, 'Learning rate': 0.0028666825814791103, 'Dropout rate': 0.2799818129318357, 'Epochs': 190}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120/160 - train_loss: 0.4246 - test_loss: 0.346981\n",
      "Epoch: 199/200 - train_loss: 0.4205 - test_loss: 0.316602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:36:54,242]\u001b[0m Trial 38 finished with value: 19.46231631031456 and parameters: {'n layers': 5, 'Hidden size': 93, 'Learning rate': 0.002081838947460536, 'Dropout rate': 0.3444767497510738, 'Epochs': 190}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159/160 - train_loss: 0.4257 - test_loss: 0.363169\n",
      "Epoch: 159/160 - train_loss: 0.4513 - test_loss: 0.292423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:37:07,363]\u001b[0m Trial 44 finished with value: 20.57939750437152 and parameters: {'n layers': 5, 'Hidden size': 99, 'Learning rate': 0.0029336654094999685, 'Dropout rate': 0.28975381485967233, 'Epochs': 160}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 04:37:07,707]\u001b[0m Trial 45 finished with value: 20.682270811407314 and parameters: {'n layers': 4, 'Hidden size': 29, 'Learning rate': 0.006755043314959045, 'Dropout rate': 0.4247401348704412, 'Epochs': 160}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200 - train_loss: 0.4628 - test_loss: 0.354971\n",
      "Epoch: 199/200 - train_loss: 0.4204 - test_loss: 0.320068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:37:18,634]\u001b[0m Trial 35 finished with value: 21.297600594525786 and parameters: {'n layers': 5, 'Hidden size': 87, 'Learning rate': 0.0019152667902534264, 'Dropout rate': 0.34526367991539053, 'Epochs': 180}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159/160 - train_loss: 0.4282 - test_loss: 0.327151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:37:19,760]\u001b[0m Trial 46 finished with value: 18.199169880152635 and parameters: {'n layers': 4, 'Hidden size': 116, 'Learning rate': 0.00735246876586996, 'Dropout rate': 0.2701507644195995, 'Epochs': 160}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/250 - train_loss: 0.4204 - test_loss: 0.340261\n",
      "Epoch: 60/240 - train_loss: 0.4287 - test_loss: 0.316662\n",
      "Epoch: 120/240 - train_loss: 0.4211 - test_loss: 0.312706\n",
      "Epoch: 50/200 - train_loss: 0.4433 - test_loss: 0.340592\n",
      "Epoch: 50/200 - train_loss: 0.7783 - test_loss: 0.650232\n",
      "Epoch: 50/200 - train_loss: 0.4315 - test_loss: 0.343251\n",
      "Epoch: 199/200 - train_loss: 0.4182 - test_loss: 0.304832\n",
      "Epoch: 50/200 - train_loss: 0.4427 - test_loss: 0.333944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:37:55,224]\u001b[0m Trial 19 finished with value: 21.763465208245464 and parameters: {'n layers': 3, 'Hidden size': 24, 'Learning rate': 0.002683851768680282, 'Dropout rate': 0.46153405883819065, 'Epochs': 200}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124/250 - train_loss: 0.4283 - test_loss: 0.328875\n",
      "Epoch: 120/240 - train_loss: 0.4251 - test_loss: 0.307414\n",
      "Epoch: 180/240 - train_loss: 0.4187 - test_loss: 0.372211\n",
      "Epoch: 50/200 - train_loss: 0.7663 - test_loss: 0.628110\n",
      "Epoch: 100/200 - train_loss: 0.4239 - test_loss: 0.360154\n",
      "Epoch: 100/200 - train_loss: 0.6046 - test_loss: 0.533432\n",
      "Epoch: 100/200 - train_loss: 0.4797 - test_loss: 0.306080\n",
      "Epoch: 100/200 - train_loss: 0.4205 - test_loss: 0.342941\n",
      "Epoch: 239/240 - train_loss: 0.4152 - test_loss: 0.342896\n",
      "Epoch: 50/200 - train_loss: 0.4272 - test_loss: 0.336687\n",
      "Epoch: 186/250 - train_loss: 0.4204 - test_loss: 0.324199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:39:03,728]\u001b[0m Trial 47 finished with value: 24.47298578986103 and parameters: {'n layers': 4, 'Hidden size': 26, 'Learning rate': 0.007068764750119693, 'Dropout rate': 0.5866268790191926, 'Epochs': 150}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200 - train_loss: 0.4330 - test_loss: 0.334576\n",
      "Epoch: 180/240 - train_loss: 0.4253 - test_loss: 0.326232\n",
      "Epoch: 150/200 - train_loss: 0.5282 - test_loss: 0.453717\n",
      "Epoch: 100/200 - train_loss: 0.5890 - test_loss: 0.500245\n",
      "Epoch: 150/200 - train_loss: 0.4461 - test_loss: 0.333126\n",
      "Epoch: 150/200 - train_loss: 0.4304 - test_loss: 0.349586\n",
      "Epoch: 50/200 - train_loss: 0.4515 - test_loss: 0.335614\n",
      "Epoch: 199/200 - train_loss: 0.4862 - test_loss: 0.324542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:39:43,567]\u001b[0m Trial 3 finished with value: 16.808748603988494 and parameters: {'n layers': 6, 'Hidden size': 8, 'Learning rate': 0.009528795394585465, 'Dropout rate': 0.44928623343587304, 'Epochs': 360}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200 - train_loss: 0.4942 - test_loss: 0.403227\n",
      "Epoch: 239/240 - train_loss: 0.4268 - test_loss: 0.292398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:39:50,163]\u001b[0m Trial 11 finished with value: 28.757766702643625 and parameters: {'n layers': 6, 'Hidden size': 343, 'Learning rate': 0.00015036753387472472, 'Dropout rate': 0.6500391324083719, 'Epochs': 500}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 04:39:50,228]\u001b[0m Trial 48 finished with value: 19.856011446326995 and parameters: {'n layers': 4, 'Hidden size': 28, 'Learning rate': 0.007243750258324411, 'Dropout rate': 0.3020292439322977, 'Epochs': 240}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 248/250 - train_loss: 0.4825 - test_loss: 0.297739\n",
      "Epoch: 249/250 - train_loss: 0.4871 - test_loss: 0.314094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:39:51,584]\u001b[0m Trial 49 finished with value: 18.07325226137753 and parameters: {'n layers': 4, 'Hidden size': 32, 'Learning rate': 0.006918143979339606, 'Dropout rate': 0.2470163751627331, 'Epochs': 250}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200 - train_loss: 0.4350 - test_loss: 0.333300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:39:57,578]\u001b[0m Trial 2 finished with value: 20.836329367238527 and parameters: {'n layers': 4, 'Hidden size': 131, 'Learning rate': 0.002994020402797443, 'Dropout rate': 0.046858054272111004, 'Epochs': 210}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/200 - train_loss: 0.4203 - test_loss: 0.337536\n",
      "Epoch: 150/200 - train_loss: 0.5013 - test_loss: 0.401765\n",
      "Epoch: 199/200 - train_loss: 0.4177 - test_loss: 0.302629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:40:02,909]\u001b[0m Trial 4 finished with value: 19.00721426798384 and parameters: {'n layers': 5, 'Hidden size': 233, 'Learning rate': 0.002473053934756489, 'Dropout rate': 0.5324715464716254, 'Epochs': 130}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/200 - train_loss: 0.4229 - test_loss: 0.306200\n",
      "Epoch: 150/200 - train_loss: 0.4293 - test_loss: 0.327586\n",
      "Epoch: 199/200 - train_loss: 0.4870 - test_loss: 0.347418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:40:11,968]\u001b[0m Trial 17 finished with value: 23.018857125573533 and parameters: {'n layers': 5, 'Hidden size': 11, 'Learning rate': 0.0002018973264388143, 'Dropout rate': 0.17507178759295142, 'Epochs': 290}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200 - train_loss: 0.4432 - test_loss: 0.316244\n",
      "Epoch: 199/200 - train_loss: 0.4866 - test_loss: 0.317903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 04:40:19,388]\u001b[0m Trial 9 finished with value: 23.87264417403412 and parameters: {'n layers': 4, 'Hidden size': 154, 'Learning rate': 0.004958178925561266, 'Dropout rate': 0.0585033860325883, 'Epochs': 100}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 04:40:23,321]\u001b[0m Trial 13 finished with value: 21.96315351031092 and parameters: {'n layers': 6, 'Hidden size': 59, 'Learning rate': 0.0009025594488864799, 'Dropout rate': 0.11723240724431074, 'Epochs': 250}. Best is trial 28 with value: 16.005045554923715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200 - train_loss: 0.4195 - test_loss: 0.315682\n",
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  TT Huế\n",
      "  Value:  16.005045554923715\n",
      "optimize result of city: TT Huế\n",
      "kết thúc study trong: 281\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Main Cell for optimize\n",
    "#########################\n",
    "dt_started = datetime.now()\n",
    "\n",
    "##################################################\n",
    "# Input param for Optimize Run\n",
    "ntry = 50\n",
    "njob = -1\n",
    "\n",
    "# Lưu thông tin traceback study và error city trong quá trình optimize\n",
    "l_study_city ={}\n",
    "# l_errCity =[]\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "  best_param = pd.DataFrame()\n",
    "  l_studies = {}\n",
    "  l_errCity =[]\n",
    "\n",
    "  for city in cities:\n",
    "    # Use Tree-structured Parzen Estimator sampler to minimise RMSE\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "\n",
    "    # truyền multiple param vào trong biến trial\n",
    "    obj_func = lambda trial: objective(trial, city)\n",
    "\n",
    "    try:\n",
    "      # Optimise over 100 trials\n",
    "      study.optimize(obj_func, n_trials=ntry, n_jobs=njob)\n",
    "\n",
    "      # Print results\n",
    "      print(\"Study statistics for : \")\n",
    "      print(\"  Number of finished trials: \", len(study.trials))\n",
    "      \n",
    "      print(\"Best trial of city: \",city)\n",
    "      best_trial = study.best_trial\n",
    "      print(\"  Value: \", best_trial.value)   \n",
    "\n",
    "      # lưu best param vào trong biến toàn cục\n",
    "      one_city_param = pd.DataFrame({\n",
    "                              'City': city,\n",
    "                              'Alg_name': 'transformer',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': ntry,\n",
    "                              'n Feature': 3, # set cứng\n",
    "                              'Batch Size': 16, # set cứng\n",
    "                              'Lookback Window': 3, # set cứng\n",
    "                              'Epochs': best_trial.params['Epochs'],\n",
    "                              'Hidden Size': best_trial.params['Hidden size'],\n",
    "                              'n Layers': best_trial.params['n layers'],\n",
    "                              'Learning rate': best_trial.params['Learning rate'], \n",
    "                              'Num. filters': '', # Transformer không dùng\n",
    "                              'Dropout rate': best_trial.params['Dropout rate']}, index=[0])\n",
    "      one_city_param.to_excel(prj_path_opt+'/tf/diarrhoea_opt_hyperparam_transformer_'+city+'.xlsx')\n",
    "      best_param = best_param.append(one_city_param)\n",
    "    except:# có error thì lưu vào l_errCity để check lại sau \n",
    "      l_errCity.append(city)\n",
    "    # Plot result\n",
    "    l_studies[city] = study # thêm vào danh sách sài sau\n",
    "    print('optimize result of city: '+ city)\n",
    "    # optuna.visualization.plot_optimization_history(study)\n",
    "    # optuna.visualization.plot_param_importances(study)\n",
    "    # optuna.visualization.plot_slice(study)\n",
    "  \n",
    "  best_param.to_excel(prj_path_opt+'/tf/diarrhoea_opt_hyperparam_transformer.xlsx')\n",
    "\n",
    "dt_ended = datetime.now()\n",
    "print('kết thúc study trong:', round((dt_ended - dt_started).total_seconds()/60))\n",
    "# print(l_errCity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RbjNytCjdHLl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ok\":true,\"result\":{\"message_id\":471,\"sender_chat\":{\"id\":-1001712314864,\"title\":\"PTN_Announcement\",\"username\":\"ptn_announcement\",\"type\":\"channel\"},\"chat\":{\"id\":-1001712314864,\"title\":\"PTN_Announcement\",\"username\":\"ptn_announcement\",\"type\":\"channel\"},\"date\":1676349624,\"text\":\"Server Ch\\u1ea1y Xong TF\"}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def send_to_telegram(message):\n",
    "\n",
    "    apiToken = '5908735099:AAGVSLrW62aXPBP-GrMvxoVgMsuJxXJpP1Q'\n",
    "    chatID = '@ptn_announcement'\n",
    "    apiURL = f'https://api.telegram.org/bot{apiToken}/sendMessage'\n",
    "\n",
    "    try:\n",
    "        response = requests.post(apiURL, json={'chat_id': chatID, 'text': message})\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "send_to_telegram(\"Server Chạy Xong TF\" )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "24f3299fa11d098f3e36f80146bbe61fdadb7bfe8872ee0c4a379787469f5f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
