{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import  RandomForest, LinearRegressionModel, LightGBMModel, \\\n",
    "                        CatBoostModel,  BlockRNNModel, NBEATSModel, NHiTSModel, \\\n",
    "                        TCNModel, TFTModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = '../'\n",
    "data_path = prj_path + \"data/new_data/DH/squeezed/\"\n",
    "prj_path_opt= prj_path + \"optimize_hyperparam/opt_results/\"\n",
    "output_process = prj_path + \"data/new_data/DH/processed_data/\"\n",
    "output_featureselection = prj_path + \"data/new_data/DH/feature_selection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = [\n",
    "        'An Giang', 'BR V≈©ng T√†u', 'B√¨nh Ph∆∞·ªõc', 'B√¨nh Thu·∫≠n', 'B√¨nh ƒê·ªãnh',\n",
    "        'B·∫°c Li√™u', 'B·∫Øc K·∫°n', 'B·∫Øc Giang', 'Cao B·∫±ng', 'C√† Mau',\n",
    "        'C·∫ßn Th∆°', 'Gia Lai', 'H√† Giang', 'H√† N·ªôi', 'H√† Tƒ©nh',\n",
    "        'H√≤a B√¨nh','H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'H·∫£i Ph√≤ng', 'Kh√°nh H√≤a', 'Ki√™n Giang',\n",
    "        'Kon Tum', 'Lai Ch√¢u', 'Long An', 'L√†o Cai', 'L√¢m ƒê·ªìng',\n",
    "        'L·∫°ng S∆°n','Nam ƒê·ªãnh', 'Ngh·ªá An', 'Ninh B√¨nh', 'Ninh Thu·∫≠n',\n",
    "        'Ph√∫ Th·ªç', 'Ph√∫ Y√™n', 'Qu·∫£ng B√¨nh', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i',\n",
    "        'Qu·∫£ng Ninh', 'Qu·∫£ng Tr·ªã', 'S√≥c TrƒÉng', 'S∆°n La', 'TT Hu·∫ø',\n",
    "        'Thanh H√≥a', 'Th√°i B√¨nh', 'Th√°i Nguy√™n', 'Ti·ªÅn Giang', 'Tr√† Vinh',\n",
    "        'Tuy√™n Quang', 'T√¢y Ninh', 'Vƒ©nh Ph√∫c', 'Y√™n B√°i', 'ƒêi·ªán Bi√™n',\n",
    "        'ƒê√† N·∫µng', 'ƒê·∫Øk N√¥ng', 'ƒê·∫Øk L·∫Øk', 'ƒê·ªìng Th√°p'\n",
    "]\n",
    "cities = ['An Giang', 'BR V≈©ng T√†u', 'B√¨nh Ph∆∞·ªõc', 'B√¨nh Thu·∫≠n', 'B√¨nh ƒê·ªãnh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters as args using the Configuration class\n",
    "class Configuration():\n",
    "    def __init__(self):\n",
    "        # l·∫•y b·ªô test d√†i 36 th√°ng = 3 nƒÉm\n",
    "        self.test_size = 36\n",
    "        # l√† nh√¨n v√†o d·ªØ li·ªáu tr∆∞·ªõc 3 th√°ng v√† d·ª± ph√≥ng        \n",
    "        self.look_back = 3\n",
    "        # d·ª± ph√≥ng n-step trong 6 th√°ng\n",
    "        self.n_predicted_period_months = 6\n",
    "        self.n_features = 3\n",
    "        self.seed = 42\n",
    "        # m·ªói ph·∫ßn t·ª≠ x trong t·∫≠p suppervise c√≥ ƒë·ªô l·ªõn l√† 16 = 16 th√°ng\n",
    "        self.batch_size = 16\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.epochs = 300\n",
    "        #others\n",
    "        self.labels = \"Dengue_fever_rates\"\n",
    "        # Input param for Optimize Run\n",
    "        self.ntry = 1\n",
    "        self.njob = 1\n",
    "\n",
    "args = Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = RandomForest(lags = args.look_back,\n",
    "#                     lags_past_covariates = [-1,-2,-3],\n",
    "#                     input_chunk_length = 5)\n",
    "# model2 = RandomForest(lags = 4,\n",
    "#                     lags_past_covariates = [-2,-3,-4])\n",
    "model3 = RandomForest(lags = 5,\n",
    "                    lags_past_covariates = [-3,-4,-5])\n",
    "specific_data = pd.read_csv(output_process+city+'_train_preprocessed.csv', parse_dates=True, index_col= None, encoding = 'unicode_escape')\n",
    "df_train, df_valid = split_data(specific_data, args.look_back,1)\n",
    "x_train = TimeSeries.from_dataframe(df_train, \"year_month\", feature_list)\n",
    "y_train = TimeSeries.from_dataframe(df_train, \"year_month\", labels)\n",
    "\n",
    "x_test = TimeSeries.from_dataframe(df_valid, \"year_month\", feature_list)\n",
    "y_test = TimeSeries.from_dataframe(df_valid, \"year_month\", labels)\n",
    "\n",
    "model1.fit(y_train, past_covariates = x_train)\n",
    "past_covariates_val = x_test\n",
    "# prediction = model3.predict(len(y_test), past_covariates = past_covariates_val, num_samples=1)\n",
    "prediction = model1.predict(len(y_test)-2+4, past_covariates = past_covariates_val, num_samples=1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_all_city_data():\n",
    "  cities_data = {}  \n",
    "  for city in cities:\n",
    "    city_result = pd.read_excel(prj_path+'data/new_data/DH/squeezed/squeezed_'+city+'.xlsx')  \n",
    "    \"\"\"Get all data from all city in 1997 - 2016\"\"\" \n",
    "    city_result = city_result.loc[city_result['year_month'] < '2017-1-1'] \n",
    "    cities_data[city] = city_result\n",
    "  return cities_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data (pre-)processing functions\n",
    "# modification\n",
    "def get_city_data(city_name, dict_full_data):\n",
    "    \"\"\"Returns Diarrhoea rate and climate data\"\"\" \n",
    "    city_data = dict_full_data[city_name].drop(columns=['Diarrhoea_cases','Diarrhoea_rates', 'province',\n",
    "                                                        'Influenza_rates','Influenza_cases',\n",
    "                                                        'Dengue_fever_cases', 'year', 'month'], \n",
    "                                                                  axis=1, \n",
    "                                                                  inplace=False)    \n",
    "    return city_data\n",
    "\n",
    "def convert_to_stationary(city_data):\n",
    "    \"\"\"Subtracts previous value for all cols except disease rates\"\"\"\n",
    "    for col_name in city_data.columns:\n",
    "        if col_name != 'Diarrhoea_rates':\n",
    "            try:\n",
    "                city_data[col_name] = city_data[col_name] - city_data[col_name].shift()\n",
    "            except:\n",
    "                print(col_name)\n",
    "    return city_data\n",
    "\n",
    "def impute_missing_value(city_data):\n",
    "    \"\"\"\n",
    "    Imputes 0 for first 12 months, \n",
    "    last year's value for months 12-24, \n",
    "    and minimum value of last two years for months 25+\n",
    "    \"\"\"\n",
    "    for col in city_data.columns:\n",
    "        for index in range(len(city_data[col])):\n",
    "            if np.isnan(city_data[col].iloc[index]):\n",
    "                if index < 12:\n",
    "                    city_data[col].iloc[index] = 0\n",
    "                elif index >= 12 and index <= 24:\n",
    "                    city_data[col].iloc[index] = city_data[col].iloc[index - 12]\n",
    "                else:\n",
    "                    city_data[col].iloc[index] = min(city_data[col].iloc[index - 12], city_data[col].iloc[index - 24])\n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_full_data(dict_full_data):\n",
    "    climate_and_disease_feats = ['Total_Evaporation',\n",
    "       'Total_Rainfall', 'Max_Daily_Rainfall', 'n_raining_days',\n",
    "       'Average_temperature', 'Max_Average_Temperature',\n",
    "       'Min_Average_Temperature', 'Max_Absolute_Temperature',\n",
    "       'Min_Absolute_Temperature', 'Average_Humidity', 'Min_Humidity',\n",
    "       'n_hours_sunshine', 'Dengue_fever_rates']\n",
    "    for city in cities:\n",
    "        city_data = get_city_data(city_name=city,dict_full_data = dict_full_data)\n",
    "        city_data_features = city_data[climate_and_disease_feats]\n",
    "        city_data_features = impute_missing_value(city_data_features)\n",
    "        city_data_features = convert_to_stationary(city_data_features)\n",
    "        city_data_features.dropna(inplace=True)\n",
    "        city_data_features.loc[:, \"year_month\"] = city_data[\"year_month\"]\n",
    "        dict_full_data[city] = city_data_features\n",
    "    return dict_full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, look_back, n_nextstep = args.n_predicted_period_months):\n",
    "    \"\"\"Splits data into train and test sets based on args (Configuration class)\"\"\"\n",
    "    train = data[: -args.test_size]    \n",
    "    test = data[-args.test_size - look_back-(n_nextstep - 1): ]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_supervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(data,  d_out, d_in, features_list=[]):\n",
    "    \"\"\"\n",
    "    Frames time-series as supervised learning dataset.\n",
    "    \n",
    "    Args:\n",
    "      d_in: lookback window\n",
    "      d_out: number of predicted months\n",
    "      features_list: list of all features **where last col is the disease incidence**\n",
    "\n",
    "    Returns:\n",
    "      Numpy arrays of disease incidence (y) and other predictors (X)\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for index, _ in enumerate(data):\n",
    "        in_end = index + d_in\n",
    "        out_end = in_end + d_out\n",
    "        if out_end <= len(data):\n",
    "            if len(features_list) == 0 :\n",
    "                X.append(data[index: in_end, :])\n",
    "            else:\n",
    "                X.append(data[index: in_end, features_list])\n",
    "            y.append(data[out_end-1: out_end, -1])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_252023.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_252023.ipynb#Y135sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# prediction = model3.predict(len(y_test), past_covariates = past_covariates_val, num_samples=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_252023.ipynb#Y135sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m prediction \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39mpredict(\u001b[39mlen\u001b[39m(y_test)\u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mlook_back, past_covariates \u001b[39m=\u001b[39m past_covariates_val, num_samples\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/trinhtruc/Documents/STUDY/NCKH/Source/Source_14012023_v4/optimize_hyperparam/optuna_ml_252023.ipynb#Y135sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m np\u001b[39m.\u001b[39;49marray(prediction)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32."
     ]
    }
   ],
   "source": [
    "model1 = RandomForest(lags = 3,\n",
    "                    lags_past_covariates = [-1,-2,-3])\n",
    "# model2 = RandomForest(lags = 4,\n",
    "#                     lags_past_covariates = [-2,-3,-4])\n",
    "# model3 = RandomForest(lags = 5,\n",
    "#                     lags_past_covariates = [-3,-4,-5])\n",
    "specific_data = pd.read_csv(output_process+city+'_train_preprocessed.csv', parse_dates=True, index_col= None, encoding = 'unicode_escape')\n",
    "df_train, df_valid = split_data(specific_data, args.look_back,1)\n",
    "x_train = TimeSeries.from_dataframe(df_train, \"year_month\", feature_list)\n",
    "y_train = TimeSeries.from_dataframe(df_train, \"year_month\", labels)\n",
    "\n",
    "x_test = TimeSeries.from_dataframe(df_valid, \"year_month\", feature_list)\n",
    "y_test = TimeSeries.from_dataframe(df_valid, \"year_month\", labels)\n",
    "\n",
    "model1.fit(y_train, past_covariates = x_train)\n",
    "past_covariates_val = x_test\n",
    "# prediction = model3.predict(len(y_test), past_covariates = past_covariates_val, num_samples=1)\n",
    "prediction = model1.predict(len(y_test)-args.look_back, past_covariates = past_covariates_val, num_samples=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5503514 , 0.7943897 , 0.54379149, 0.52382343, 0.54897979,\n",
       "       0.55659009, 0.54082459, 0.54310631, 0.53979221, 0.54582229,\n",
       "       0.54382109, 0.54297397, 0.45361153, 0.52414221, 0.5254382 ,\n",
       "       0.58274941, 0.53918262, 0.54095845, 0.54509208, 0.53932759,\n",
       "       0.54133891, 0.55079078, 0.54549301, 0.55991313, 0.75319625,\n",
       "       0.50700563, 0.46905401, 0.57559314, 0.54916772, 0.55059619,\n",
       "       0.55106765, 0.55230924, 0.54698121, 0.54069252, 0.54006857,\n",
       "       0.54600497])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(prediction._xa).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(df_train, df_eval, model, feature_list , labels, scaler):\n",
    "  \"\"\"\n",
    "  $df: pandas.DataFrame object containing data for training and testing model:\n",
    "  $model: darts model object\n",
    "  $feature_list: Names of the features used as model input\n",
    "  $label: the value the model will be trained to predict\n",
    "  $scaler: scaler object. Note: the scaler will be fitted on training data and applied to test data\n",
    "  $lags: how much to look back into the past to output prediction\n",
    "  $split_index: the point at which to divide train and test_data\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  x_train = TimeSeries.from_dataframe(df_train, \"year_month\", feature_list)\n",
    "  y_train = TimeSeries.from_dataframe(df_train, \"year_month\", labels)\n",
    "\n",
    "  x_test = TimeSeries.from_dataframe(df_eval, \"year_month\", feature_list)\n",
    "  y_test = TimeSeries.from_dataframe(df_eval, \"year_month\", labels)\n",
    "\n",
    "  model.fit(y_train, past_covariates = x_train)\n",
    "\n",
    "  prediction = model.predict(len(y_test)-args.look_back, past_covariates = x_test, num_samples=1)\n",
    "\n",
    "  y_true = scaler.inverse_transform(df_eval.iloc[:,:-1])[:,[-1]].reshape(len(df_eval))[args.look_back:]\n",
    "\n",
    "  df_eval[labels][args.look_back:] = np.array(prediction._xa).squeeze()\n",
    "  y_pred = scaler.inverse_transform(df_eval.iloc[args.look_back:,:-1])[:,[-1]].reshape(len(prediction))\n",
    "\n",
    "  # df_compare_test_predict = pd.DataFrame({'y_true':y_true, 'y_pred':y_pred})\n",
    "  # df_compare_test_predict.plot()\n",
    "  # plt.legend()\n",
    "  # plt.show()\n",
    "\n",
    "  mse = mean_squared_error(y_true, y_pred)\n",
    "  mae = mean_absolute_error(y_true, y_pred)\n",
    "  rmse = mse**0.5\n",
    "  mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "  print(f\"mean_squared_error: {mse:.4f}\")\n",
    "  print(f\"rmse: {rmse}\")\n",
    "  print(f\"mape: {mape}\")\n",
    "  return model, y_true, y_pred, mse, mae, rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction_for_location(df_train, df_eval, model, location, feature_list, \n",
    "                                                labels, scaler):\n",
    "    \"\"\"train and generate prediction for a province\n",
    "    df: DataFrame object containing features and label(s) for training model\n",
    "    localtion: location_name\n",
    "    feature_list: list of features used as model input,  must be among the column names of df\n",
    "    labels: the values model will be trained to predict\n",
    "    scaler: sklearn scaler object\n",
    "    lags: how long into the past to look back when making prediction\n",
    "    split_index: the point at which to divide data into the train and test subsets.\n",
    "    \"\"\"\n",
    "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
    "    df_prediction = pd.DataFrame({\"Date\": df_eval[\"year_month\"][-len(prediction_inverse):],\n",
    "                                  \"Observed\": y_true[-len(prediction_inverse):],\n",
    "                                  \"1-month\": prediction_inverse})\n",
    "    \n",
    "    df_prediction[\"City\"] = location\n",
    "    df_prediction[\"RMSE_1-month\"] = rmse\n",
    "    df_prediction[\"MAE_1-month\"] = mae\n",
    "    df_prediction[\"MAPE_1-month\"] = mape\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataWithSelectedFeature(city, next_predicted_month):\n",
    "  selected_feature = []\n",
    "  df = pd.read_csv(output_featureselection+str(next_predicted_month)+\"step_feature_selection_3_most.csv\", encoding = 'unicode_escape')\n",
    "  for row in range(len(df)):\n",
    "    if (df[\"City\"][row] == city):\n",
    "      selected_feature.append(df[\"1st_Feature\"][row])\n",
    "      selected_feature.append(df[\"2nd_Feature\"][row])\n",
    "      selected_feature.append(df[\"3rd_Feature\"][row])\n",
    "  return selected_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective and Suggest Hyperparams of Darts Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(model_name, trial, city, nstep):   \n",
    "    specific_data = pd.read_csv(output_process+city+'_train_preprocessed.csv', parse_dates=True, index_col= None, encoding = 'unicode_escape')\n",
    "    scaler = joblib.load(output_process+city+'_train_scalerMinMaxNorm.save') #ok\n",
    "\n",
    "    df_train, df_valid = split_data(specific_data, args.look_back,nstep)\n",
    "    selected_features = getDataWithSelectedFeature(city, nstep)\n",
    "\n",
    "    lags_by_nstep = args.look_back + nstep - 1\n",
    "    lags_past_covariates_by_nstep = [-lags_by_nstep+2,-lags_by_nstep+1,-lags_by_nstep] #M·∫£ng n√†y ch·ª©a ba gi√° tr·ªã t∆∞∆°ng ·ª©ng cho args.lookback 3\n",
    "\n",
    "\n",
    "\n",
    "    if model_name == \"RandomForest\":\n",
    "      random_state = trial.suggest_int('random_state', 0, 42)\n",
    "      n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "      max_depth = trial.suggest_int('max_depth', 1, 15)\n",
    "      # Create the RandomForest model\n",
    "      model = RandomForest(\n",
    "                    lags = lags_by_nstep,\n",
    "                    lags_past_covariates = lags_past_covariates_by_nstep,\n",
    "                    output_chunk_length = 1,\n",
    "                    n_estimators = n_estimators,\n",
    "                    max_depth = max_depth,\n",
    "                    random_state=random_state)\n",
    "    elif model_name == 'TFTModel':\n",
    "      # Define the hyperparameters to optimize\n",
    "      random_state = trial.suggest_int('random_state', 0, 42)\n",
    "      dropout = trial.suggest_uniform('dropout', 0.01, 0.8)\n",
    "      n_epochs = trial.suggest_int('n_epochs', 50, 200)\n",
    "\n",
    "      # Create the TFTModel model\n",
    "      model = TFTModel(\n",
    "                    input_chunk_length = lags_by_nstep,\n",
    "                    output_chunk_length = 1,\n",
    "                    add_relative_index = True,\n",
    "                    dropout = dropout,\n",
    "                    n_epochs = n_epochs ,\n",
    "                    random_state=random_state)\n",
    "    elif model_name == 'NHiTSModel':\n",
    "      #suggest hyperparams\n",
    "      random_state = trial.suggest_int('random_state', 0, 42)\n",
    "      dropout = trial.suggest_uniform('dropout', 0.01, 0.80)\n",
    "      n_epochs = trial.suggest_int('n_epochs', 100, 500, step=10)\n",
    "      MaxPool1d = trial.suggest_categorical('MaxPool1d', [True, False])\n",
    "\n",
    "      model = NHiTSModel(\n",
    "                          input_chunk_length = lags_by_nstep,\n",
    "                          output_chunk_length = 1,\n",
    "                          MaxPool1d = MaxPool1d,\n",
    "                          dropout = dropout,\n",
    "                          n_epochs = n_epochs ,\n",
    "                          random_state=random_state)\n",
    "    elif model_name == 'LinearRegressionModel':\n",
    "      random_state = trial.suggest_int('random_state', 0, 43)\n",
    "      \n",
    "      # Create the  model\n",
    "      model = LinearRegressionModel(\n",
    "                      lags = lags_by_nstep,\n",
    "                      lags_past_covariates = lags_past_covariates_by_nstep,\n",
    "                      output_chunk_length = 1,\n",
    "                      random_state=random_state)\n",
    "    elif model_name == \"BlockRNNModel\":\n",
    "      #suggest hyperparams\n",
    "      random_state = trial.suggest_int('random_state', 0, 1000)\n",
    "      n_rnn_layers = trial.suggest_int('n_rnn_layers', 1, 3)\n",
    "      dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
    "      hidden_dim = trial.suggest_int('n_rnn_layers', 5, 20)\n",
    "      n_epochs = trial.suggest_int('n_epochs', 50, 200)\n",
    "\n",
    "      model = BlockRNNModel(\n",
    "                          input_chunk_length = lags_by_nstep,\n",
    "                          output_chunk_length = 1,\n",
    "                          hidden_dim = hidden_dim,\n",
    "                          n_rnn_layers = n_rnn_layers,\n",
    "                          dropout = dropout,\n",
    "                          n_epochs = n_epochs,\n",
    "                          random_state=random_state)\n",
    "      \n",
    "    elif model_name == \"CatBoostModel\":\n",
    "      #suggest hyperparams\n",
    "      learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
    "      n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "      max_depth = trial.suggest_int('max_depth', 1, 15)\n",
    "      random_state = trial.suggest_int('random_state', 0, 1000)\n",
    "      likelihood = trial.suggest_categorical('likelihood', ['quantile'])\n",
    "      quantiles =  trial.suggest_categorical('quantiles', [None, [0.1, 0.5, 0.9]])\n",
    "      bagging_temperature = trial.suggest_float('bagging_temperature', 0.01, 100.0)\n",
    "      border_count = trial.suggest_int('border_count', 1, 255)\n",
    "      l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 0.1, 10)\n",
    "      random_strength = trial.suggest_float('random_strength', 0.1, 10)\n",
    "      model = CatBoostModel(\n",
    "                            lags=lags_by_nstep,\n",
    "                            lags_past_covariates=lags_past_covariates_by_nstep, \n",
    "                            learning_rate=learning_rate,\n",
    "                            n_estimators=n_estimators,\n",
    "                            max_depth=max_depth, \n",
    "                            output_chunk_length = 1,\n",
    "                            likelihood = likelihood,\n",
    "                            quantiles = quantiles,\n",
    "                            bagging_temperature = bagging_temperature,\n",
    "                            border_count = border_count,\n",
    "                            l2_leaf_reg = l2_leaf_reg,\n",
    "                            random_strength = random_strength,\n",
    "                            random_state=random_state)\n",
    "    \n",
    "    elif model_name == \"NBEATSModel\":\n",
    "      random_state = trial.suggest_int('random_state', 0, 42)\n",
    "      dropout = trial.suggest_uniform('dropout', 0.01, 0.80)\n",
    "      n_epochs = trial.suggest_int('n_epochs', 50, 200)\n",
    "\n",
    "      pl_trainer_kwargs = {\n",
    "              \"accelerator\": \"gpu\",\n",
    "              \"devices\": -1,\n",
    "              \"auto_select_gpus\": True,\n",
    "          }\n",
    "      model = NBEATSModel(\n",
    "                            input_chunk_length = lags_by_nstep,\n",
    "                            output_chunk_length = 1,\n",
    "                            dropout = dropout,\n",
    "                            n_epochs = n_epochs ,\n",
    "                            pl_trainer_kwargs = pl_trainer_kwargs,\n",
    "                            random_state=random_state)\n",
    "  \n",
    "    elif model_name == \"TCNModel\":\n",
    "      params = {\n",
    "        'kernel_size': trial.suggest_int(\"kernel_size\", 2, 5),\n",
    "        'num_filters': trial.suggest_int(\"num_filters\", 1, 5),\n",
    "        'weight_norm': trial.suggest_categorical(\"weight_norm\", [False, True]),\n",
    "        'dilation_base': trial.suggest_int(\"dilation_base\", 2, 4),\n",
    "        'dropout': trial.suggest_float(\"dropout\", 0.0, 0.4),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 5e-5, 1e-3, log=True),\n",
    "        'include_year': trial.suggest_categorical(\"year\", [False, True]),\n",
    "        'n_epochs': trial.suggest_int(\"n_epochs\", 100, 300),\n",
    "      }\n",
    "\n",
    "      # select input and output chunk lengths\n",
    "\n",
    "      params['input_chunk_length'] = lags_by_nstep\n",
    "      params['output_chunk_length'] = 1  \n",
    "   \n",
    "\n",
    "      # optionally also add the (scaled) year value as a past covariate\n",
    "      if params['include_year']:\n",
    "          encoders = {\"datetime_attribute\": {\"past\": [\"year\"]},\n",
    "                      \"transformer\": Scaler()}\n",
    "      else:\n",
    "          encoders = None\n",
    "      params['encoders'] = encoders\n",
    "\n",
    "      pl_trainer_kwargs = {\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\": -1,\n",
    "            \"auto_select_gpus\": True,\n",
    "        }\n",
    "     \n",
    "\n",
    "      param = params\n",
    "      model = TCNModel(\n",
    "          input_chunk_length=param['input_chunk_length'],\n",
    "          output_chunk_length=param['output_chunk_length'],\n",
    "          batch_size=16,\n",
    "          n_epochs=param['n_epochs'],\n",
    "          nr_epochs_val_period=1,\n",
    "          kernel_size=param['kernel_size'],\n",
    "          num_filters=param['num_filters'],\n",
    "          weight_norm=param['weight_norm'],\n",
    "          dilation_base=param['dilation_base'],\n",
    "          dropout=param['dropout'],\n",
    "          optimizer_kwargs={\"lr\": param['learning_rate']},\n",
    "          add_encoders=param['encoders'],\n",
    "          likelihood=GaussianLikelihood(),\n",
    "          pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "          model_name=\"tcn_model\",\n",
    "          force_reset=True,\n",
    "          save_checkpoints=True,\n",
    "      )\n",
    "    elif model_name == \"LightGBMModel\":\n",
    "      params = {\n",
    "        \"lags\": lags_by_nstep,\n",
    "        \"lags_past_covariates\": lags_past_covariates_by_nstep,\n",
    "        \"random_state\": trial.suggest_int(\"random_state\", 0, 999),\n",
    "        \"multi_models\": trial.suggest_categorical(\"multi_models\", [True, False]),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.5),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'verbose': -1,\n",
    "        'likelihood' : trial.suggest_categorical(\"likelihood\", [\"quantile\"])\n",
    "      }\n",
    "\n",
    "      param = params\n",
    "      model = LightGBMModel(\n",
    "          lags = param['lags'],\n",
    "          lags_past_covariates = param['lags_past_covariates'],\n",
    "          output_chunk_length = 1,\n",
    "          random_state = param['random_state'],\n",
    "          multi_models = param['multi_models'],\n",
    "          likelihood = param['likelihood'],\n",
    "          num_leaves = param['num_leaves'],\n",
    "          learning_rate = param['learning_rate'],\n",
    "          feature_fraction = param['feature_fraction'],\n",
    "          bagging_fraction = param['bagging_fraction'],\n",
    "          min_child_samples = param['min_child_samples'],\n",
    "          lambda_l1 = param['lambda_l1'],\n",
    "          verbose = param['verbose']\n",
    "      )\n",
    "    \n",
    "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
    "                                                labels=args.labels, scaler=scaler)\n",
    "\n",
    "    return mae_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main run optimize and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:03,329] A new study created in memory with name: RandomForest\n",
      "[I 2023-10-26 16:04:03,463] Trial 0 finished with value: 5.2964356941984585 and parameters: {'random_state': 21, 'n_estimators': 68, 'max_depth': 7}. Best is trial 0 with value: 5.2964356941984585.\n",
      "[I 2023-10-26 16:04:03,463] A new study created in memory with name: RandomForest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 103.3371\n",
      "rmse: 10.165487584586481\n",
      "mape: 47673.36442579695\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  An Giang\n",
      "  Value:  5.2964356941984585\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:03,728] Trial 0 finished with value: 10.28214613025141 and parameters: {'random_state': 36, 'n_estimators': 195, 'max_depth': 9}. Best is trial 0 with value: 10.28214613025141.\n",
      "[I 2023-10-26 16:04:03,729] A new study created in memory with name: RandomForest\n",
      "[I 2023-10-26 16:04:03,886] Trial 0 finished with value: 11.98246205749524 and parameters: {'random_state': 20, 'n_estimators': 119, 'max_depth': 12}. Best is trial 0 with value: 11.98246205749524.\n",
      "[I 2023-10-26 16:04:03,886] A new study created in memory with name: RandomForest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 206.4195\n",
      "rmse: 14.367308228499391\n",
      "mape: 5.840052542801727\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  BR V≈©ng T√†u\n",
      "  Value:  10.28214613025141\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 290.4715\n",
      "rmse: 17.04322590625228\n",
      "mape: 1.9064474351343128\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh Ph∆∞·ªõc\n",
      "  Value:  11.98246205749524\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:04,077] Trial 0 finished with value: 3.339688844455983 and parameters: {'random_state': 11, 'n_estimators': 165, 'max_depth': 10}. Best is trial 0 with value: 3.339688844455983.\n",
      "[I 2023-10-26 16:04:04,077] A new study created in memory with name: RandomForest\n",
      "[I 2023-10-26 16:04:04,205] Trial 0 finished with value: 3.2714942337812287 and parameters: {'random_state': 28, 'n_estimators': 114, 'max_depth': 5}. Best is trial 0 with value: 3.2714942337812287.\n",
      "[I 2023-10-26 16:04:04,206] A new study created in memory with name: LinearRegressionModel\n",
      "[W 2023-10-26 16:04:04,221] Trial 0 failed with parameters: {'random_state': 30} because of the following error: ValueError(\"Input X contains infinity or a value too large for dtype('float64').\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 21, in train_and_evaluate\n",
      "    prediction = model.predict(len(y_test)-args.look_back, past_covariates = x_test, num_samples=1)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/regression_model.py\", line 994, in predict\n",
      "    prediction = self._predict_and_sample(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/linear_regression_model.py\", line 279, in _predict_and_sample\n",
      "    return super()._predict_and_sample(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/regression_model.py\", line 1033, in _predict_and_sample\n",
      "    prediction = self.model.predict(x, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py\", line 386, in predict\n",
      "    return self._decision_function(X)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py\", line 369, in _decision_function\n",
      "    X = self._validate_data(X, accept_sparse=[\"csr\", \"csc\", \"coo\"], reset=False)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 604, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "[W 2023-10-26 16:04:04,221] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:04,222] A new study created in memory with name: LinearRegressionModel\n",
      "[I 2023-10-26 16:04:04,240] Trial 0 finished with value: 7.790132031540103 and parameters: {'random_state': 18}. Best is trial 0 with value: 7.790132031540103.\n",
      "[I 2023-10-26 16:04:04,240] A new study created in memory with name: LinearRegressionModel\n",
      "[I 2023-10-26 16:04:04,260] Trial 0 finished with value: 11.026946160116264 and parameters: {'random_state': 2}. Best is trial 0 with value: 11.026946160116264.\n",
      "[I 2023-10-26 16:04:04,261] A new study created in memory with name: LinearRegressionModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 23.4508\n",
      "rmse: 4.842606950353951\n",
      "mape: 2.42382034155474\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh Thu·∫≠n\n",
      "  Value:  3.339688844455983\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 27.9106\n",
      "rmse: 5.283048638260686\n",
      "mape: 8282.693048522277\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh ƒê·ªãnh\n",
      "  Value:  3.2714942337812287\n",
      "ü¶Å 6\n",
      "LinearRegressionModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 130.3747\n",
      "rmse: 11.418172286162022\n",
      "mape: 0.95713966553233\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  BR V≈©ng T√†u\n",
      "  Value:  7.790132031540103\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 248.3009\n",
      "rmse: 15.757566771422649\n",
      "mape: 1.014835580385045\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh Ph∆∞·ªõc\n",
      "  Value:  11.026946160116264\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 20.5256\n",
      "rmse: 4.530513352751685\n",
      "mape: 0.9967861034495081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:04,279] Trial 0 finished with value: 3.0097119332291222 and parameters: {'random_state': 38}. Best is trial 0 with value: 3.0097119332291222.\n",
      "[I 2023-10-26 16:04:04,279] A new study created in memory with name: LinearRegressionModel\n",
      "[I 2023-10-26 16:04:04,297] Trial 0 finished with value: 3.243043277998413 and parameters: {'random_state': 30}. Best is trial 0 with value: 3.243043277998413.\n",
      "[I 2023-10-26 16:04:04,298] A new study created in memory with name: LightGBMModel\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,302] Trial 0 failed with parameters: {'random_state': 452, 'multi_models': False, 'num_leaves': 255, 'learning_rate': 0.031503393706201754, 'feature_fraction': 0.29219012836339164, 'bagging_fraction': 0.5814138392045606, 'min_child_samples': 32, 'lambda_l1': 0.000951964604709908, 'lambda_l2': 0.7862197369838138, 'likelihood': 'quantile'} because of the following error: ImportError('The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 195, in objective\n",
      "    model = LightGBMModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/utils.py\", line 22, in __call__\n",
      "    raise_log(ImportError(self.error_message), logger=logger)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 129, in raise_log\n",
      "    raise exception\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,302] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:04,302] A new study created in memory with name: LightGBMModel\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,306] Trial 0 failed with parameters: {'random_state': 271, 'multi_models': False, 'num_leaves': 100, 'learning_rate': 0.03140481829940194, 'feature_fraction': 0.3077012981933528, 'bagging_fraction': 0.39970361258094744, 'min_child_samples': 90, 'lambda_l1': 0.01822857682954824, 'lambda_l2': 5.682154076220614, 'likelihood': 'quantile'} because of the following error: ImportError('The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 195, in objective\n",
      "    model = LightGBMModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/utils.py\", line 22, in __call__\n",
      "    raise_log(ImportError(self.error_message), logger=logger)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 129, in raise_log\n",
      "    raise exception\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,306] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:04,307] A new study created in memory with name: LightGBMModel\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,310] Trial 0 failed with parameters: {'random_state': 712, 'multi_models': True, 'num_leaves': 177, 'learning_rate': 0.009547441343709927, 'feature_fraction': 0.16524122053001739, 'bagging_fraction': 0.9510356685801588, 'min_child_samples': 92, 'lambda_l1': 0.037274595572175634, 'lambda_l2': 0.006979427715443319, 'likelihood': 'quantile'} because of the following error: ImportError('The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 195, in objective\n",
      "    model = LightGBMModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/utils.py\", line 22, in __call__\n",
      "    raise_log(ImportError(self.error_message), logger=logger)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 129, in raise_log\n",
      "    raise exception\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,310] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:04,310] A new study created in memory with name: LightGBMModel\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,314] Trial 0 failed with parameters: {'random_state': 672, 'multi_models': True, 'num_leaves': 177, 'learning_rate': 0.009622607414714603, 'feature_fraction': 0.8579765617760232, 'bagging_fraction': 0.8489253659052564, 'min_child_samples': 10, 'lambda_l1': 0.0039720077784812366, 'lambda_l2': 0.0074895798266154745, 'likelihood': 'quantile'} because of the following error: ImportError('The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 195, in objective\n",
      "    model = LightGBMModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/utils.py\", line 22, in __call__\n",
      "    raise_log(ImportError(self.error_message), logger=logger)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 129, in raise_log\n",
      "    raise exception\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,314] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:04,314] A new study created in memory with name: LightGBMModel\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,318] Trial 0 failed with parameters: {'random_state': 571, 'multi_models': False, 'num_leaves': 129, 'learning_rate': 0.012101373501161439, 'feature_fraction': 0.9601485298418659, 'bagging_fraction': 0.9858679837125265, 'min_child_samples': 86, 'lambda_l1': 7.348970150639795, 'lambda_l2': 1.2608494761961309e-08, 'likelihood': 'quantile'} because of the following error: ImportError('The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 195, in objective\n",
      "    model = LightGBMModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/utils.py\", line 22, in __call__\n",
      "    raise_log(ImportError(self.error_message), logger=logger)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 129, in raise_log\n",
      "    raise exception\n",
      "ImportError: The `LightGBM` module could not be imported. To enable LightGBM support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "[W 2023-10-26 16:04:04,319] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:04,319] A new study created in memory with name: CatBoostModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh Thu·∫≠n\n",
      "  Value:  3.0097119332291222\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "mean_squared_error: 28.4965\n",
      "rmse: 5.338211788213013\n",
      "mape: 1063.295144598981\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh ƒê·ªãnh\n",
      "  Value:  3.243043277998413\n",
      "ü¶Å 6\n",
      "LightGBMModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "CatBoostModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:04,598] Trial 0 finished with value: 3.5911979723156073 and parameters: {'learning_rate': 0.007527416224769369, 'n_estimators': 122, 'max_depth': 3, 'random_state': 850, 'likelihood': 'quantile', 'quantiles': None, 'bagging_temperature': 76.73991663017422, 'border_count': 130, 'l2_leaf_reg': 0.2185440606390539, 'random_strength': 5.621083173096114}. Best is trial 0 with value: 3.5911979723156073.\n",
      "[I 2023-10-26 16:04:04,599] A new study created in memory with name: CatBoostModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 21.1406\n",
      "rmse: 4.597888250263901\n",
      "mape: 9318.985097299717\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  An Giang\n",
      "  Value:  3.5911979723156073\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:04,833] Trial 0 finished with value: 7.678935227000677 and parameters: {'learning_rate': 0.04725618993980723, 'n_estimators': 72, 'max_depth': 9, 'random_state': 374, 'likelihood': 'quantile', 'quantiles': [0.1, 0.5, 0.9], 'bagging_temperature': 9.813753967246452, 'border_count': 168, 'l2_leaf_reg': 7.654797542505024, 'random_strength': 8.428041922900961}. Best is trial 0 with value: 7.678935227000677.\n",
      "[I 2023-10-26 16:04:04,833] A new study created in memory with name: CatBoostModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 126.9776\n",
      "rmse: 11.268431823945805\n",
      "mape: 1.5280161792505824\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  BR V≈©ng T√†u\n",
      "  Value:  7.678935227000677\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:05,095] Trial 0 finished with value: 10.922653829662432 and parameters: {'learning_rate': 0.0021666181665747444, 'n_estimators': 123, 'max_depth': 4, 'random_state': 526, 'likelihood': 'quantile', 'quantiles': None, 'bagging_temperature': 0.1612867986572044, 'border_count': 92, 'l2_leaf_reg': 1.4563106381155262, 'random_strength': 5.370240061931337}. Best is trial 0 with value: 10.922653829662432.\n",
      "[I 2023-10-26 16:04:05,095] A new study created in memory with name: CatBoostModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 248.2020\n",
      "rmse: 15.754426852793129\n",
      "mape: 0.9429201266538154\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh Ph∆∞·ªõc\n",
      "  Value:  10.922653829662432\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:05,504] Trial 0 finished with value: 3.615708220557645 and parameters: {'learning_rate': 0.03719081247612475, 'n_estimators': 110, 'max_depth': 7, 'random_state': 62, 'likelihood': 'quantile', 'quantiles': None, 'bagging_temperature': 3.8664186744815616, 'border_count': 66, 'l2_leaf_reg': 8.160051121841807, 'random_strength': 0.34282134534201314}. Best is trial 0 with value: 3.615708220557645.\n",
      "[I 2023-10-26 16:04:05,505] A new study created in memory with name: CatBoostModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 28.5214\n",
      "rmse: 5.340547375335261\n",
      "mape: 1.908571005665915\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh Thu·∫≠n\n",
      "  Value:  3.615708220557645\n",
      "ü¶Å 6\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 16:04:06,450] Trial 0 finished with value: 4.266333602122166 and parameters: {'learning_rate': 0.09734823349444331, 'n_estimators': 113, 'max_depth': 11, 'random_state': 821, 'likelihood': 'quantile', 'quantiles': [0.1, 0.5, 0.9], 'bagging_temperature': 56.71366757819445, 'border_count': 146, 'l2_leaf_reg': 5.254169997833668, 'random_strength': 8.31026631527977}. Best is trial 0 with value: 4.266333602122166.\n",
      "[I 2023-10-26 16:04:06,452] A new study created in memory with name: BlockRNNModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,497] Trial 0 failed with parameters: {'random_state': 420, 'n_rnn_layers': 2, 'dropout': 0.11910127447217111, 'n_epochs': 155} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/rnn.py\", line 187, in _apply\n",
      "    ret = super(RNNBase, self)._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,497] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,498] A new study created in memory with name: BlockRNNModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,522] Trial 0 failed with parameters: {'random_state': 591, 'n_rnn_layers': 2, 'dropout': 0.4697481089604115, 'n_epochs': 184} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/rnn.py\", line 187, in _apply\n",
      "    ret = super(RNNBase, self)._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,522] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,522] A new study created in memory with name: BlockRNNModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,545] Trial 0 failed with parameters: {'random_state': 22, 'n_rnn_layers': 2, 'dropout': 0.3892107774150545, 'n_epochs': 158} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/rnn.py\", line 187, in _apply\n",
      "    ret = super(RNNBase, self)._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,546] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,546] A new study created in memory with name: BlockRNNModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,569] Trial 0 failed with parameters: {'random_state': 48, 'n_rnn_layers': 2, 'dropout': 0.3669132777085097, 'n_epochs': 86} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/rnn.py\", line 187, in _apply\n",
      "    ret = super(RNNBase, self)._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,570] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,570] A new study created in memory with name: BlockRNNModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,592] Trial 0 failed with parameters: {'random_state': 851, 'n_rnn_layers': 2, 'dropout': 0.29762030269467155, 'n_epochs': 71} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/rnn.py\", line 187, in _apply\n",
      "    ret = super(RNNBase, self)._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,593] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,593] A new study created in memory with name: NBEATSModel\n",
      "[W 2023-10-26 16:04:06,632] Trial 0 failed with parameters: {'random_state': 12, 'dropout': 0.7756891970147783, 'n_epochs': 138} because of the following error: TypeError(\"__init__() got an unexpected keyword argument 'auto_select_gpus'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 902, in fit_from_dataset\n",
      "    *self._setup_for_train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1011, in _setup_for_train\n",
      "    trainer = self._setup_trainer(trainer, model, verbose, train_num_epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 519, in _setup_trainer\n",
      "    return self._init_trainer(trainer_params=trainer_params, max_epochs=epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 532, in _init_trainer\n",
      "    return pl.Trainer(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'auto_select_gpus'\n",
      "[W 2023-10-26 16:04:06,632] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,633] A new study created in memory with name: NBEATSModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 31.9678\n",
      "rmse: 5.654011370307797\n",
      "mape: 122382.95728780006\n",
      "ü¶Å 4\n",
      "Study statistics for : \n",
      "  Number of finished trials:  1\n",
      "ü¶Å 4\n",
      "Best trial of city:  B√¨nh ƒê·ªãnh\n",
      "  Value:  4.266333602122166\n",
      "ü¶Å 6\n",
      "BlockRNNModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "NBEATSModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-10-26 16:04:06,670] Trial 0 failed with parameters: {'random_state': 15, 'dropout': 0.04785492500337957, 'n_epochs': 195} because of the following error: TypeError(\"__init__() got an unexpected keyword argument 'auto_select_gpus'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 902, in fit_from_dataset\n",
      "    *self._setup_for_train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1011, in _setup_for_train\n",
      "    trainer = self._setup_trainer(trainer, model, verbose, train_num_epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 519, in _setup_trainer\n",
      "    return self._init_trainer(trainer_params=trainer_params, max_epochs=epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 532, in _init_trainer\n",
      "    return pl.Trainer(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'auto_select_gpus'\n",
      "[W 2023-10-26 16:04:06,670] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,671] A new study created in memory with name: NBEATSModel\n",
      "[W 2023-10-26 16:04:06,706] Trial 0 failed with parameters: {'random_state': 8, 'dropout': 0.08324557623078058, 'n_epochs': 75} because of the following error: TypeError(\"__init__() got an unexpected keyword argument 'auto_select_gpus'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 902, in fit_from_dataset\n",
      "    *self._setup_for_train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1011, in _setup_for_train\n",
      "    trainer = self._setup_trainer(trainer, model, verbose, train_num_epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 519, in _setup_trainer\n",
      "    return self._init_trainer(trainer_params=trainer_params, max_epochs=epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 532, in _init_trainer\n",
      "    return pl.Trainer(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'auto_select_gpus'\n",
      "[W 2023-10-26 16:04:06,707] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,707] A new study created in memory with name: NBEATSModel\n",
      "[W 2023-10-26 16:04:06,743] Trial 0 failed with parameters: {'random_state': 41, 'dropout': 0.09927215898247575, 'n_epochs': 72} because of the following error: TypeError(\"__init__() got an unexpected keyword argument 'auto_select_gpus'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 902, in fit_from_dataset\n",
      "    *self._setup_for_train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1011, in _setup_for_train\n",
      "    trainer = self._setup_trainer(trainer, model, verbose, train_num_epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 519, in _setup_trainer\n",
      "    return self._init_trainer(trainer_params=trainer_params, max_epochs=epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 532, in _init_trainer\n",
      "    return pl.Trainer(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'auto_select_gpus'\n",
      "[W 2023-10-26 16:04:06,743] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,744] A new study created in memory with name: NBEATSModel\n",
      "[W 2023-10-26 16:04:06,779] Trial 0 failed with parameters: {'random_state': 21, 'dropout': 0.015971570470481, 'n_epochs': 127} because of the following error: TypeError(\"__init__() got an unexpected keyword argument 'auto_select_gpus'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 902, in fit_from_dataset\n",
      "    *self._setup_for_train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1011, in _setup_for_train\n",
      "    trainer = self._setup_trainer(trainer, model, verbose, train_num_epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 519, in _setup_trainer\n",
      "    return self._init_trainer(trainer_params=trainer_params, max_epochs=epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 532, in _init_trainer\n",
      "    return pl.Trainer(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'auto_select_gpus'\n",
      "[W 2023-10-26 16:04:06,780] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,780] A new study created in memory with name: NHiTSModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,808] Trial 0 failed with parameters: {'random_state': 33, 'dropout': 0.6322575440335285, 'n_epochs': 410, 'MaxPool1d': True} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,809] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,809] A new study created in memory with name: NHiTSModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,835] Trial 0 failed with parameters: {'random_state': 7, 'dropout': 0.34781782428088986, 'n_epochs': 230, 'MaxPool1d': True} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,835] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,835] A new study created in memory with name: NHiTSModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,860] Trial 0 failed with parameters: {'random_state': 10, 'dropout': 0.3410218288035091, 'n_epochs': 220, 'MaxPool1d': True} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,860] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,861] A new study created in memory with name: NHiTSModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "NHiTSModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,886] Trial 0 failed with parameters: {'random_state': 15, 'dropout': 0.4736368088071843, 'n_epochs': 320, 'MaxPool1d': True} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,887] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,887] A new study created in memory with name: NHiTSModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,914] Trial 0 failed with parameters: {'random_state': 41, 'dropout': 0.697177743784456, 'n_epochs': 360, 'MaxPool1d': True} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,914] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,914] A new study created in memory with name: TCNModel\n",
      "[W 2023-10-26 16:04:06,930] Trial 0 failed with parameters: {'kernel_size': 2, 'num_filters': 1, 'weight_norm': False, 'dilation_base': 3, 'dropout': 0.21210990989937628, 'learning_rate': 0.00010611885083107565, 'year': False, 'n_epochs': 107} because of the following error: TypeError(\"__init__() got an unexpected keyword argument 'auto_select_gpus'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 902, in fit_from_dataset\n",
      "    *self._setup_for_train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1011, in _setup_for_train\n",
      "    trainer = self._setup_trainer(trainer, model, verbose, train_num_epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 519, in _setup_trainer\n",
      "    return self._init_trainer(trainer_params=trainer_params, max_epochs=epochs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 532, in _init_trainer\n",
      "    return pl.Trainer(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'auto_select_gpus'\n",
      "[W 2023-10-26 16:04:06,930] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,930] A new study created in memory with name: TCNModel\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,934] Trial 0 failed with parameters: {'kernel_size': 3, 'num_filters': 3, 'weight_norm': True, 'dilation_base': 2, 'dropout': 0.12493546678771016, 'learning_rate': 0.00021321730179462876, 'year': True, 'n_epochs': 125} because of the following error: ValueError('The kernel size must be strictly smaller than the input length.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 158, in objective\n",
      "    model = TCNModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/forecasting_model.py\", line 106, in __call__\n",
      "    return super().__call__(**all_params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/tcn_model.py\", line 470, in __init__\n",
      "    raise_if_not(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 78, in raise_if_not\n",
      "    raise ValueError(message)\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,935] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,935] A new study created in memory with name: TCNModel\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,938] Trial 0 failed with parameters: {'kernel_size': 3, 'num_filters': 1, 'weight_norm': False, 'dilation_base': 2, 'dropout': 0.15464380441221595, 'learning_rate': 0.00013868939041440393, 'year': True, 'n_epochs': 219} because of the following error: ValueError('The kernel size must be strictly smaller than the input length.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 158, in objective\n",
      "    model = TCNModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/forecasting_model.py\", line 106, in __call__\n",
      "    return super().__call__(**all_params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/tcn_model.py\", line 470, in __init__\n",
      "    raise_if_not(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 78, in raise_if_not\n",
      "    raise ValueError(message)\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,939] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,939] A new study created in memory with name: TCNModel\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,942] Trial 0 failed with parameters: {'kernel_size': 3, 'num_filters': 3, 'weight_norm': False, 'dilation_base': 4, 'dropout': 0.23887979132742232, 'learning_rate': 8.299505215593074e-05, 'year': False, 'n_epochs': 275} because of the following error: ValueError('The kernel size must be strictly smaller than the input length.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 158, in objective\n",
      "    model = TCNModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/forecasting_model.py\", line 106, in __call__\n",
      "    return super().__call__(**all_params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/tcn_model.py\", line 470, in __init__\n",
      "    raise_if_not(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 78, in raise_if_not\n",
      "    raise ValueError(message)\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,943] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,943] A new study created in memory with name: TCNModel\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,946] Trial 0 failed with parameters: {'kernel_size': 4, 'num_filters': 2, 'weight_norm': False, 'dilation_base': 3, 'dropout': 0.22207268189319584, 'learning_rate': 7.234587847152512e-05, 'year': True, 'n_epochs': 204} because of the following error: ValueError('The kernel size must be strictly smaller than the input length.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 158, in objective\n",
      "    model = TCNModel(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/forecasting_model.py\", line 106, in __call__\n",
      "    return super().__call__(**all_params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/tcn_model.py\", line 470, in __init__\n",
      "    raise_if_not(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/logging.py\", line 78, in raise_if_not\n",
      "    raise ValueError(message)\n",
      "ValueError: The kernel size must be strictly smaller than the input length.\n",
      "[W 2023-10-26 16:04:06,947] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,947] A new study created in memory with name: TFTModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:06,975] Trial 0 failed with parameters: {'random_state': 9, 'dropout': 0.6688001875458398, 'n_epochs': 105} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:06,976] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:06,976] A new study created in memory with name: TFTModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:07,004] Trial 0 failed with parameters: {'random_state': 33, 'dropout': 0.04982513380061378, 'n_epochs': 75} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:07,004] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:07,005] A new study created in memory with name: TFTModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:07,031] Trial 0 failed with parameters: {'random_state': 1, 'dropout': 0.7310489068372189, 'n_epochs': 167} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:07,031] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:07,032] A new study created in memory with name: TFTModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:07,058] Trial 0 failed with parameters: {'random_state': 41, 'dropout': 0.4825196242466611, 'n_epochs': 150} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:07,058] Trial 0 failed with value None.\n",
      "[I 2023-10-26 16:04:07,058] A new study created in memory with name: TFTModel\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-10-26 16:04:07,084] Trial 0 failed with parameters: {'random_state': 41, 'dropout': 0.7424495084109861, 'n_epochs': 184} because of the following error: TypeError(\"Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1312014569.py\", line 33, in <lambda>\n",
      "    obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/719169775.py\", line 211, in objective\n",
      "    mae_error = output_prediction_for_location(df_train, df_valid, model, location=city, feature_list=selected_features,\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/1283319320.py\", line 12, in output_prediction_for_location\n",
      "    model, y_true, prediction_inverse, mse, mae, rmse, mape = train_and_evaluate(df_train, df_eval, model, feature_list, labels, scaler)\n",
      "  File \"/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_36494/3955677608.py\", line 19, in train_and_evaluate\n",
      "    model.fit(y_train, past_covariates = x_train)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 700, in fit\n",
      "    return self.fit_from_dataset(*params)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/utils/torch.py\", line 112, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 901, in fit_from_dataset\n",
      "    self._train(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1045, in _train\n",
      "    trainer.fit(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py\", line 966, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 77, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/lightning_fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/trinhtruc/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
      "[W 2023-10-26 16:04:07,084] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "TCNModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "TFTModel\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n",
      "ü¶Å 1\n",
      "ü¶Å 2\n",
      "ü¶Å 3\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Main Cell for optimize\n",
    "#########################\n",
    "\n",
    "model_name_list = [\n",
    "     \"RandomForest\",\n",
    "     \"LinearRegressionModel\",\n",
    "     \"LightGBMModel\",\n",
    "     \"CatBoostModel\",\n",
    "     \"BlockRNNModel\",\n",
    "     \"NBEATSModel\",\n",
    "     \"NHiTSModel\",\n",
    "     \"TCNModel\",\n",
    "     \"TFTModel\"\n",
    "]\n",
    "\n",
    "# L∆∞u th√¥ng tin traceback study v√† error city trong qu√° tr√¨nh optimize\n",
    "l_study_city ={}\n",
    "l_errCity =[]\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "  nstep = 1\n",
    "  for model_name in model_name_list: \n",
    "    print(\"ü¶Åü¶Åü¶Åü¶Åü¶Åü¶Åü¶Åü¶Åü¶Åü¶Åü¶Å: \",model_name)\n",
    "    best_param = pd.DataFrame()\n",
    "    for city_index in range(len(cities)):\n",
    "      # Use Tree-structured Parzen Estimator sampler to minimise RMSE\n",
    "      sampler = optuna.samplers.TPESampler()\n",
    "      study = optuna.create_study(sampler=sampler, direction='minimize', study_name = model_name)\n",
    "\n",
    "      # truy·ªÅn multiple param v√†o trong bi·∫øn trial\n",
    "      print(\"ü¶Å 1\")\n",
    "      obj_func = lambda trial: objective(model_name, trial, cities[city_index], nstep = nstep)\n",
    "      print(\"ü¶Å 2\")\n",
    "      try:\n",
    "        # Optimise over 100 trials\n",
    "        print(\"ü¶Å 3\")\n",
    "        study.optimize(obj_func, n_trials=args.ntry, n_jobs=args.njob)\n",
    "        print(\"ü¶Å 4\")\n",
    "\n",
    "        # Print results\n",
    "        print(\"Study statistics for : \")\n",
    "        print(\"  Number of finished trials: \", len(study.trials))\n",
    "    \n",
    "        print(\"ü¶Å 4\")\n",
    "        print(\"Best trial of city: \",cities[city_index])\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "        print(\"  Value: \", best_trial.value)   \n",
    "        print(\"ü¶Å 6\")\n",
    "        # l∆∞u best param v√†o trong bi·∫øn to√†n c·ª•c\n",
    "\n",
    "        if model_name == \"LinearRegressionModel\": \n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'LinearRegressionModel',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'lags' : best_trial.params['output_chunk_length'],\n",
    "                              'lags_past_covariates': 3,\n",
    "                              'output_chunk_length': best_trial.params['output_chunk_length'],\n",
    "                              'random_state':best_trial.params['random_state'],\n",
    "                              }, index=[0])\n",
    "\n",
    "\n",
    "        elif model_name == \"LightGBMModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'LightGBMModel',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'lags': best_trial.params['lags'],\n",
    "                              'lags_past_covariates': best_trial.params['lags_past_covariates'],\n",
    "                              'multi_models': best_trial.params['multi_models'],\n",
    "                              'num_leaves': best_trial.params['num_leaves'], \n",
    "                              'feature_fraction': best_trial.params['feature_fraction'], \n",
    "                              'min_child_samples': best_trial.params['min_child_samples'], \n",
    "                              'lambda_l1': best_trial.params['lambda_l1'], \n",
    "                              'lambda_l2': best_trial.params['lambda_l2'], \n",
    "                              'likelihood': best_trial.params['likelihood'], \n",
    "                              'learning_rate': best_trial.params['learning_rate']}, index=[0])\n",
    "\n",
    "           \n",
    "        elif model_name == \"CatBoostModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'CatBoost',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'lags' : 3,\n",
    "                              'lags_past_covariates': 3,\n",
    "                              'output_chunk_length': best_trial.params['output_chunk_length'],\n",
    "                              'likelihood': best_trial.params['likelihood'],\n",
    "                              'learning_rate': best_trial.params['learning_rate'],\n",
    "                              'n_estimators': best_trial.params['n_estimators'],\n",
    "                              'max_depth': best_trial.params['max_depth'],\n",
    "                              'bagging_temperature': best_trial.params['bagging_temperature'],\n",
    "                              'l2_leaf_reg': best_trial.params['l2_leaf_reg'],\n",
    "                              'random_strength':best_trial.params['random_strength'],\n",
    "                              }, index=[0])\n",
    "\n",
    "\n",
    "          \n",
    "        elif model_name == \"NHiTSModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'N-HiTS',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'input_chunk_length' : 3,\n",
    "                              'output_chunk_length' : 1,\n",
    "                              'MaxPool1d' : best_trial.params['MaxPool1d'],\n",
    "                              'dropout' : best_trial.params['dropout'],\n",
    "                              'n_epochs' : best_trial.params['n_epochs'],\n",
    "                              'random_state' : best_trial.params['random_state'],\n",
    "                              }, index=[0])\n",
    "\n",
    "\n",
    "        elif model_name == \"TCNModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'TCNModel',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'lags' : best_trial.params['input_chunk_length'],\n",
    "                              'input_chunk_length': best_trial.params['input_chunk_length'],\n",
    "                              'output_chunk_length': best_trial.params['output_chunk_length'],\n",
    "                              'n_epochs':best_trial.params['n_epochs'],\n",
    "                              'num_filters':best_trial.params['num_filters'],\n",
    "                              'weight_norm':best_trial.params['weight_norm'],\n",
    "                              'dilation_base':best_trial.params['dilation_base'],\n",
    "                              'dropout':best_trial.params['dropout'],\n",
    "                              'learning_rate':best_trial.params['learning_rate'],\n",
    "                              'year':best_trial.params['year'],\n",
    "                              }, index=[0])\n",
    "\n",
    "          \n",
    "        elif model_name == \"NBEATSModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'NBeatsModel',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'output_chunk_length': 3,\n",
    "                              'input_chunk_length': 1,\n",
    "                              'n_epochs':best_trial.params['n_epochs'],\n",
    "                              'dropout':best_trial.params['dropout'],\n",
    "                              'random_state':best_trial.params['random_state'],\n",
    "                              }, index=[0])    \n",
    "\n",
    "        elif model_name == \"TFTModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'TFTModel',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'output_chunk_length': 3,\n",
    "                              'input_chunk_length': 1,\n",
    "                              'add_relative_index': True,\n",
    "                              'random_state':best_trial.params['random_state'],\n",
    "                              'n_epochs':best_trial.params['n_epochs'],\n",
    "                              'dropout':best_trial.params['dropout']\n",
    "                              }, index=[0])\n",
    "\n",
    "        elif model_name == \"RandomForest\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'RandomForest',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'lags' : best_trial.params['output_chunk_length'],\n",
    "                              'lags_past_covariates': 3,\n",
    "                              'output_chunk_length': best_trial.params['output_chunk_length'],\n",
    "                              'n_estimators': best_trial.params['n_estimators'],\n",
    "                              'max_depth': best_trial.params['max_depth'],\n",
    "                              'random_state':best_trial.params['random_state'],\n",
    "                              }, index=[0])\n",
    "\n",
    "           \n",
    "        elif model_name == \"BlockRNNModel\":\n",
    "          one_city_param = pd.DataFrame({\n",
    "                              'City':  cities[city_index],\n",
    "                              'Alg_name': 'BlockRNNModel',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': args.ntry,\n",
    "                              'input_chunk_length': 3,\n",
    "                              'output_chunk_length': 1,\n",
    "                              'random_state':best_trial.params['random_state'],\n",
    "                              'n_epochs':best_trial.params['n_epochs'],\n",
    "                              'hidden_dim': best_trial.params['hidden_dim'],\n",
    "                              'n_rnn_layers': best_trial.params['n_rnn_layers'],\n",
    "                              'dropout':best_trial.params['dropout']\n",
    "                              }, index=[0])\n",
    "\n",
    "\n",
    "        file_path = '261023_denguefever_opt_hyperparam_'+ model_name + '_'+nstep+'-nstep.xlsx'\n",
    "        if(os.path.isfile(file_path)):\n",
    "            print(\"üçâüçâüçâüçâüçâüçâüçâüçâüçâüçâ\")\n",
    "            with pd.ExcelWriter(file_path,mode=\"a\",engine=\"openpyxl\",if_sheet_exists=\"overlay\") as writer:\n",
    "                one_city_param.to_excel(writer, header=None, startrow=city_index+2,index=False)\n",
    "        else:\n",
    "            with pd.ExcelWriter(file_path,engine=\"openpyxl\") as writer:\n",
    "                one_city_param.to_excel(writer, startrow=city_index+1,index=False)\n",
    "      except:# c√≥ error th√¨ l∆∞u v√†o l_errCity ƒë·ªÉ check l·∫°i sau \n",
    "        l_errCity.append(cities[city_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An Giang', 'BR V≈©ng T√†u', 'B√¨nh Ph∆∞·ªõc', 'B√¨nh Thu·∫≠n', 'B√¨nh ƒê·ªãnh']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'diarrhoea_opt_hyperparam_RNN_v5.xlsx'\n",
    "for city_index in range(len(cities)):\n",
    "        one_city_param = pd.DataFrame({\n",
    "                                    'City': cities[city_index],\n",
    "                                    'Alg_name': 'BlockRNNModel',\n",
    "                                    'Best_value': 2,\n",
    "                                    'n_try_opt': 2,\n",
    "                                    'input_chunk_length': 2,\n",
    "                                    'output_chunk_length': 1,\n",
    "                                    'random_state': 3,\n",
    "                                    'n_epochs': 3,\n",
    "                                    'hidden_dim': 3,\n",
    "                                    'n_rnn_layers': 3,\n",
    "                                    'dropout': 3\n",
    "                                    }, index=[city_index])\n",
    "        \n",
    "        if(os.path.isfile(file_path)):\n",
    "            with pd.ExcelWriter(file_path,mode=\"a\",engine=\"openpyxl\",if_sheet_exists=\"overlay\") as writer:\n",
    "                one_city_param.to_excel(writer, header=None, startrow=city_index+2,index=False)\n",
    "        else:\n",
    "            with pd.ExcelWriter(file_path,engine=\"openpyxl\") as writer:\n",
    "                one_city_param.to_excel(writer, startrow=city_index+1,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pandas\n",
      "Version: 2.1.0\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: https://pandas.pydata.org\n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "        \n",
      "        Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "        All rights reserved.\n",
      "        \n",
      "        Copyright (c) 2011-2023, Open source contributors.\n",
      "        \n",
      "        Redistribution and use in source and binary forms, with or without\n",
      "        modification, are permitted provided that the following conditions are met:\n",
      "        \n",
      "        * Redistributions of source code must retain the above copyright notice, this\n",
      "          list of conditions and the following disclaimer.\n",
      "        \n",
      "        * Redistributions in binary form must reproduce the above copyright notice,\n",
      "          this list of conditions and the following disclaimer in the documentation\n",
      "          and/or other materials provided with the distribution.\n",
      "        \n",
      "        * Neither the name of the copyright holder nor the names of its\n",
      "          contributors may be used to endorse or promote products derived from\n",
      "          this software without specific prior written permission.\n",
      "        \n",
      "        THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "        AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "        IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "        DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "        FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "        SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "        CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "        OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "        OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: /Users/trinhtruc/Library/Python/3.9/lib/python/site-packages\n",
      "Requires: numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: audformat, catboost, darts, fugue, nfoursid, pmdarima, qpd, seaborn, shap, statsforecast, statsmodels, triad, xarray\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# def send_to_telegram(message):\n",
    "\n",
    "#     apiToken = '5908735099:AAGVSLrW62aXPBP-GrMvxoVgMsuJxXJpP1Q'\n",
    "#     chatID = '@ptn_announcement'\n",
    "#     apiURL = f'https://api.telegram.org/bot{apiToken}/sendMessage'\n",
    "\n",
    "#     try:\n",
    "#         response = requests.post(apiURL, json={'chat_id': chatID, 'text': message})\n",
    "#         print(response.text)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "# send_to_telegram(\"Server Ch·∫°y Xong optimize\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '‚ñ∫';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '‚ñº';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;TimeSeries (DataArray) (Date Time: 52704, component: 21, sample: 1)&gt;\n",
       "array([[[1.00889e+03],\n",
       "        [7.10000e-01],\n",
       "        [2.73180e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.14500e+01],\n",
       "        [4.28100e+02]],\n",
       "\n",
       "       [[1.00876e+03],\n",
       "        [7.50000e-01],\n",
       "        [2.73220e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.15100e+01],\n",
       "        [4.28000e+02]],\n",
       "\n",
       "       [[1.00866e+03],\n",
       "        [7.30000e-01],\n",
       "        [2.73210e+02],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34500e+01],\n",
       "        [4.35200e+02]],\n",
       "\n",
       "       [[9.78260e+02],\n",
       "        [2.07000e+00],\n",
       "        [2.76950e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34700e+01],\n",
       "        [4.33900e+02]],\n",
       "\n",
       "       [[9.78240e+02],\n",
       "        [2.01000e+00],\n",
       "        [2.76890e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34800e+01],\n",
       "        [4.36500e+02]]])\n",
       "Coordinates:\n",
       "  * Date Time  (Date Time) datetime64[ns] 2020-01-01T00:10:00 ... 2021-01-01\n",
       "  * component  (component) object &#x27;p (mbar)&#x27; &#x27;T (degC)&#x27; ... &#x27;CO2 (ppm)&#x27;\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>TimeSeries (DataArray)</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>Date Time</span>: 52704</li><li><span class='xr-has-index'>component</span>: 21</li><li><span>sample</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-a910b5c3-5126-417f-bffd-9f5ba5834d7c' class='xr-array-in' type='checkbox' checked><label for='section-a910b5c3-5126-417f-bffd-9f5ba5834d7c' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1.009e+03 0.71 273.2 -1.33 86.1 6.43 ... 0.0 0.0 0.0 0.0 13.48 436.5</span></div><div class='xr-array-data'><pre>array([[[1.00889e+03],\n",
       "        [7.10000e-01],\n",
       "        [2.73180e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.14500e+01],\n",
       "        [4.28100e+02]],\n",
       "\n",
       "       [[1.00876e+03],\n",
       "        [7.50000e-01],\n",
       "        [2.73220e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.15100e+01],\n",
       "        [4.28000e+02]],\n",
       "\n",
       "       [[1.00866e+03],\n",
       "        [7.30000e-01],\n",
       "        [2.73210e+02],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34500e+01],\n",
       "        [4.35200e+02]],\n",
       "\n",
       "       [[9.78260e+02],\n",
       "        [2.07000e+00],\n",
       "        [2.76950e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34700e+01],\n",
       "        [4.33900e+02]],\n",
       "\n",
       "       [[9.78240e+02],\n",
       "        [2.01000e+00],\n",
       "        [2.76890e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34800e+01],\n",
       "        [4.36500e+02]]])</pre></div></div></li><li class='xr-section-item'><input id='section-b394de0f-6a90-421a-88f1-e44c3f9b10c9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b394de0f-6a90-421a-88f1-e44c3f9b10c9' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>Date Time</span></div><div class='xr-var-dims'>(Date Time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2020-01-01T00:10:00 ... 2021-01-01</div><input id='attrs-3bc439b8-680a-4dc6-b81b-6527c4c5122e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3bc439b8-680a-4dc6-b81b-6527c4c5122e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-45309568-c2d7-41ef-a4c4-9c2aca00c0b3' class='xr-var-data-in' type='checkbox'><label for='data-45309568-c2d7-41ef-a4c4-9c2aca00c0b3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2020-01-01T00:10:00.000000000&#x27;, &#x27;2020-01-01T00:20:00.000000000&#x27;,\n",
       "       &#x27;2020-01-01T00:30:00.000000000&#x27;, ..., &#x27;2020-12-31T23:40:00.000000000&#x27;,\n",
       "       &#x27;2020-12-31T23:50:00.000000000&#x27;, &#x27;2021-01-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>component</span></div><div class='xr-var-dims'>(component)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;p (mbar)&#x27; ... &#x27;CO2 (ppm)&#x27;</div><input id='attrs-7b6a872c-e0ad-4825-b8d4-92e543297409' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7b6a872c-e0ad-4825-b8d4-92e543297409' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4620b134-8301-4ac3-a05d-d18619a8a816' class='xr-var-data-in' type='checkbox'><label for='data-4620b134-8301-4ac3-a05d-d18619a8a816' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;p (mbar)&#x27;, &#x27;T (degC)&#x27;, &#x27;Tpot (K)&#x27;, &#x27;Tdew (degC)&#x27;, &#x27;rh (%)&#x27;,\n",
       "       &#x27;VPmax (mbar)&#x27;, &#x27;VPact (mbar)&#x27;, &#x27;VPdef (mbar)&#x27;, &#x27;sh (g/kg)&#x27;,\n",
       "       &#x27;H2OC (mmol/mol)&#x27;, &#x27;rho (g/m**3)&#x27;, &#x27;wv (m/s)&#x27;, &#x27;max. wv (m/s)&#x27;,\n",
       "       &#x27;wd (deg)&#x27;, &#x27;rain (mm)&#x27;, &#x27;raining (s)&#x27;, &#x27;SWDR (W/m¬≤)&#x27;,\n",
       "       &#x27;PAR (¬µmol/m¬≤/s)&#x27;, &#x27;max. PAR (¬µmol/m¬≤/s)&#x27;, &#x27;Tlog (degC)&#x27;, &#x27;CO2 (ppm)&#x27;],\n",
       "      dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-92c3d3a7-a43e-4f6d-80b9-df9da6bd3355' class='xr-section-summary-in' type='checkbox'  ><label for='section-92c3d3a7-a43e-4f6d-80b9-df9da6bd3355' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>Date Time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-81e8fc6c-9c4e-4473-8cd5-5dd3378d7199' class='xr-index-data-in' type='checkbox'/><label for='index-81e8fc6c-9c4e-4473-8cd5-5dd3378d7199' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2020-01-01 00:10:00&#x27;, &#x27;2020-01-01 00:20:00&#x27;,\n",
       "               &#x27;2020-01-01 00:30:00&#x27;, &#x27;2020-01-01 00:40:00&#x27;,\n",
       "               &#x27;2020-01-01 00:50:00&#x27;, &#x27;2020-01-01 01:00:00&#x27;,\n",
       "               &#x27;2020-01-01 01:10:00&#x27;, &#x27;2020-01-01 01:20:00&#x27;,\n",
       "               &#x27;2020-01-01 01:30:00&#x27;, &#x27;2020-01-01 01:40:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2020-12-31 22:30:00&#x27;, &#x27;2020-12-31 22:40:00&#x27;,\n",
       "               &#x27;2020-12-31 22:50:00&#x27;, &#x27;2020-12-31 23:00:00&#x27;,\n",
       "               &#x27;2020-12-31 23:10:00&#x27;, &#x27;2020-12-31 23:20:00&#x27;,\n",
       "               &#x27;2020-12-31 23:30:00&#x27;, &#x27;2020-12-31 23:40:00&#x27;,\n",
       "               &#x27;2020-12-31 23:50:00&#x27;, &#x27;2021-01-01 00:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;Date Time&#x27;, length=52704, freq=&#x27;10T&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>component</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-8b7fc593-7944-4454-a087-80fb2156766d' class='xr-index-data-in' type='checkbox'/><label for='index-8b7fc593-7944-4454-a087-80fb2156766d' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;p (mbar)&#x27;, &#x27;T (degC)&#x27;, &#x27;Tpot (K)&#x27;, &#x27;Tdew (degC)&#x27;, &#x27;rh (%)&#x27;,\n",
       "       &#x27;VPmax (mbar)&#x27;, &#x27;VPact (mbar)&#x27;, &#x27;VPdef (mbar)&#x27;, &#x27;sh (g/kg)&#x27;,\n",
       "       &#x27;H2OC (mmol/mol)&#x27;, &#x27;rho (g/m**3)&#x27;, &#x27;wv (m/s)&#x27;, &#x27;max. wv (m/s)&#x27;,\n",
       "       &#x27;wd (deg)&#x27;, &#x27;rain (mm)&#x27;, &#x27;raining (s)&#x27;, &#x27;SWDR (W/m¬≤)&#x27;,\n",
       "       &#x27;PAR (¬µmol/m¬≤/s)&#x27;, &#x27;max. PAR (¬µmol/m¬≤/s)&#x27;, &#x27;Tlog (degC)&#x27;, &#x27;CO2 (ppm)&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;component&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f6e3e122-8f44-48cc-bccb-8187c396c71d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f6e3e122-8f44-48cc-bccb-8187c396c71d' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>static_covariates :</span></dt><dd>None</dd><dt><span>hierarchy :</span></dt><dd>None</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<TimeSeries (DataArray) (Date Time: 52704, component: 21, sample: 1)>\n",
       "array([[[1.00889e+03],\n",
       "        [7.10000e-01],\n",
       "        [2.73180e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.14500e+01],\n",
       "        [4.28100e+02]],\n",
       "\n",
       "       [[1.00876e+03],\n",
       "        [7.50000e-01],\n",
       "        [2.73220e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.15100e+01],\n",
       "        [4.28000e+02]],\n",
       "\n",
       "       [[1.00866e+03],\n",
       "        [7.30000e-01],\n",
       "        [2.73210e+02],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34500e+01],\n",
       "        [4.35200e+02]],\n",
       "\n",
       "       [[9.78260e+02],\n",
       "        [2.07000e+00],\n",
       "        [2.76950e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34700e+01],\n",
       "        [4.33900e+02]],\n",
       "\n",
       "       [[9.78240e+02],\n",
       "        [2.01000e+00],\n",
       "        [2.76890e+02],\n",
       "        ...,\n",
       "        [0.00000e+00],\n",
       "        [1.34800e+01],\n",
       "        [4.36500e+02]]])\n",
       "Coordinates:\n",
       "  * Date Time  (Date Time) datetime64[ns] 2020-01-01T00:10:00 ... 2021-01-01\n",
       "  * component  (component) object 'p (mbar)' 'T (degC)' ... 'CO2 (ppm)'\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from darts.datasets import WeatherDataset\n",
    "from darts.models import RandomForest\n",
    "series = WeatherDataset().load()\n",
    "# predicting atmospheric pressure\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1005.73340676],\n",
       "       [1005.71159051],\n",
       "       [1005.7322616 ],\n",
       "       [1005.76314504],\n",
       "       [1005.82204348],\n",
       "       [1005.89100967]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from darts.datasets import WeatherDataset\n",
    "from darts.models import RegressionModel\n",
    "from sklearn.linear_model import Ridge\n",
    "series = WeatherDataset().load()\n",
    "# predicting atmospheric pressure\n",
    "target = series['p (mbar)'][:100]\n",
    "# optionally, use past observed rainfall (pretending to be unknown beyond index 100)\n",
    "past_cov = series['rain (mm)'][:100]\n",
    "# optionally, use future temperatures (pretending this component is a forecast)\n",
    "future_cov = series['T (degC)'][:106]\n",
    "# wrap around the sklearn Ridge model\n",
    "model = RegressionModel(\n",
    "    model=Ridge(),\n",
    "    lags=12,\n",
    "    lags_past_covariates=4,\n",
    "    lags_future_covariates=(0,6),\n",
    "    output_chunk_length=6\n",
    ")\n",
    "model.fit(target, past_covariates=past_cov, future_covariates=future_cov)\n",
    "pred = model.predict(6)\n",
    "pred.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1006.4309]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = series['p (mbar)'][:100]\n",
    "# optionally, use past observed rainfall (pretending to be unknown beyond index 100)\n",
    "past_cov = series['rain (mm)'][:100]\n",
    "# optionally, use future temperatures (pretending this component is a forecast)\n",
    "future_cov = series['T (degC)'][:106]\n",
    "# random forest with 200 trees trained with MAE\n",
    "model = RandomForest(\n",
    "    lags=2,\n",
    "    lags_past_covariates=2,\n",
    "    lags_future_covariates=[0,1,2,3,4,5],\n",
    "    output_chunk_length=6,\n",
    "    n_estimators=200,\n",
    "    criterion=\"absolute_error\",\n",
    ")\n",
    "model.fit(target, past_covariates=past_cov, future_covariates=future_cov)\n",
    "pred = model.predict(1)\n",
    "pred.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
