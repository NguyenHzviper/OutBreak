{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Smx2B-csrq"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17063,
     "status": "ok",
     "timestamp": 1675101187981,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "VW4v2IEcTYHa",
    "outputId": "3eae95c8-1dab-4f6b-be39-9e8ffc15a25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from scikit-learn) (1.23.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ftfy in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (6.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from ftfy) (0.2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (3.0.2)\n",
      "Requirement already satisfied: PyYAML in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: colorlog in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mlworker/.local/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: tqdm in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: cliff in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: numpy in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from optuna) (1.23.3)\n",
      "Requirement already satisfied: Mako in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mlworker/.local/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mlworker/.local/lib/python3.9/site-packages (from cliff->optuna) (5.0.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mlworker/.local/lib/python3.9/site-packages (from importlib-metadata>=4.4->cliff->optuna) (3.8.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from stevedore>=2.0.1->cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/mlworker/anaconda3/envs/climate_diseases_py39/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "%pip install -U scikit-learn\n",
    "%pip install ftfy\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2280,
     "status": "ok",
     "timestamp": 1675101190254,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "b8I8S9koHjT_"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ftfy import fix_text\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA7yvJS1czVO"
   },
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3325,
     "status": "ok",
     "timestamp": 1675101193568,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "MNAuUk6_HVs1",
    "outputId": "9e3b5911-d2e8-4c20-9936-c0cbc4955010"
   },
   "outputs": [],
   "source": [
    "\n",
    "prj_path = '/home/mlworker/Quang/HealthCare/Source_14012023_v4/'\n",
    "data_path = prj_path + \"/data/\"\n",
    "prj_path_opt= prj_path + \"optimize_hyperparam/opt_results/opt_results_12022023_v4/\"\n",
    "\n",
    "os.chdir(prj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X94Oj9inc8Fk"
   },
   "source": [
    "# Create Dict data for all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1675101194240,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "ONDHBTEPRMTu"
   },
   "outputs": [],
   "source": [
    "cities = [\n",
    "#      'Bắc Giang', 'Cao Bằng', 'Cà Mau',\n",
    "#         'Cần Thơ', 'Gia Lai', 'Hà Giang', 'Hà Nội', 'Hà Tĩnh', 'Hòa Bình',\n",
    "#         'Hưng Yên', 'Hải Dương', 'Hải Phòng', 'Khánh Hòa', 'Kiên Giang',\n",
    "#         'Kon Tum', 'Lai Châu', 'Long An', 'Lào Cai', 'Lâm Đồng',\n",
    "#         'Lạng Sơn', 'Nam Định', 'Nghệ An', 'Ninh Bình', 'Ninh Thuận',\n",
    "#         'Phú Thọ', 'Phú Yên', \n",
    "    'Quảng Bình', 'Quảng Nam', 'Quảng Ngãi',\n",
    "#         'Quảng Ninh', 'Quảng Trị', 'Sóc Trăng', 'Sơn La',\n",
    "#           'TT Huế',\n",
    "#         'Thanh Hóa', 'Thái Bình', 'Thái Nguyên', 'Tiền Giang', 'Trà Vinh',\n",
    "        ]\n",
    "\n",
    "def get_dict_all_city_data():\n",
    "  cities_data = {}  \n",
    "  for city in cities:\n",
    "    city_result = pd.read_excel(prj_path+'data/new_data/DH/squeezed/squeezed_'+city+'.xlsx')  \n",
    "    # Đoạn này rất quan trọng. Vì việc optimize không được đụng vào 24 tháng (2016-2017) để dự báo. \n",
    "    # Dữ liệu optimize tính từ 1997- 30/12/2015. Sau đó tách ra train và test trên bộ này.\n",
    "    # lọc 2 năm cuối ra khỏi bộ dữ liệu trước khi chạy optimize \n",
    "    # đoạn này áp dụng cho tất cả các bước optimize trong project\n",
    "    city_result = city_result.loc[city_result['year_month'] < '2013-1-1'] \n",
    "    cities_data[city] = city_result\n",
    "  return cities_data\n",
    "\n",
    "dict_full_data = get_dict_all_city_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUPWuxbOdBlU"
   },
   "source": [
    "# Seed and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194240,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "fVkHGeUPO6cO"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194241,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "lEn56jmQtEmD"
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters as args using the Configuration class\n",
    "class Configuration():\n",
    "    def __init__(self):\n",
    "        self.test_size = 24\n",
    "        self.look_back = 3\n",
    "        self.n_predicted_month = 3\n",
    "        self.n_features = 3\n",
    "        self.seed = 42\n",
    "        self.batch_size = 16\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.epochs = 300\n",
    "\n",
    "args = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OyQATbT2nRz"
   },
   "source": [
    "# Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194241,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "ukoPuS5CHvdl"
   },
   "outputs": [],
   "source": [
    "# Define data (pre-)processing functions\n",
    "# modification\n",
    "def get_city_data(city_name):\n",
    "    \"\"\"Returns Diarrhoea rate and climate data\"\"\" \n",
    "    city_data = dict_full_data[city_name].drop(columns=['Diarrhoea_cases', 'province', 'year_month',\n",
    "                                                        'Influenza_rates','Dengue_fever_rates',\n",
    "                                                        'Influenza_cases','Dengue_fever_cases', 'year', 'month'], \n",
    "                                                                  axis=1, \n",
    "                                                                  inplace=False)    \n",
    "    return city_data\n",
    "\n",
    "\n",
    "def convert_to_stationary(city_data):\n",
    "    \"\"\"Subtracts previous value for all cols except disease rates\"\"\"\n",
    "    for col_name in city_data.columns:\n",
    "        if col_name != 'Diarrhoea_rates':\n",
    "            try:\n",
    "                city_data[col_name] = city_data[col_name] - city_data[col_name].shift()\n",
    "            except:\n",
    "                print(col_name)\n",
    "    return city_data\n",
    "\n",
    "def impute_missing_value(city_data):\n",
    "    \"\"\"\n",
    "    Cơ bản dữ liệu bị thiếu sót rất nhiều: Như Điện Biên 1997 -2003 là thiếu dữ liệu về bệnh\n",
    "    Hàm này sẽ tự sinh ra dữ liệu bị thiếu. Nếu tháng nào không có số liệu thì tính như sau:\n",
    "    12 tháng đầu không có số liệu thì gán = 0\n",
    "    tháng 13-24 không có số liệu, sẽ lấy giá trị của tháng cùng kỳ năm trước\n",
    "    tháng từ 24 trở đi sẽ lấy giá trị nhỏ nhất của 2 tháng cùng kỳ trong 2 năm gần nhất.\n",
    "    Do Điện Biên bằng 0 nên sau khi xử lý từ 1997 -2003 là đều = 0.  \n",
    "    \"\"\"\n",
    "    for col in city_data.columns:\n",
    "        for index in range(len(city_data[col])):\n",
    "            if np.isnan(city_data[col].iloc[index]):\n",
    "                if index < 12:\n",
    "                    city_data[col].iloc[index] = 0\n",
    "                elif index >= 12 and index <= 24:\n",
    "                    city_data[col].iloc[index] = city_data[col].iloc[index - 12]\n",
    "                else:\n",
    "                    city_data[col].iloc[index] = min(city_data[col].iloc[index - 12], city_data[col].iloc[index - 24])\n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194241,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "RT8LmtHts4fQ"
   },
   "outputs": [],
   "source": [
    "def split_data(data, look_back ):\n",
    "    \"\"\"Splits data into train and test sets based on args (Configuration class)\"\"\"\n",
    "    train = data[: -args.test_size]\n",
    "    print('lookback', look_back)\n",
    "    test = data[-args.test_size - look_back: ]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "6Wdc44U0uMbP"
   },
   "outputs": [],
   "source": [
    "def to_supervised(data, d_in=args.look_back, d_out=args.n_predicted_month, features_list=[]):\n",
    "    \"\"\"\n",
    "    Frames time-series as supervised learning dataset.\n",
    "    \n",
    "    Args:\n",
    "      d_in: lookback window\n",
    "      d_out: number of predicted months\n",
    "      features_list: list of all features **where last col is the disease incidence**\n",
    "\n",
    "    Returns:\n",
    "      Numpy arrays of disease incidence (y) and other predictors (X)\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for index, _ in enumerate(data):\n",
    "        in_end = index + d_in\n",
    "        out_end = in_end + d_out\n",
    "        if out_end <= len(data):\n",
    "            if len(features_list) == 0 :\n",
    "                X.append(data[index: in_end, :])\n",
    "            else:\n",
    "                X.append(data[index: in_end, features_list])\n",
    "            y.append(data[in_end: out_end, -1])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "x_RfqYtVGTAk"
   },
   "outputs": [],
   "source": [
    "def select_feature(train, specific_data):\n",
    "    \"\"\"Selects args.n_features top features using RFE\"\"\"\n",
    "    train_X, train_y = to_supervised(train, d_in=1, d_out=1)\n",
    "    train_X, train_y = np.squeeze(train_X), np.squeeze(train_y)\n",
    "    rfe = RFE(RandomForestRegressor(n_estimators=500, random_state=args.seed), n_features_to_select=args.n_features)\n",
    "    fit = rfe.fit(train_X, train_y)\n",
    "    important_features = list()\n",
    "    # print(\"Important Feature:\")\n",
    "    for i in range(len(fit.support_)):\n",
    "        if fit.support_[i]:\n",
    "            important_features.append(i)\n",
    "            # print(specific_data.columns[i])\n",
    "    return np.array(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "OsgC3mbHV96C"
   },
   "outputs": [],
   "source": [
    "def get_data(train_np, test_np, batch_size, specific_data):\n",
    "    \"\"\"\n",
    "    Returns important feature list and data formatted for input into Pytorch \n",
    "    models\n",
    "    \"\"\"\n",
    "    important_features = select_feature(train_np, specific_data)\n",
    "\n",
    "    train_X, train_y = to_supervised(train_np, features_list=important_features)\n",
    "    test_X, test_y = to_supervised(test_np, features_list=important_features)\n",
    "    train_tensor = TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\n",
    "    test_tensor = (torch.from_numpy(test_X), torch.from_numpy(test_y))\n",
    "\n",
    "    train_loader = DataLoader(train_tensor, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return important_features, train_loader, test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194242,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "PW18DMZgF5K_"
   },
   "outputs": [],
   "source": [
    "#Define Pytorch LSTM model\n",
    "class MultiVariateLSTM(nn.Module):\n",
    "    def __init__(self, n_feature=3, n_layers=2, hidden_size=50):\n",
    "        super(MultiVariateLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_feature, hidden_size=hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, args.n_predicted_month)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "    \n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        output, (last_hidden, _) = self.lstm(X_batch)\n",
    "        last_hidden_vector = output[:, -1, :]\n",
    "        y_predicted = self.linear(last_hidden_vector)\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "            #return y_predicted, self.loss_fn(y_predicted, y_batch)\n",
    "        else:\n",
    "            return y_predicted\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X)\n",
    "\n",
    "#Define Pytorch LSTM-ATT model\n",
    "class MultiVariateLSTM_Attention(nn.Module):\n",
    "    def __init__(self, n_feature=3, n_layers=2, hidden_size=50):\n",
    "        super(MultiVariateLSTM_Attention, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_feature, hidden_size=hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.attention_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        # self.linear = nn.Linear(hidden_size*2, args.n_predicted_month)\n",
    "        self.linear = nn.Linear(hidden_size, args.n_predicted_month)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "    \n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        output, (last_hidden, _) = self.lstm(X_batch)\n",
    "        last_hidden_vector = last_hidden[-1]\n",
    "        remain_hidden_vector = output\n",
    "        e_t = remain_hidden_vector.bmm(self.attention_linear(last_hidden_vector).unsqueeze(2)).squeeze(-1)\n",
    "        alpha_t = F.softmax(e_t, dim=1)\n",
    "        attenion_vector = remain_hidden_vector.transpose(2, 1).bmm(alpha_t.unsqueeze(2)).squeeze(-1)\n",
    "        # combine_vector = torch.cat((last_hidden_vector, attenion_vector), dim=1)\n",
    "        # combine_vector = last_hidden_vector + attenion_vector\n",
    "        y_predicted = self.linear(attenion_vector)\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "            # return y_predicted, self.loss_fn(y_predicted, y_batch)\n",
    "        else:\n",
    "            return y_predicted\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X)\n",
    "\n",
    "# Define Pytorch CNN model\n",
    "class MultivariateCNN(nn.Module):\n",
    "    def __init__(self, num_filters=[100, 100, 100], dropout=0.01):\n",
    "        super(MultivariateCNN, self).__init__()\n",
    "        self.loss_fn = loss = nn.MSELoss()\n",
    "        self.filter_sizes = [1, 2, 3]\n",
    "        self.conv1d_list = nn.ModuleList([nn.Conv1d(args.n_features, num_filters[i], self.filter_sizes[i]) for i in range(len(self.filter_sizes))])\n",
    "        self.linear = nn.Linear(np.sum(num_filters), args.n_predicted_month)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "\n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        X_batch = X_batch.permute(0, 2, 1)  #(batch_size, n_features, n_look_back)\n",
    "        X_conv_list = [F.relu(conv1d(X_batch)) for conv1d in self.conv1d_list]\n",
    "        X_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2]) for x_conv in X_conv_list]\n",
    "        X_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in X_pool_list], dim=1)\n",
    "        y_predicted = self.linear(self.dropout(X_fc))\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "            # return y_predicted, self.loss_fn(y_predicted, y_batch)\n",
    "        else:\n",
    "            return y_predicted\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3TB2E72MDb"
   },
   "source": [
    "# Define Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675101194243,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "ZvmfYUt4vWeP"
   },
   "outputs": [],
   "source": [
    "# Define Pytorch Transformer model\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=3, n_feature=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(n_feature, d_model)\n",
    "        for pos in range(n_feature):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n",
    "                if i + 1 < d_model:\n",
    "                    pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n",
    "        pe = pe.unsqueeze(0)        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x*math.sqrt(self.d_model)\n",
    "        length = x.size(1)\n",
    "        pe = Variable(self.pe[:, :length], requires_grad=False)\n",
    "        if x.is_cuda:\n",
    "            pe.cuda()\n",
    "        x = x + pe\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, d_input=3, n_head=3, hidden_size=256, n_layers=3, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pe = PositionalEncoder(dropout=dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_input, nhead=n_head, dim_feedforward=hidden_size, dropout=dropout, activation='gelu')\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "        self.decoder = nn.Linear(d_input*n_head, args.n_predicted_month)\n",
    "        self.sigma = nn.Parameter(torch.ones(args.n_predicted_month))\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, X_batch, y_batch=None):\n",
    "        X_batch = self.pe(X_batch)\n",
    "        X_batch = self.transformer_encoder(X_batch)\n",
    "        X_batch = X_batch.view(X_batch.size(0), -1)\n",
    "        \n",
    "        y_predicted = self.decoder(X_batch)\n",
    "        if y_batch != None:\n",
    "            assert y_predicted.size() == y_batch.size()\n",
    "            loss = self.loss_fn(y_predicted, y_batch)\n",
    "            loss = 0.5 * loss / self.sigma**2\n",
    "            loss = loss.sum() + torch.log(1 + self.sigma.prod())\n",
    "            return y_predicted, loss\n",
    "        else:\n",
    "            return y_predicted\n",
    "        return X_batch\n",
    "    \n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor(X, device=args.device)\n",
    "        return self.forward(X).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaAY5LAp2Htc"
   },
   "source": [
    "# Class Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675101194243,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "8TvH93W9mNWQ"
   },
   "outputs": [],
   "source": [
    "# Create class to train and evaluate models\n",
    "class Trainer():\n",
    "    def __init__(self, city, model_type, learning_rate, important_features, train_loader, test_tensor, n_layers=2, hidden_size=128, num_filters=[100, 100, 100], dropout=0.01):\n",
    "        \"\"\"\n",
    "        Initialise trainer, allowing input of LSTM, LSTM-ATT, or CNN \n",
    "        hyperparameters. Adam optimiser used for all models.\n",
    "        \"\"\"\n",
    "        self.model_type = model_type    \n",
    "        self.city = city    \n",
    "        self.Model = self.init_model(model_type, n_layers, hidden_size, num_filters, dropout, city)\n",
    "        self.Model.double().to(args.device)\n",
    "        self.optimizer = torch.optim.Adam(self.Model.parameters(), lr=learning_rate)\n",
    "        self.important_features, self.train_loader, self.test_tensor = important_features, train_loader, test_tensor\n",
    "    \n",
    "    def init_model(self, model_type, n_layers, hidden_size, num_filters, dropout, city):\n",
    "        \"\"\"Initialise a model based on whether LSTM, LSTM-ATT, CNN or Transformer is chosen.\"\"\"\n",
    "        model = TransformerModel()\n",
    "        if model_type.lower() == 'lstm':\n",
    "            model = MultiVariateLSTM(args.n_features, n_layers, hidden_size)\n",
    "        elif model_type.lower() == 'lstm_attention':\n",
    "            model = MultiVariateLSTM_Attention(args.n_features, n_layers, hidden_size)\n",
    "        elif model_type.lower() == 'cnn':\n",
    "            model = MultivariateCNN(num_filters, dropout)\n",
    "        elif model_type.lower() == 'transformers':\n",
    "            model = TransformerModel(d_input=args.look_back, n_head=3, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
    "        return model\n",
    "\n",
    "    def step(self, batch):\n",
    "        self.Model.train()\n",
    "        X_batch, y_batch = tuple(t.to(args.device) for t in batch)\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred, loss = self.Model.forward(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.mean().item()\n",
    "\n",
    "    def validation(self):\n",
    "        self.Model.eval()\n",
    "        eval_loss = 0.0\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        y_true = np.array([])\n",
    "        y_pred = np.array([])\n",
    "\n",
    "        X_batch, y_batch = tuple(t.to(args.device) for t in self.test_tensor)\n",
    "        with torch.no_grad():\n",
    "            outputs, loss = self.Model.forward(X_batch, y_batch)\n",
    "            eval_loss = loss.mean().item()\n",
    "\n",
    "        return eval_loss\n",
    "\n",
    "    def train(self, epochs=20):\n",
    "        best_lost = float(\"inf\")\n",
    "        best_model = None\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            for batch in self.train_loader:\n",
    "                loss = self.step(batch)\n",
    "                total_loss += loss\n",
    "            train_loss = total_loss/len(self.train_loader)\n",
    "            eval_loss = self.validation()\n",
    "            if eval_loss < best_lost:\n",
    "                best_lost = eval_loss\n",
    "                best_model = copy.deepcopy(self.Model)\n",
    "            if (epoch + 1) == epochs or (epoch + 1) in [c + 1 for c in range(epochs) if c % int(epochs/4) == 0]:\n",
    "                print(f\"Epoch: {epoch:2}/{epochs:2} - train_loss: {train_loss:.4f} - test_loss: {eval_loss:4f}\")\n",
    "        self.Model = best_model\n",
    "        self.Model.eval()\n",
    "        return None\n",
    "\n",
    "    # Lưu model vào trong thư mục models\n",
    "    def save_model_to(self, path = '', city =''):       \n",
    "        torch.save(self.Model, path)\n",
    "\n",
    "    def load_model_to(self, path = ''):       \n",
    "        return torch.load(path)\n",
    "\n",
    "    def evaluate_model(self, np_data=None, plot=True, scaled=True, city=None, k_steps=None, y_scaler =None):\n",
    "        assert scaled, \"data must be scaled\"\n",
    "        self.Model.eval()\n",
    "        tensor_data = torch.from_numpy(np_data)\n",
    "        rmse_list = []\n",
    "        mae_list = [] \n",
    "        mape_list = []\n",
    "\n",
    "        y_predicted_list = []\n",
    "        y_true_list = []\n",
    "\n",
    "        for k_steps in range(1, args.n_predicted_month + 1):\n",
    "            y_predicted = []\n",
    "            y_true = []\n",
    "            for index in range(tensor_data.size(0) - args.look_back):\n",
    "                X = tensor_data[index: index + args.look_back, self.important_features]\n",
    "                # yhat = self.Model.predict(X.unsqueeze(0)).squeeze()\n",
    "\n",
    "                yhat = self.Model.predict(X.unsqueeze(0))\n",
    "                yhat = yhat.squeeze()\n",
    "\n",
    "                y_predicted.append(yhat.detach().cpu().numpy()[k_steps - 1])\n",
    "                y_true.append(tensor_data[index + args.look_back, -1].detach().cpu().numpy())\n",
    "\n",
    "            y_predicted = y_scaler.inverse_transform(np.array(y_predicted).reshape(-1, 1)).reshape(-1, )\n",
    "            y_true = y_scaler.inverse_transform(np.array(y_true).reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "            rmse = mean_squared_error(y_true, y_predicted, squared=False)\n",
    "            mae = mean_absolute_error(y_true, y_predicted)\n",
    "            mape = mean_absolute_percentage_error(y_true, y_predicted)\n",
    "\n",
    "            rmse_list.append(rmse)\n",
    "            mae_list.append(mae)\n",
    "            mape_list.append(mape)\n",
    "\n",
    "            # print('City: '+self.city+'  _algo:'+self.model_type+'  -RMSE: '+str(rmse))\n",
    "            if plot==True:\n",
    "              plt.grid(True)\n",
    "              plt.plot(y_predicted, label='predicted')\n",
    "              plt.plot(y_true, label='actual')\n",
    "              plt.title(f\"k-steps = {k_steps} - city: \"+self.city+'  _algo:'+self.model_type+'  -RMSE: '+str(rmse))\n",
    "              plt.legend()\n",
    "              plt.show()\n",
    "\n",
    "              plt.show()\n",
    "            y_predicted_list.append(y_predicted)\n",
    "            y_true_list.append(y_true)\n",
    "\n",
    "        return y_true_list, y_predicted_list, rmse_list, mae_list, mape_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gOIdsGo19Oc"
   },
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675101194243,
     "user": {
      "displayName": "Nhat Le",
      "userId": "00702307310725808810"
     },
     "user_tz": -420
    },
    "id": "8px_TDW2mtRt"
   },
   "outputs": [],
   "source": [
    "def objective(trial, city):\n",
    "    # Define search parameters\n",
    "    n_layers = trial.suggest_int('n layers', 3, 6) # a    \n",
    "    hidden_size = trial.suggest_int('Hidden size', 5, 384, log=True) #b\n",
    "    learning_rate = trial.suggest_loguniform('Learning rate', 1e-4, 1e-2)\n",
    "    dropout = trial.suggest_uniform('Dropout rate', 0.01, 0.80)\n",
    "    args.epochs = trial.suggest_int('Epochs', 100, 500, step=10)\n",
    "    lookback_window = 3 # fix cứng optimize sau\n",
    "\n",
    "    # Pre-process data\n",
    "    specific_data = get_city_data(fix_text(city))\n",
    "    specific_data = impute_missing_value(specific_data)\n",
    "    specific_data = convert_to_stationary(specific_data)\n",
    "    specific_data.dropna(inplace=True)\n",
    "\n",
    "    train, test = split_data(specific_data,lookback_window)\n",
    "\n",
    "    # Fit data scaler to training data\n",
    "    full_scaler = MinMaxScaler().fit(train)\n",
    "    y_scaler = MinMaxScaler().fit(train.values[:, -1].reshape(-1, 1))\n",
    "\n",
    "    # Scale train and test data\n",
    "    train = full_scaler.transform(train)\n",
    "    test = full_scaler.transform(test)\n",
    "\n",
    "    # Get data to run model\n",
    "    important_features, train_loader, test_tensor = get_data(train, test, args.batch_size, specific_data)\n",
    "\n",
    "    # Transformer model\n",
    "    trainer = Trainer(model_type='transformer',\n",
    "                  city = city,\n",
    "                  important_features=important_features,\n",
    "                  train_loader=train_loader,\n",
    "                  test_tensor=test_tensor,\n",
    "                  n_layers=n_layers,\n",
    "                  hidden_size=hidden_size,\n",
    "                  learning_rate=learning_rate,\n",
    "                  dropout=dropout)\n",
    "\n",
    "    # Train model\n",
    "    # trainer.train(epochs=args.epochs, trial=trial)\n",
    "    trainer.train(epochs=args.epochs)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_true, y_pred, rmse_list, mae_list, mape_list = trainer.evaluate_model(np_data=test, plot= False, scaled=True, city=city, y_scaler = y_scaler)\n",
    "    # _, _, rmse, mae, = trainer.evaluate_model(np_data=test, plot=False, scaled=True, city=city, y_scaler=y_scaler)\n",
    "\n",
    "    return mae_list[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHbv5lQ7dn3S"
   },
   "source": [
    "# Main Cell For Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggBbhETfXbsk",
    "outputId": "743bc695-4dd4-4b98-e665-df86250c4a04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:16:03,336]\u001b[0m A new study created in memory with name: no-name-88e6cbee-b82e-455f-a7cc-7602f90e3448\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/240 - train_loss: 1.6194 - test_loss: 0.816275\n",
      "Epoch:  0/240 - train_loss: 0.8545 - test_loss: 0.713307Epoch:  0/240 - train_loss: 0.8094 - test_loss: 0.733607Epoch:  0/240 - train_loss: 1.2065 - test_loss: 0.657757Epoch:  0/240 - train_loss: 0.9499 - test_loss: 0.797417\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  0/240 - train_loss: 1.4215 - test_loss: 1.015825\n",
      "Epoch:  0/240 - train_loss: 1.7483 - test_loss: 0.902604\n",
      "Epoch:  0/240 - train_loss: 1.1377 - test_loss: 0.794228Epoch:  0/240 - train_loss: 1.2894 - test_loss: 0.719010\n",
      "\n",
      "Epoch:  0/240 - train_loss: 1.2482 - test_loss: 0.870136\n",
      "Epoch:  0/240 - train_loss: 1.6423 - test_loss: 1.961987\n",
      "Epoch:  0/240 - train_loss: 1.7096 - test_loss: 1.372632Epoch:  0/240 - train_loss: 1.5210 - test_loss: 0.820703\n",
      "\n",
      "Epoch:  0/240 - train_loss: 1.9140 - test_loss: 1.267055Epoch:  0/240 - train_loss: 1.4315 - test_loss: 0.802183\n",
      "\n",
      "Epoch:  0/240 - train_loss: 1.4672 - test_loss: 1.012116\n",
      "Epoch:  0/240 - train_loss: 1.5043 - test_loss: 0.792909\n",
      "Epoch:  0/240 - train_loss: 1.3063 - test_loss: 1.244963\n",
      "Epoch:  0/240 - train_loss: 1.0296 - test_loss: 1.027216\n",
      "Epoch:  0/240 - train_loss: 1.6249 - test_loss: 0.921999\n",
      "Epoch: 60/240 - train_loss: 0.8303 - test_loss: 0.674826\n",
      "Epoch: 60/240 - train_loss: 0.3408 - test_loss: 0.407663\n",
      "Epoch: 60/240 - train_loss: 0.5853 - test_loss: 0.589935\n",
      "Epoch: 60/240 - train_loss: 0.4423 - test_loss: 0.407697\n",
      "Epoch: 60/240 - train_loss: 0.3195 - test_loss: 0.384488\n",
      "Epoch: 120/240 - train_loss: 0.6178 - test_loss: 0.604972\n",
      "Epoch: 120/240 - train_loss: 0.3570 - test_loss: 0.329013\n",
      "Epoch: 60/240 - train_loss: 0.3264 - test_loss: 0.415687\n",
      "Epoch: 120/240 - train_loss: 0.4412 - test_loss: 0.449904\n",
      "Epoch: 60/240 - train_loss: 0.9228 - test_loss: 0.742948\n",
      "Epoch: 120/240 - train_loss: 0.3235 - test_loss: 0.377079\n",
      "Epoch: 180/240 - train_loss: 0.5369 - test_loss: 0.519310\n",
      "Epoch: 60/240 - train_loss: 0.3179 - test_loss: 0.364062\n",
      "Epoch: 120/240 - train_loss: 0.3263 - test_loss: 0.366562\n",
      "Epoch: 180/240 - train_loss: 0.3213 - test_loss: 0.358015\n",
      "Epoch: 180/240 - train_loss: 0.3741 - test_loss: 0.389792\n",
      "Epoch: 120/240 - train_loss: 0.3266 - test_loss: 0.399320\n",
      "Epoch: 180/240 - train_loss: 0.3248 - test_loss: 0.375549\n",
      "Epoch: 239/240 - train_loss: 0.4357 - test_loss: 0.465734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:27:01,321]\u001b[0m Trial 7 finished with value: 24.6667908698284 and parameters: {'n layers': 5, 'Hidden size': 15, 'Learning rate': 0.0001066673478983732, 'Dropout rate': 0.3367738780350509, 'Epochs': 290}. Best is trial 7 with value: 24.6667908698284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 120/240 - train_loss: 0.5794 - test_loss: 0.481251\n",
      "Epoch: 239/240 - train_loss: 0.3185 - test_loss: 0.334695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:27:17,326]\u001b[0m Trial 17 finished with value: 16.191801508309748 and parameters: {'n layers': 3, 'Hidden size': 243, 'Learning rate': 0.005052696534135308, 'Dropout rate': 0.6856575773865976, 'Epochs': 420}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 180/240 - train_loss: 0.3328 - test_loss: 0.328832\n",
      "Epoch:  0/210 - train_loss: 1.4341 - test_loss: 1.408703\n",
      "Epoch: 239/240 - train_loss: 0.3296 - test_loss: 0.375308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:27:55,906]\u001b[0m Trial 10 finished with value: 20.223274195507447 and parameters: {'n layers': 5, 'Hidden size': 105, 'Learning rate': 0.00019528506866581954, 'Dropout rate': 0.3092395801736202, 'Epochs': 200}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 180/240 - train_loss: 0.3332 - test_loss: 0.321569\n",
      "Epoch:  0/140 - train_loss: 1.3366 - test_loss: 0.781122\n",
      "Epoch: 120/240 - train_loss: 0.3201 - test_loss: 0.392241\n",
      "Epoch: 239/240 - train_loss: 0.3181 - test_loss: 0.374812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:28:43,727]\u001b[0m Trial 16 finished with value: 18.52341307367487 and parameters: {'n layers': 3, 'Hidden size': 172, 'Learning rate': 0.0004980017251026896, 'Dropout rate': 0.21538127388854097, 'Epochs': 260}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/140 - train_loss: 1.3505 - test_loss: 0.913970\n",
      "lookback 3\n",
      "Epoch: 35/140 - train_loss: 0.4306 - test_loss: 0.435161\n",
      "Epoch: 239/240 - train_loss: 0.3215 - test_loss: 0.363948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:29:17,363]\u001b[0m Trial 5 finished with value: 17.549188023753384 and parameters: {'n layers': 4, 'Hidden size': 21, 'Learning rate': 0.006227395293439369, 'Dropout rate': 0.7812107688597949, 'Epochs': 170}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 180/240 - train_loss: 0.4309 - test_loss: 0.405797\n",
      "Epoch: 52/210 - train_loss: 0.6938 - test_loss: 0.610882\n",
      "Epoch:  0/260 - train_loss: 1.1061 - test_loss: 0.748920\n",
      "Epoch: 35/140 - train_loss: 0.7276 - test_loss: 0.698801\n",
      "Epoch: 239/240 - train_loss: 0.3293 - test_loss: 0.372350\n",
      "Epoch:  0/260 - train_loss: 1.8058 - test_loss: 1.741125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:30:02,618]\u001b[0m Trial 1 finished with value: 17.740821377943163 and parameters: {'n layers': 3, 'Hidden size': 9, 'Learning rate': 0.004461422331413588, 'Dropout rate': 0.7693039579915096, 'Epochs': 300}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 70/140 - train_loss: 0.3355 - test_loss: 0.359095\n",
      "Epoch: 180/240 - train_loss: 0.3159 - test_loss: 0.361127\n",
      "Epoch: 70/140 - train_loss: 0.6265 - test_loss: 0.629517\n",
      "Epoch:  0/470 - train_loss: 1.7278 - test_loss: 1.059270\n",
      "Epoch: 104/210 - train_loss: 0.4999 - test_loss: 0.493840\n",
      "Epoch: 105/140 - train_loss: 0.3195 - test_loss: 0.372936\n",
      "Epoch: 65/260 - train_loss: 0.3387 - test_loss: 0.394573\n",
      "Epoch: 239/240 - train_loss: 0.3571 - test_loss: 0.345406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:31:09,121]\u001b[0m Trial 8 finished with value: 19.54662909312474 and parameters: {'n layers': 3, 'Hidden size': 102, 'Learning rate': 0.0001551433284959247, 'Dropout rate': 0.28497330975046936, 'Epochs': 290}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 105/140 - train_loss: 0.6180 - test_loss: 0.568638\n",
      "Epoch:  0/380 - train_loss: 1.7467 - test_loss: 1.462508\n",
      "Epoch: 65/260 - train_loss: 0.7854 - test_loss: 0.643128\n",
      "Epoch: 139/140 - train_loss: 0.3232 - test_loss: 0.395091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:31:53,748]\u001b[0m Trial 21 finished with value: 17.459187410398837 and parameters: {'n layers': 4, 'Hidden size': 64, 'Learning rate': 0.0007848458158262655, 'Dropout rate': 0.5899384818925567, 'Epochs': 210}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 156/210 - train_loss: 0.4076 - test_loss: 0.430297\n",
      "Epoch: 139/140 - train_loss: 0.5034 - test_loss: 0.522342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:32:27,106]\u001b[0m Trial 22 finished with value: 22.067018880371393 and parameters: {'n layers': 5, 'Hidden size': 30, 'Learning rate': 0.00012307639485650216, 'Dropout rate': 0.13246587910278657, 'Epochs': 140}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 239/240 - train_loss: 0.3870 - test_loss: 0.390624\n",
      "Epoch:  0/260 - train_loss: 1.3311 - test_loss: 1.065326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:32:38,552]\u001b[0m Trial 6 finished with value: 18.212619419344893 and parameters: {'n layers': 6, 'Hidden size': 48, 'Learning rate': 0.0014019654216981768, 'Dropout rate': 0.7223163455974857, 'Epochs': 470}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 130/260 - train_loss: 0.3231 - test_loss: 0.366080\n",
      "Epoch:  0/430 - train_loss: 0.9370 - test_loss: 0.806440\n",
      "Epoch: 208/210 - train_loss: 0.3456 - test_loss: 0.404190\n",
      "Epoch: 209/210 - train_loss: 0.4042 - test_loss: 0.403435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:33:40,621]\u001b[0m Trial 20 finished with value: 23.746169457160022 and parameters: {'n layers': 4, 'Hidden size': 245, 'Learning rate': 0.00019642417222963062, 'Dropout rate': 0.5051588939426062, 'Epochs': 400}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/430 - train_loss: 1.2317 - test_loss: 0.763421\n",
      "lookback 3\n",
      "Epoch: 130/260 - train_loss: 0.5369 - test_loss: 0.508153\n",
      "Epoch:  0/390 - train_loss: 1.3488 - test_loss: 0.853627\n",
      "Epoch: 117/470 - train_loss: 0.3843 - test_loss: 0.408481\n",
      "Epoch: 65/260 - train_loss: 0.3620 - test_loss: 0.371534\n",
      "Epoch: 195/260 - train_loss: 0.3907 - test_loss: 0.364160\n",
      "Epoch: 95/380 - train_loss: 0.3263 - test_loss: 0.354117\n",
      "Epoch: 195/260 - train_loss: 0.4041 - test_loss: 0.419279\n",
      "Epoch: 130/260 - train_loss: 0.3303 - test_loss: 0.388745\n",
      "Epoch: 107/430 - train_loss: 0.3264 - test_loss: 0.364737\n",
      "Epoch: 259/260 - train_loss: 0.3201 - test_loss: 0.403885\n",
      "Epoch: 97/390 - train_loss: 0.3305 - test_loss: 0.367114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:36:06,206]\u001b[0m Trial 23 finished with value: 19.729024882823126 and parameters: {'n layers': 4, 'Hidden size': 53, 'Learning rate': 0.004602861155196333, 'Dropout rate': 0.47772817874188706, 'Epochs': 180}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/390 - train_loss: 1.2020 - test_loss: 0.792075\n",
      "Epoch: 259/260 - train_loss: 0.3461 - test_loss: 0.388593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:36:58,304]\u001b[0m Trial 24 finished with value: 22.46267331637949 and parameters: {'n layers': 6, 'Hidden size': 257, 'Learning rate': 0.00017096122489222042, 'Dropout rate': 0.018381442085791053, 'Epochs': 260}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 195/260 - train_loss: 0.3166 - test_loss: 0.378935\n",
      "Epoch: 234/470 - train_loss: 0.3713 - test_loss: 0.367581\n",
      "Epoch:  0/420 - train_loss: 1.4732 - test_loss: 0.839872\n",
      "Epoch: 190/380 - train_loss: 0.3192 - test_loss: 0.355441\n",
      "Epoch: 107/430 - train_loss: 0.3252 - test_loss: 0.374500\n",
      "Epoch: 60/240 - train_loss: 0.3301 - test_loss: 0.361974\n",
      "Epoch: 60/240 - train_loss: 0.3315 - test_loss: 0.353781\n",
      "Epoch: 60/240 - train_loss: 0.3333 - test_loss: 0.441513\n",
      "Epoch: 60/240 - train_loss: 0.3213 - test_loss: 0.363935\n",
      "Epoch: 60/240 - train_loss: 0.4358 - test_loss: 0.403388\n",
      "Epoch: 60/240 - train_loss: 0.3429 - test_loss: 0.374139\n",
      "Epoch: 60/240 - train_loss: 0.3211 - test_loss: 0.308247\n",
      "Epoch: 60/240 - train_loss: 0.7803 - test_loss: 0.745948Epoch: 60/240 - train_loss: 0.3492 - test_loss: 0.300006\n",
      "\n",
      "Epoch: 60/240 - train_loss: 0.5968 - test_loss: 0.574672\n",
      "Epoch: 60/240 - train_loss: 0.6686 - test_loss: 0.660218\n",
      "Epoch: 60/240 - train_loss: 0.3172 - test_loss: 0.282347\n",
      "Epoch: 214/430 - train_loss: 0.3395 - test_loss: 0.361266\n",
      "Epoch: 194/390 - train_loss: 0.3185 - test_loss: 0.390732\n",
      "Epoch: 259/260 - train_loss: 0.3183 - test_loss: 0.372776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:38:33,510]\u001b[0m Trial 27 finished with value: 16.299502543447243 and parameters: {'n layers': 5, 'Hidden size': 42, 'Learning rate': 0.0006659844301249135, 'Dropout rate': 0.17033404915422076, 'Epochs': 200}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 97/390 - train_loss: 0.3733 - test_loss: 0.375760\n",
      "Epoch:  0/380 - train_loss: 1.3443 - test_loss: 1.017297\n",
      "Epoch: 105/420 - train_loss: 0.3205 - test_loss: 0.398992\n",
      "Epoch: 351/470 - train_loss: 0.3784 - test_loss: 0.365540\n",
      "Epoch: 291/390 - train_loss: 0.3231 - test_loss: 0.372490\n",
      "Epoch: 321/430 - train_loss: 0.3192 - test_loss: 0.388029\n",
      "Epoch: 285/380 - train_loss: 0.3318 - test_loss: 0.359918\n",
      "Epoch: 95/380 - train_loss: 0.3232 - test_loss: 0.380482\n",
      "Epoch: 194/390 - train_loss: 0.3251 - test_loss: 0.390535\n",
      "Epoch: 120/240 - train_loss: 0.3195 - test_loss: 0.380576\n",
      "Epoch: 214/430 - train_loss: 0.3260 - test_loss: 0.373487\n",
      "Epoch: 388/390 - train_loss: 0.3228 - test_loss: 0.338198\n",
      "Epoch: 389/390 - train_loss: 0.3420 - test_loss: 0.375786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:42:04,551]\u001b[0m Trial 30 finished with value: 16.47712734731512 and parameters: {'n layers': 4, 'Hidden size': 381, 'Learning rate': 0.0019100693517668358, 'Dropout rate': 0.5448413536173051, 'Epochs': 390}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 210/420 - train_loss: 0.3236 - test_loss: 0.350633\n",
      "Epoch:  0/370 - train_loss: 1.5511 - test_loss: 1.153745\n",
      "Epoch: 428/430 - train_loss: 0.3302 - test_loss: 0.370876\n",
      "Epoch: 429/430 - train_loss: 0.3291 - test_loss: 0.359355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:42:47,794]\u001b[0m Trial 28 finished with value: 18.616959115655476 and parameters: {'n layers': 3, 'Hidden size': 88, 'Learning rate': 0.003092801371140783, 'Dropout rate': 0.24110772007329928, 'Epochs': 260}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 190/380 - train_loss: 0.3259 - test_loss: 0.345625\n",
      "Epoch: 468/470 - train_loss: 0.3812 - test_loss: 0.355377\n",
      "Epoch: 469/470 - train_loss: 0.3320 - test_loss: 0.339190\n",
      "Epoch: 291/390 - train_loss: 0.3233 - test_loss: 0.380396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:43:14,678]\u001b[0m Trial 25 finished with value: 18.572949519336238 and parameters: {'n layers': 5, 'Hidden size': 25, 'Learning rate': 0.000292615882104132, 'Dropout rate': 0.49604111273991525, 'Epochs': 470}. Best is trial 17 with value: 16.191801508309748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 379/380 - train_loss: 0.3230 - test_loss: 0.390861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:43:19,610]\u001b[0m Trial 26 finished with value: 15.647226254592143 and parameters: {'n layers': 4, 'Hidden size': 24, 'Learning rate': 0.0010903424369172329, 'Dropout rate': 0.6901992197256113, 'Epochs': 380}. Best is trial 26 with value: 15.647226254592143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/370 - train_loss: 0.8482 - test_loss: 0.666185\n",
      "Epoch: 120/240 - train_loss: 0.3376 - test_loss: 0.351902\n",
      "Epoch:  0/370 - train_loss: 1.1364 - test_loss: 0.789405\n",
      "Epoch:  0/370 - train_loss: 1.1947 - test_loss: 0.665353\n",
      "Epoch: 180/240 - train_loss: 0.3188 - test_loss: 0.348187\n",
      "Epoch: 315/420 - train_loss: 0.3248 - test_loss: 0.373611\n",
      "Epoch: 92/370 - train_loss: 0.3226 - test_loss: 0.391088\n",
      "Epoch: 285/380 - train_loss: 0.3772 - test_loss: 0.367914\n",
      "Epoch: 388/390 - train_loss: 0.3178 - test_loss: 0.356421\n",
      "Epoch: 389/390 - train_loss: 0.3169 - test_loss: 0.332181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:45:37,620]\u001b[0m Trial 31 finished with value: 15.830433330738591 and parameters: {'n layers': 3, 'Hidden size': 336, 'Learning rate': 0.0016563756974776913, 'Dropout rate': 0.5957534304931291, 'Epochs': 390}. Best is trial 26 with value: 15.647226254592143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/370 - train_loss: 0.3307 - test_loss: 0.408552\n",
      "lookback 3\n",
      "Epoch: 321/430 - train_loss: 0.3504 - test_loss: 0.417261\n",
      "Epoch:  0/340 - train_loss: 1.9532 - test_loss: 1.282945\n",
      "Epoch: 92/370 - train_loss: 0.3355 - test_loss: 0.430856\n",
      "Epoch: 92/370 - train_loss: 0.3304 - test_loss: 0.364692\n",
      "Epoch: 184/370 - train_loss: 0.3879 - test_loss: 0.389095\n",
      "Epoch: 379/380 - train_loss: 0.3296 - test_loss: 0.394513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:47:10,669]\u001b[0m Trial 33 finished with value: 18.031454045100304 and parameters: {'n layers': 5, 'Hidden size': 5, 'Learning rate': 0.0021367305595632337, 'Dropout rate': 0.01886032922451472, 'Epochs': 380}. Best is trial 26 with value: 15.647226254592143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 239/240 - train_loss: 0.3399 - test_loss: 0.397882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:47:14,798]\u001b[0m Trial 18 finished with value: 18.298930643603256 and parameters: {'n layers': 3, 'Hidden size': 46, 'Learning rate': 0.008132656992496884, 'Dropout rate': 0.7698445086021896, 'Epochs': 390}. Best is trial 26 with value: 15.647226254592143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 419/420 - train_loss: 0.3402 - test_loss: 0.320880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:47:21,104]\u001b[0m Trial 32 finished with value: 16.870580454970646 and parameters: {'n layers': 3, 'Hidden size': 350, 'Learning rate': 0.0018731852409910313, 'Dropout rate': 0.6132214126056831, 'Epochs': 420}. Best is trial 26 with value: 15.647226254592143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 184/370 - train_loss: 0.3304 - test_loss: 0.370236\n",
      "Epoch: 180/240 - train_loss: 0.3207 - test_loss: 0.399810\n",
      "Epoch:  0/330 - train_loss: 1.2602 - test_loss: 0.769127\n",
      "Epoch:  0/330 - train_loss: 1.2396 - test_loss: 0.783468\n",
      "Epoch:  0/330 - train_loss: 1.5287 - test_loss: 1.127982\n",
      "Epoch: 85/340 - train_loss: 0.3306 - test_loss: 0.349208\n",
      "Epoch: 184/370 - train_loss: 0.3174 - test_loss: 0.396235\n",
      "Epoch: 276/370 - train_loss: 0.3374 - test_loss: 0.412359\n",
      "Epoch: 184/370 - train_loss: 0.3904 - test_loss: 0.340027\n",
      "Epoch: 428/430 - train_loss: 0.3210 - test_loss: 0.406789\n",
      "Epoch: 429/430 - train_loss: 0.3188 - test_loss: 0.371200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:49:36,602]\u001b[0m Trial 29 finished with value: 15.230893420915598 and parameters: {'n layers': 4, 'Hidden size': 336, 'Learning rate': 0.0027352179038096043, 'Dropout rate': 0.5184188091935471, 'Epochs': 430}. Best is trial 29 with value: 15.230893420915598.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 276/370 - train_loss: 0.3277 - test_loss: 0.312514\n",
      "Epoch: 82/330 - train_loss: 0.3205 - test_loss: 0.388197\n",
      "Epoch:  0/350 - train_loss: 1.7821 - test_loss: 1.108844\n",
      "Epoch: 82/330 - train_loss: 0.3292 - test_loss: 0.373514\n",
      "Epoch: 170/340 - train_loss: 0.3238 - test_loss: 0.360499\n",
      "Epoch: 368/370 - train_loss: 0.3321 - test_loss: 0.353997\n",
      "Epoch: 369/370 - train_loss: 0.3273 - test_loss: 0.421643\n",
      "Epoch: 276/370 - train_loss: 0.4146 - test_loss: 0.400752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:51:01,373]\u001b[0m Trial 34 finished with value: 19.543383770234698 and parameters: {'n layers': 5, 'Hidden size': 6, 'Learning rate': 0.0026211714268217054, 'Dropout rate': 0.6310989425733864, 'Epochs': 370}. Best is trial 29 with value: 15.230893420915598.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/340 - train_loss: 1.6725 - test_loss: 1.560464\n",
      "Epoch: 164/330 - train_loss: 0.3189 - test_loss: 0.318096\n",
      "Epoch: 368/370 - train_loss: 0.3237 - test_loss: 0.316897\n",
      "Epoch: 369/370 - train_loss: 0.3387 - test_loss: 0.364945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:51:53,560]\u001b[0m Trial 35 finished with value: 14.914681663856816 and parameters: {'n layers': 5, 'Hidden size': 7, 'Learning rate': 0.009842487343130826, 'Dropout rate': 0.4069117448510397, 'Epochs': 380}. Best is trial 35 with value: 14.914681663856816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 276/370 - train_loss: 0.3395 - test_loss: 0.352158\n",
      "Epoch: 120/240 - train_loss: 0.3267 - test_loss: 0.354555\n",
      "Epoch: 164/330 - train_loss: 0.3237 - test_loss: 0.343573\n",
      "Epoch: 255/340 - train_loss: 0.3139 - test_loss: 0.360049\n",
      "Epoch: 82/330 - train_loss: 0.3293 - test_loss: 0.364310\n",
      "Epoch:  0/350 - train_loss: 1.6395 - test_loss: 1.014086\n",
      "Epoch: 239/240 - train_loss: 0.3264 - test_loss: 0.314605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:52:34,687]\u001b[0m Trial 12 finished with value: 19.017838214204144 and parameters: {'n layers': 6, 'Hidden size': 69, 'Learning rate': 0.0028910016300575077, 'Dropout rate': 0.6772383340543855, 'Epochs': 270}. Best is trial 35 with value: 14.914681663856816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 87/350 - train_loss: 0.3235 - test_loss: 0.395152\n",
      "Epoch:  0/350 - train_loss: 1.5375 - test_loss: 1.354545\n",
      "Epoch: 368/370 - train_loss: 0.3178 - test_loss: 0.374656\n",
      "Epoch: 369/370 - train_loss: 0.3185 - test_loss: 0.363528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:53:30,138]\u001b[0m Trial 36 finished with value: 13.548062029201825 and parameters: {'n layers': 6, 'Hidden size': 6, 'Learning rate': 0.009683190734258716, 'Dropout rate': 0.6502704855935032, 'Epochs': 370}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 85/340 - train_loss: 0.3161 - test_loss: 0.401361\n",
      "Epoch: 246/330 - train_loss: 0.3156 - test_loss: 0.345725\n",
      "Epoch:  0/330 - train_loss: 1.0204 - test_loss: 0.746444\n",
      "Epoch: 246/330 - train_loss: 0.3765 - test_loss: 0.361790\n",
      "Epoch: 339/340 - train_loss: 0.3430 - test_loss: 0.351294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:54:20,283]\u001b[0m Trial 38 finished with value: 16.824094415965458 and parameters: {'n layers': 3, 'Hidden size': 6, 'Learning rate': 0.002044882912112056, 'Dropout rate': 0.6590496938108819, 'Epochs': 340}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 368/370 - train_loss: 0.3202 - test_loss: 0.362158\n",
      "Epoch: 369/370 - train_loss: 0.3721 - test_loss: 0.333449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:54:41,146]\u001b[0m Trial 37 finished with value: 16.92827037296017 and parameters: {'n layers': 3, 'Hidden size': 8, 'Learning rate': 0.00960083925044421, 'Dropout rate': 0.6397279935035405, 'Epochs': 370}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 87/350 - train_loss: 0.3409 - test_loss: 0.394611\n",
      "Epoch:  0/500 - train_loss: 0.9568 - test_loss: 0.696375\n",
      "Epoch:  0/500 - train_loss: 1.2725 - test_loss: 0.735395\n",
      "Epoch: 170/340 - train_loss: 0.3221 - test_loss: 0.398025\n",
      "Epoch: 328/330 - train_loss: 0.3235 - test_loss: 0.375503\n",
      "Epoch: 329/330 - train_loss: 0.3276 - test_loss: 0.371421\n",
      "Epoch: 164/330 - train_loss: 0.3222 - test_loss: 0.388007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:55:50,260]\u001b[0m Trial 39 finished with value: 16.690718781825982 and parameters: {'n layers': 3, 'Hidden size': 10, 'Learning rate': 0.0012720598288842456, 'Dropout rate': 0.6374635901038971, 'Epochs': 350}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 174/350 - train_loss: 0.3202 - test_loss: 0.348431\n",
      "Epoch:  0/450 - train_loss: 1.0929 - test_loss: 0.693298\n",
      "Epoch: 82/330 - train_loss: 0.3342 - test_loss: 0.373848\n",
      "Epoch: 328/330 - train_loss: 0.3191 - test_loss: 0.368120\n",
      "Epoch: 329/330 - train_loss: 0.3223 - test_loss: 0.339483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:56:34,201]\u001b[0m Trial 41 finished with value: 17.707232426816862 and parameters: {'n layers': 3, 'Hidden size': 138, 'Learning rate': 0.0011071539488765303, 'Dropout rate': 0.6740032048983724, 'Epochs': 330}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 174/350 - train_loss: 0.3204 - test_loss: 0.369515\n",
      "Epoch: 255/340 - train_loss: 0.3862 - test_loss: 0.382136\n",
      "Epoch: 180/240 - train_loss: 0.3235 - test_loss: 0.388099\n",
      "Epoch: 125/500 - train_loss: 0.3222 - test_loss: 0.379018\n",
      "Epoch: 164/330 - train_loss: 0.3667 - test_loss: 0.346288\n",
      "Epoch: 87/350 - train_loss: 0.4390 - test_loss: 0.355244\n",
      "Epoch: 261/350 - train_loss: 0.3220 - test_loss: 0.360663\n",
      "Epoch: 261/350 - train_loss: 0.3345 - test_loss: 0.296365\n",
      "Epoch: 125/500 - train_loss: 0.3917 - test_loss: 0.369751\n",
      "Epoch: 112/450 - train_loss: 0.3532 - test_loss: 0.323726\n",
      "Epoch: 246/330 - train_loss: 0.3715 - test_loss: 0.335542\n",
      "Epoch: 339/340 - train_loss: 0.3248 - test_loss: 0.372850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:58:16,704]\u001b[0m Trial 43 finished with value: 19.19309732789613 and parameters: {'n layers': 4, 'Hidden size': 178, 'Learning rate': 0.0012489013573502943, 'Dropout rate': 0.4171902849000714, 'Epochs': 340}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 246/330 - train_loss: 0.3299 - test_loss: 0.388595\n",
      "Epoch: 348/350 - train_loss: 0.3198 - test_loss: 0.373106\n",
      "Epoch: 349/350 - train_loss: 0.3197 - test_loss: 0.365921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:58:57,953]\u001b[0m Trial 44 finished with value: 17.908546561602225 and parameters: {'n layers': 4, 'Hidden size': 12, 'Learning rate': 0.00110390826522278, 'Dropout rate': 0.371542534555794, 'Epochs': 350}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/500 - train_loss: 0.3358 - test_loss: 0.331355\n",
      "Epoch: 348/350 - train_loss: 0.3184 - test_loss: 0.373047\n",
      "Epoch: 349/350 - train_loss: 0.3182 - test_loss: 0.367115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:59:14,423]\u001b[0m Trial 42 finished with value: 18.210847594443276 and parameters: {'n layers': 4, 'Hidden size': 152, 'Learning rate': 0.0011135224322392123, 'Dropout rate': 0.6467422547032732, 'Epochs': 350}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224/450 - train_loss: 0.3205 - test_loss: 0.374454\n",
      "Epoch: 328/330 - train_loss: 0.3174 - test_loss: 0.358780\n",
      "Epoch: 329/330 - train_loss: 0.3187 - test_loss: 0.367440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:59:35,432]\u001b[0m Trial 40 finished with value: 18.416585646997664 and parameters: {'n layers': 3, 'Hidden size': 366, 'Learning rate': 0.0013405055590961677, 'Dropout rate': 0.6472082202493936, 'Epochs': 350}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239/240 - train_loss: 0.3257 - test_loss: 0.378591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:59:41,184]\u001b[0m Trial 4 finished with value: 19.47057840095901 and parameters: {'n layers': 5, 'Hidden size': 13, 'Learning rate': 0.000588147281808291, 'Dropout rate': 0.2292830584890552, 'Epochs': 320}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/500 - train_loss: 0.3264 - test_loss: 0.390170\n",
      "Epoch: 174/350 - train_loss: 0.3257 - test_loss: 0.352459\n",
      "Epoch: 328/330 - train_loss: 0.3203 - test_loss: 0.317209\n",
      "Epoch: 120/240 - train_loss: 0.4293 - test_loss: 0.449290\n",
      "Epoch: 329/330 - train_loss: 0.3237 - test_loss: 0.345174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 00:59:59,476]\u001b[0m Trial 46 finished with value: 14.559629117912232 and parameters: {'n layers': 6, 'Hidden size': 10, 'Learning rate': 0.009854660400863456, 'Dropout rate': 0.4038912525944706, 'Epochs': 330}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120/240 - train_loss: 0.3348 - test_loss: 0.354320\n",
      "Epoch: 120/240 - train_loss: 0.5813 - test_loss: 0.601394\n",
      "Epoch: 120/240 - train_loss: 0.5658 - test_loss: 0.568678\n",
      "Epoch: 375/500 - train_loss: 0.3760 - test_loss: 0.363063\n",
      "Epoch: 180/240 - train_loss: 0.3613 - test_loss: 0.388162\n",
      "Epoch: 336/450 - train_loss: 0.3210 - test_loss: 0.332979\n",
      "Epoch: 180/240 - train_loss: 0.5386 - test_loss: 0.517037\n",
      "Epoch: 261/350 - train_loss: 0.3195 - test_loss: 0.378001\n",
      "Epoch: 180/240 - train_loss: 0.3854 - test_loss: 0.373481\n",
      "Epoch: 375/500 - train_loss: 0.3809 - test_loss: 0.377108\n",
      "Epoch: 120/240 - train_loss: 0.3378 - test_loss: 0.328228\n",
      "Epoch: 120/240 - train_loss: 0.3201 - test_loss: 0.377249\n",
      "Epoch: 239/240 - train_loss: 0.3464 - test_loss: 0.362763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:01:51,760]\u001b[0m Trial 2 finished with value: 20.574253550509855 and parameters: {'n layers': 3, 'Hidden size': 330, 'Learning rate': 0.00020162621087964423, 'Dropout rate': 0.45172479247318487, 'Epochs': 240}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180/240 - train_loss: 0.4883 - test_loss: 0.497182\n",
      "Epoch: 239/240 - train_loss: 0.4669 - test_loss: 0.447281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:01,462]\u001b[0m Trial 11 finished with value: 22.38222364131853 and parameters: {'n layers': 4, 'Hidden size': 86, 'Learning rate': 0.00011337150064458937, 'Dropout rate': 0.26285418368244595, 'Epochs': 420}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239/240 - train_loss: 0.3215 - test_loss: 0.325540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:13,747]\u001b[0m Trial 13 finished with value: 16.800858825528124 and parameters: {'n layers': 3, 'Hidden size': 9, 'Learning rate': 0.0009915253339384828, 'Dropout rate': 0.7094826466582755, 'Epochs': 180}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 348/350 - train_loss: 0.3152 - test_loss: 0.371698\n",
      "Epoch: 349/350 - train_loss: 0.3785 - test_loss: 0.379821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:21,042]\u001b[0m Trial 45 finished with value: 16.734142573985434 and parameters: {'n layers': 4, 'Hidden size': 11, 'Learning rate': 0.0012723544519394722, 'Dropout rate': 0.4037526385210281, 'Epochs': 350}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448/450 - train_loss: 0.3710 - test_loss: 0.329375\n",
      "Epoch: 449/450 - train_loss: 0.3282 - test_loss: 0.327180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:29,263]\u001b[0m Trial 49 finished with value: 14.018914041789785 and parameters: {'n layers': 6, 'Hidden size': 13, 'Learning rate': 0.006833161486604878, 'Dropout rate': 0.4108998543189142, 'Epochs': 450}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499/500 - train_loss: 0.3194 - test_loss: 0.352607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:34,137]\u001b[0m Trial 47 finished with value: 15.654919755583121 and parameters: {'n layers': 6, 'Hidden size': 11, 'Learning rate': 0.009738658729497408, 'Dropout rate': 0.42201925527354833, 'Epochs': 500}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120/240 - train_loss: 0.3219 - test_loss: 0.359100\n",
      "Epoch: 180/240 - train_loss: 0.3255 - test_loss: 0.378377\n",
      "Epoch: 239/240 - train_loss: 0.4168 - test_loss: 0.442105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:43,480]\u001b[0m Trial 9 finished with value: 21.52111216783761 and parameters: {'n layers': 5, 'Hidden size': 16, 'Learning rate': 0.00010795359021870093, 'Dropout rate': 0.4062630147521442, 'Epochs': 280}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180/240 - train_loss: 0.3234 - test_loss: 0.360557\n",
      "Epoch: 120/240 - train_loss: 0.3204 - test_loss: 0.392064\n",
      "Epoch: 120/240 - train_loss: 0.3222 - test_loss: 0.335747\n",
      "Epoch: 499/500 - train_loss: 0.3213 - test_loss: 0.403786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:02:58,635]\u001b[0m Trial 48 finished with value: 15.42248423910546 and parameters: {'n layers': 6, 'Hidden size': 12, 'Learning rate': 0.0075707682264632295, 'Dropout rate': 0.40727792015099756, 'Epochs': 500}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239/240 - train_loss: 0.3333 - test_loss: 0.385811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:03:06,348]\u001b[0m Trial 3 finished with value: 16.43287425589261 and parameters: {'n layers': 5, 'Hidden size': 235, 'Learning rate': 0.0014495231515685072, 'Dropout rate': 0.20954488192500942, 'Epochs': 350}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180/240 - train_loss: 0.3315 - test_loss: 0.377182\n",
      "Epoch: 239/240 - train_loss: 0.3178 - test_loss: 0.357878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:03:11,340]\u001b[0m Trial 19 finished with value: 16.54544350573773 and parameters: {'n layers': 5, 'Hidden size': 116, 'Learning rate': 0.0010309468805629483, 'Dropout rate': 0.42195876234085616, 'Epochs': 240}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180/240 - train_loss: 0.3280 - test_loss: 0.387664\n",
      "Epoch: 180/240 - train_loss: 0.3298 - test_loss: 0.382065\n",
      "Epoch: 239/240 - train_loss: 0.3395 - test_loss: 0.386020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:03:23,538]\u001b[0m Trial 15 finished with value: 14.027076853560757 and parameters: {'n layers': 6, 'Hidden size': 87, 'Learning rate': 0.007164038952590685, 'Dropout rate': 0.4290110039302964, 'Epochs': 160}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239/240 - train_loss: 0.3241 - test_loss: 0.382000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:03:28,336]\u001b[0m Trial 14 finished with value: 18.9369131228364 and parameters: {'n layers': 5, 'Hidden size': 60, 'Learning rate': 0.004753641390887928, 'Dropout rate': 0.12507110797003398, 'Epochs': 300}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239/240 - train_loss: 0.3220 - test_loss: 0.414648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:03:30,571]\u001b[0m Trial 0 finished with value: 14.613897919517703 and parameters: {'n layers': 3, 'Hidden size': 22, 'Learning rate': 0.007482768189538164, 'Dropout rate': 0.41205376724174847, 'Epochs': 150}. Best is trial 36 with value: 13.548062029201825.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 01:03:30,589]\u001b[0m A new study created in memory with name: no-name-8eb1dfa7-dbf1-4b19-b536-a716f7485a28\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Quảng Ninh\n",
      "  Value:  13.548062029201825\n",
      "optimize result of city: Quảng Ninh\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/430 - train_loss: 0.9325 - test_loss: 0.600907\n",
      "Epoch:  0/430 - train_loss: 1.0628 - test_loss: 0.757142\n",
      "Epoch:  0/430 - train_loss: 1.0812 - test_loss: 0.737964\n",
      "Epoch:  0/430 - train_loss: 1.0579 - test_loss: 0.817187\n",
      "Epoch:  0/430 - train_loss: 1.7310 - test_loss: 2.181586\n",
      "Epoch:  0/430 - train_loss: 1.0342 - test_loss: 0.778546\n",
      "Epoch:  0/430 - train_loss: 0.8119 - test_loss: 0.642815\n",
      "Epoch:  0/430 - train_loss: 0.8926 - test_loss: 0.585321\n",
      "Epoch:  0/430 - train_loss: 0.9234 - test_loss: 0.780561\n",
      "Epoch:  0/430 - train_loss: 0.9935 - test_loss: 0.698919\n",
      "Epoch:  0/430 - train_loss: 0.7062 - test_loss: 0.559516\n",
      "Epoch:  0/430 - train_loss: 1.0388 - test_loss: 0.696077\n",
      "Epoch:  0/430 - train_loss: 1.1017 - test_loss: 0.924846\n",
      "Epoch:  0/430 - train_loss: 1.7682 - test_loss: 2.203356\n",
      "Epoch:  0/430 - train_loss: 1.3749 - test_loss: 0.859105\n",
      "Epoch:  0/430 - train_loss: 1.2524 - test_loss: 0.714993\n",
      "Epoch:  0/430 - train_loss: 1.3775 - test_loss: 0.969930\n",
      "Epoch:  0/430 - train_loss: 1.8138 - test_loss: 1.948492\n",
      "Epoch:  0/430 - train_loss: 1.2013 - test_loss: 0.934100\n",
      "Epoch:  0/430 - train_loss: 1.4604 - test_loss: 1.457742\n",
      "Epoch: 107/430 - train_loss: 0.2072 - test_loss: 0.104235\n",
      "Epoch: 107/430 - train_loss: 0.2147 - test_loss: 0.110532\n",
      "Epoch: 107/430 - train_loss: 0.2446 - test_loss: 0.185478\n",
      "Epoch: 107/430 - train_loss: 0.2067 - test_loss: 0.110750\n",
      "Epoch: 107/430 - train_loss: 0.3194 - test_loss: 0.269973\n",
      "Epoch: 107/430 - train_loss: 0.2002 - test_loss: 0.114122\n",
      "Epoch: 107/430 - train_loss: 0.2003 - test_loss: 0.108754\n",
      "Epoch: 214/430 - train_loss: 0.2019 - test_loss: 0.106325\n",
      "Epoch: 214/430 - train_loss: 0.2126 - test_loss: 0.105451\n",
      "Epoch: 107/430 - train_loss: 0.2289 - test_loss: 0.113677\n",
      "Epoch: 214/430 - train_loss: 0.2036 - test_loss: 0.106126\n",
      "Epoch: 214/430 - train_loss: 0.1986 - test_loss: 0.099271\n",
      "Epoch: 214/430 - train_loss: 0.2081 - test_loss: 0.122476\n",
      "Epoch: 214/430 - train_loss: 0.2129 - test_loss: 0.096620\n",
      "Epoch: 321/430 - train_loss: 0.2081 - test_loss: 0.105393\n",
      "Epoch: 214/430 - train_loss: 0.2005 - test_loss: 0.100572\n",
      "Epoch: 321/430 - train_loss: 0.2896 - test_loss: 0.133485\n",
      "Epoch: 321/430 - train_loss: 0.2017 - test_loss: 0.112846\n",
      "Epoch: 321/430 - train_loss: 0.2031 - test_loss: 0.112106\n",
      "Epoch: 107/430 - train_loss: 0.2057 - test_loss: 0.105188\n",
      "Epoch: 321/430 - train_loss: 0.2138 - test_loss: 0.106026\n",
      "Epoch: 321/430 - train_loss: 0.1998 - test_loss: 0.106509\n",
      "Epoch: 214/430 - train_loss: 0.2149 - test_loss: 0.108733\n",
      "Epoch: 428/430 - train_loss: 0.2072 - test_loss: 0.103762\n",
      "Epoch: 429/430 - train_loss: 0.2626 - test_loss: 0.111943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:17:36,973]\u001b[0m Trial 3 finished with value: 12.75570352751364 and parameters: {'n layers': 4, 'Hidden size': 50, 'Learning rate': 0.009183761861358239, 'Dropout rate': 0.6815720927380268, 'Epochs': 420}. Best is trial 3 with value: 12.75570352751364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 428/430 - train_loss: 0.1991 - test_loss: 0.110265\n",
      "Epoch: 429/430 - train_loss: 0.1972 - test_loss: 0.109797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:17:50,998]\u001b[0m Trial 14 finished with value: 13.218117046852692 and parameters: {'n layers': 4, 'Hidden size': 81, 'Learning rate': 0.0018096754339444268, 'Dropout rate': 0.016271507815313675, 'Epochs': 450}. Best is trial 3 with value: 12.75570352751364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 428/430 - train_loss: 0.1994 - test_loss: 0.105232\n",
      "Epoch: 429/430 - train_loss: 0.1988 - test_loss: 0.108370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:18:13,197]\u001b[0m Trial 0 finished with value: 12.550559875857056 and parameters: {'n layers': 4, 'Hidden size': 22, 'Learning rate': 0.00042198491935078363, 'Dropout rate': 0.797407086803774, 'Epochs': 400}. Best is trial 0 with value: 12.550559875857056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/340 - train_loss: 1.1994 - test_loss: 0.888509\n",
      "Epoch: 428/430 - train_loss: 0.2000 - test_loss: 0.109565\n",
      "Epoch: 429/430 - train_loss: 0.2001 - test_loss: 0.103659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:18:47,753]\u001b[0m Trial 2 finished with value: 13.962805767444685 and parameters: {'n layers': 5, 'Hidden size': 231, 'Learning rate': 0.008603573913068947, 'Dropout rate': 0.27967583215371955, 'Epochs': 470}. Best is trial 0 with value: 12.550559875857056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 107/430 - train_loss: 0.2426 - test_loss: 0.110400\n",
      "Epoch: 321/430 - train_loss: 0.2019 - test_loss: 0.106184\n",
      "Epoch:  0/190 - train_loss: 1.3134 - test_loss: 1.601511\n",
      "Epoch:  0/190 - train_loss: 1.2960 - test_loss: 1.282195\n",
      "Epoch: 428/430 - train_loss: 0.2727 - test_loss: 0.104996\n",
      "Epoch: 429/430 - train_loss: 0.2192 - test_loss: 0.107970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:19:35,884]\u001b[0m Trial 12 finished with value: 14.044120612281624 and parameters: {'n layers': 3, 'Hidden size': 275, 'Learning rate': 0.0002963688876825631, 'Dropout rate': 0.53300190628523, 'Epochs': 320}. Best is trial 0 with value: 12.550559875857056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/380 - train_loss: 1.7036 - test_loss: 2.273305\n",
      "Epoch:  0/380 - train_loss: 0.9059 - test_loss: 0.586452\n",
      "Epoch: 47/190 - train_loss: 0.4760 - test_loss: 0.429321\n",
      "Epoch: 428/430 - train_loss: 0.2008 - test_loss: 0.102683\n",
      "Epoch: 429/430 - train_loss: 0.2099 - test_loss: 0.106293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:20:37,404]\u001b[0m Trial 17 finished with value: 14.320332878337902 and parameters: {'n layers': 4, 'Hidden size': 172, 'Learning rate': 0.008202954383485391, 'Dropout rate': 0.722007218669853, 'Epochs': 310}. Best is trial 0 with value: 12.550559875857056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 47/190 - train_loss: 0.7929 - test_loss: 0.592933\n",
      "Epoch: 214/430 - train_loss: 0.2023 - test_loss: 0.110751\n",
      "Epoch: 85/340 - train_loss: 0.2320 - test_loss: 0.147655\n",
      "Epoch: 321/430 - train_loss: 0.2014 - test_loss: 0.110661\n",
      "Epoch:  0/330 - train_loss: 1.7143 - test_loss: 1.640167\n",
      "Epoch: 94/190 - train_loss: 0.3232 - test_loss: 0.253790\n",
      "Epoch: 94/190 - train_loss: 0.5734 - test_loss: 0.502129\n",
      "Epoch: 428/430 - train_loss: 0.1994 - test_loss: 0.103487\n",
      "Epoch: 429/430 - train_loss: 0.2026 - test_loss: 0.105298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:21:59,610]\u001b[0m Trial 4 finished with value: 12.415048616551305 and parameters: {'n layers': 5, 'Hidden size': 65, 'Learning rate': 0.00910822946646893, 'Dropout rate': 0.45863799324062754, 'Epochs': 160}. Best is trial 4 with value: 12.415048616551305.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 95/380 - train_loss: 0.2129 - test_loss: 0.113031\n",
      "Epoch: 141/190 - train_loss: 0.2308 - test_loss: 0.162588\n",
      "Epoch: 95/380 - train_loss: 0.2632 - test_loss: 0.116560\n",
      "Epoch:  0/360 - train_loss: 1.0605 - test_loss: 0.889585\n",
      "Epoch: 141/190 - train_loss: 0.4931 - test_loss: 0.421824\n",
      "Epoch: 170/340 - train_loss: 0.2154 - test_loss: 0.108135\n",
      "Epoch: 82/330 - train_loss: 0.6261 - test_loss: 0.540239\n",
      "Epoch: 188/190 - train_loss: 0.2037 - test_loss: 0.121594\n",
      "Epoch: 189/190 - train_loss: 0.2017 - test_loss: 0.120601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:23:28,657]\u001b[0m Trial 21 finished with value: 15.392897964946528 and parameters: {'n layers': 5, 'Hidden size': 11, 'Learning rate': 0.00033578466248887175, 'Dropout rate': 0.5008860932245861, 'Epochs': 280}. Best is trial 4 with value: 12.415048616551305.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 188/190 - train_loss: 0.4123 - test_loss: 0.351577\n",
      "Epoch: 189/190 - train_loss: 0.4091 - test_loss: 0.350130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:23:51,613]\u001b[0m Trial 22 finished with value: 21.50140703085184 and parameters: {'n layers': 5, 'Hidden size': 56, 'Learning rate': 0.00011853894082256971, 'Dropout rate': 0.667446635696125, 'Epochs': 340}. Best is trial 4 with value: 12.415048616551305.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/260 - train_loss: 1.4456 - test_loss: 1.629413\n",
      "Epoch: 190/380 - train_loss: 0.2017 - test_loss: 0.109640\n",
      "Epoch: 214/430 - train_loss: 0.2001 - test_loss: 0.107389\n",
      "Epoch: 428/430 - train_loss: 0.2018 - test_loss: 0.103840\n",
      "Epoch: 429/430 - train_loss: 0.1997 - test_loss: 0.107615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:24:37,127]\u001b[0m Trial 7 finished with value: 11.681945046765046 and parameters: {'n layers': 6, 'Hidden size': 60, 'Learning rate': 0.00098351088616184, 'Dropout rate': 0.6148277484298985, 'Epochs': 250}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/180 - train_loss: 1.3969 - test_loss: 0.959057\n",
      "Epoch: 255/340 - train_loss: 0.1992 - test_loss: 0.108065\n",
      "Epoch: 321/430 - train_loss: 0.2116 - test_loss: 0.110334\n",
      "Epoch: 190/380 - train_loss: 0.2001 - test_loss: 0.111356\n",
      "Epoch: 107/430 - train_loss: 0.2627 - test_loss: 0.203456\n",
      "Epoch:  0/180 - train_loss: 1.0892 - test_loss: 0.801251\n",
      "Epoch: 90/360 - train_loss: 0.5374 - test_loss: 0.474043\n",
      "Epoch: 164/330 - train_loss: 0.4331 - test_loss: 0.371909\n",
      "Epoch: 45/180 - train_loss: 0.8988 - test_loss: 0.658630\n",
      "Epoch: 65/260 - train_loss: 0.4082 - test_loss: 0.359486\n",
      "Epoch: 285/380 - train_loss: 0.2005 - test_loss: 0.108094\n",
      "Epoch: 339/340 - train_loss: 0.2165 - test_loss: 0.108424\n",
      "Epoch: 90/180 - train_loss: 0.6763 - test_loss: 0.537361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:26:44,788]\u001b[0m Trial 20 finished with value: 14.08795844320671 and parameters: {'n layers': 4, 'Hidden size': 128, 'Learning rate': 0.0006076602752996505, 'Dropout rate': 0.4426115066774486, 'Epochs': 280}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 45/180 - train_loss: 0.2103 - test_loss: 0.123770\n",
      "Epoch: 130/260 - train_loss: 0.2540 - test_loss: 0.181589\n",
      "Epoch:  0/140 - train_loss: 1.3180 - test_loss: 1.179099\n",
      "Epoch: 285/380 - train_loss: 0.2167 - test_loss: 0.142524\n",
      "Epoch: 246/330 - train_loss: 0.3210 - test_loss: 0.257587\n",
      "Epoch: 135/180 - train_loss: 0.5206 - test_loss: 0.451789\n",
      "Epoch: 180/360 - train_loss: 0.3561 - test_loss: 0.310314\n",
      "Epoch: 35/140 - train_loss: 0.2052 - test_loss: 0.115335\n",
      "Epoch: 90/180 - train_loss: 0.2010 - test_loss: 0.110342\n",
      "Epoch: 195/260 - train_loss: 0.2024 - test_loss: 0.128788\n",
      "Epoch: 379/380 - train_loss: 0.2073 - test_loss: 0.108753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:28:26,038]\u001b[0m Trial 23 finished with value: 11.892929692384628 and parameters: {'n layers': 6, 'Hidden size': 41, 'Learning rate': 0.0007941740093575604, 'Dropout rate': 0.5934460138164162, 'Epochs': 190}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 179/180 - train_loss: 0.4499 - test_loss: 0.383250\n",
      "Epoch: 70/140 - train_loss: 0.1997 - test_loss: 0.102938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:28:32,356]\u001b[0m Trial 28 finished with value: 17.69609788669763 and parameters: {'n layers': 3, 'Hidden size': 9, 'Learning rate': 0.00010618768262928688, 'Dropout rate': 0.25181430924017545, 'Epochs': 260}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/170 - train_loss: 1.1113 - test_loss: 0.950622\n",
      "Epoch:  0/170 - train_loss: 1.2550 - test_loss: 1.343709\n",
      "Epoch: 379/380 - train_loss: 0.2019 - test_loss: 0.111585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:29:38,710]\u001b[0m Trial 24 finished with value: 15.079712997466823 and parameters: {'n layers': 5, 'Hidden size': 47, 'Learning rate': 0.009937936521591736, 'Dropout rate': 0.07997603572490647, 'Epochs': 380}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135/180 - train_loss: 0.2019 - test_loss: 0.111049\n",
      "lookback 3\n",
      "Epoch: 105/140 - train_loss: 0.2029 - test_loss: 0.108188\n",
      "Epoch: 328/330 - train_loss: 0.2525 - test_loss: 0.183229\n",
      "Epoch: 329/330 - train_loss: 0.2442 - test_loss: 0.182923\n",
      "Epoch: 428/430 - train_loss: 0.2016 - test_loss: 0.106977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:29:47,755]\u001b[0m Trial 25 finished with value: 19.88165788609994 and parameters: {'n layers': 4, 'Hidden size': 27, 'Learning rate': 0.00012849641700170088, 'Dropout rate': 0.11804007995760082, 'Epochs': 330}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 429/430 - train_loss: 0.1986 - test_loss: 0.100474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:29:52,190]\u001b[0m Trial 15 finished with value: 13.600084355942831 and parameters: {'n layers': 4, 'Hidden size': 53, 'Learning rate': 0.0027066894158851865, 'Dropout rate': 0.6035160955980553, 'Epochs': 100}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 259/260 - train_loss: 0.2021 - test_loss: 0.113110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:30:33,092]\u001b[0m Trial 27 finished with value: 14.496663968968656 and parameters: {'n layers': 4, 'Hidden size': 22, 'Learning rate': 0.00032624013906435936, 'Dropout rate': 0.48678573862080293, 'Epochs': 140}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 270/360 - train_loss: 0.2618 - test_loss: 0.200296\n",
      "Epoch: 321/430 - train_loss: 0.1989 - test_loss: 0.107277\n",
      "Epoch: 139/140 - train_loss: 0.2257 - test_loss: 0.105300\n",
      "Epoch:  0/230 - train_loss: 1.1736 - test_loss: 0.826912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:31:07,783]\u001b[0m Trial 30 finished with value: 12.2167875012402 and parameters: {'n layers': 6, 'Hidden size': 16, 'Learning rate': 0.002087702953354698, 'Dropout rate': 0.2876689945655696, 'Epochs': 140}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 42/170 - train_loss: 0.2083 - test_loss: 0.104482\n",
      "Epoch: 42/170 - train_loss: 0.2289 - test_loss: 0.115846\n",
      "Epoch:  0/220 - train_loss: 0.9888 - test_loss: 0.760926\n",
      "Epoch:  0/220 - train_loss: 1.1956 - test_loss: 0.782550\n",
      "Epoch: 179/180 - train_loss: 0.2156 - test_loss: 0.122441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:31:42,150]\u001b[0m Trial 29 finished with value: 12.125279088392366 and parameters: {'n layers': 6, 'Hidden size': 6, 'Learning rate': 0.0025180182317064564, 'Dropout rate': 0.25418457243475123, 'Epochs': 180}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/230 - train_loss: 1.1483 - test_loss: 0.814911\n",
      "Epoch: 107/430 - train_loss: 0.2011 - test_loss: 0.101942\n",
      "Epoch:  0/230 - train_loss: 1.2806 - test_loss: 0.911628\n",
      "Epoch: 84/170 - train_loss: 0.2080 - test_loss: 0.105347\n",
      "Epoch:  0/230 - train_loss: 1.0629 - test_loss: 0.991486\n",
      "Epoch: 84/170 - train_loss: 0.2006 - test_loss: 0.114584\n",
      "Epoch: 57/230 - train_loss: 0.2025 - test_loss: 0.105492\n",
      "Epoch: 55/220 - train_loss: 0.2061 - test_loss: 0.106063\n",
      "Epoch: 57/230 - train_loss: 0.2084 - test_loss: 0.126226\n",
      "Epoch: 126/170 - train_loss: 0.1993 - test_loss: 0.110418\n",
      "Epoch: 57/230 - train_loss: 0.2217 - test_loss: 0.138060\n",
      "Epoch: 126/170 - train_loss: 0.2284 - test_loss: 0.110749\n",
      "Epoch: 359/360 - train_loss: 0.2132 - test_loss: 0.138611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:33:33,095]\u001b[0m Trial 26 finished with value: 16.423130134876597 and parameters: {'n layers': 3, 'Hidden size': 76, 'Learning rate': 0.0001472581639124102, 'Dropout rate': 0.4785623503517288, 'Epochs': 360}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 55/220 - train_loss: 0.2018 - test_loss: 0.124607\n",
      "Epoch: 114/230 - train_loss: 0.1999 - test_loss: 0.110358\n",
      "Epoch:  0/220 - train_loss: 1.2793 - test_loss: 0.903532\n",
      "Epoch: 168/170 - train_loss: 0.2032 - test_loss: 0.110758\n",
      "Epoch: 169/170 - train_loss: 0.2017 - test_loss: 0.105053\n",
      "Epoch: 110/220 - train_loss: 0.2122 - test_loss: 0.103890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:34:23,484]\u001b[0m Trial 31 finished with value: 11.887464495488642 and parameters: {'n layers': 6, 'Hidden size': 19, 'Learning rate': 0.0018349203766290733, 'Dropout rate': 0.3204204655233488, 'Epochs': 170}. Best is trial 7 with value: 11.681945046765046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 214/430 - train_loss: 0.2069 - test_loss: 0.104859\n",
      "Epoch: 57/230 - train_loss: 0.2314 - test_loss: 0.161783\n",
      "Epoch: 168/170 - train_loss: 0.2153 - test_loss: 0.113257\n",
      "Epoch: 169/170 - train_loss: 0.2069 - test_loss: 0.116300\n",
      "Epoch: 114/230 - train_loss: 0.2003 - test_loss: 0.107845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:34:35,347]\u001b[0m Trial 32 finished with value: 11.576500365134045 and parameters: {'n layers': 6, 'Hidden size': 25, 'Learning rate': 0.001775024367457914, 'Dropout rate': 0.5929619274048638, 'Epochs': 170}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 114/230 - train_loss: 0.2098 - test_loss: 0.104501\n",
      "Epoch:  0/230 - train_loss: 1.0443 - test_loss: 0.721524\n",
      "Epoch:  0/230 - train_loss: 1.0367 - test_loss: 0.859053\n",
      "Epoch: 171/230 - train_loss: 0.1990 - test_loss: 0.102413\n",
      "Epoch: 55/220 - train_loss: 0.2243 - test_loss: 0.125521\n",
      "Epoch: 165/220 - train_loss: 0.2024 - test_loss: 0.113742\n",
      "Epoch: 171/230 - train_loss: 0.2003 - test_loss: 0.105575\n",
      "Epoch: 171/230 - train_loss: 0.2015 - test_loss: 0.102094\n",
      "Epoch: 110/220 - train_loss: 0.2046 - test_loss: 0.122346\n",
      "Epoch: 57/230 - train_loss: 0.2219 - test_loss: 0.132138\n",
      "Epoch: 114/230 - train_loss: 0.2079 - test_loss: 0.110221\n",
      "Epoch: 57/230 - train_loss: 0.2050 - test_loss: 0.108046\n",
      "Epoch: 107/430 - train_loss: 0.4752 - test_loss: 0.413942\n",
      "Epoch: 228/230 - train_loss: 0.2086 - test_loss: 0.111846\n",
      "Epoch: 229/230 - train_loss: 0.1987 - test_loss: 0.106429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:36:46,189]\u001b[0m Trial 33 finished with value: 12.003499189054608 and parameters: {'n layers': 6, 'Hidden size': 20, 'Learning rate': 0.001797212014495788, 'Dropout rate': 0.5871946094649536, 'Epochs': 190}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 228/230 - train_loss: 0.2239 - test_loss: 0.107166\n",
      "Epoch: 229/230 - train_loss: 0.2030 - test_loss: 0.113690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:36:59,400]\u001b[0m Trial 36 finished with value: 14.23439348595997 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.0010813030739980516, 'Dropout rate': 0.34061315128902764, 'Epochs': 230}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 219/220 - train_loss: 0.2006 - test_loss: 0.108626\n",
      "Epoch: 428/430 - train_loss: 0.2008 - test_loss: 0.106207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:37:07,939]\u001b[0m Trial 34 finished with value: 12.168536501985946 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.0018332199021918218, 'Dropout rate': 0.5472011108401125, 'Epochs': 180}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 429/430 - train_loss: 0.2038 - test_loss: 0.103556\n",
      "Epoch: 228/230 - train_loss: 0.2008 - test_loss: 0.110489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:37:13,425]\u001b[0m Trial 9 finished with value: 14.60600859062294 and parameters: {'n layers': 3, 'Hidden size': 57, 'Learning rate': 0.0009245735650292622, 'Dropout rate': 0.6792813460879881, 'Epochs': 330}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 229/230 - train_loss: 0.2218 - test_loss: 0.107664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:37:19,472]\u001b[0m Trial 37 finished with value: 13.698519157220366 and parameters: {'n layers': 6, 'Hidden size': 105, 'Learning rate': 0.0010213393081883984, 'Dropout rate': 0.5849471112459499, 'Epochs': 220}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 110/220 - train_loss: 0.2151 - test_loss: 0.104475\n",
      "Epoch: 114/230 - train_loss: 0.2055 - test_loss: 0.102981\n",
      "Epoch:  0/100 - train_loss: 0.8849 - test_loss: 0.638028\n",
      "Epoch: 114/230 - train_loss: 0.1992 - test_loss: 0.109318\n",
      "Epoch:  0/100 - train_loss: 1.0610 - test_loss: 0.744874\n",
      "Epoch:  0/100 - train_loss: 1.0064 - test_loss: 0.650057\n",
      "Epoch: 171/230 - train_loss: 0.1994 - test_loss: 0.106686\n",
      "Epoch: 165/220 - train_loss: 0.2097 - test_loss: 0.114760\n",
      "Epoch:  0/100 - train_loss: 0.8747 - test_loss: 0.642022\n",
      "Epoch:  0/100 - train_loss: 0.9038 - test_loss: 0.707380\n",
      "Epoch: 25/100 - train_loss: 0.2127 - test_loss: 0.127719\n",
      "Epoch: 25/100 - train_loss: 0.2835 - test_loss: 0.098400\n",
      "Epoch: 25/100 - train_loss: 0.2182 - test_loss: 0.116196\n",
      "Epoch: 25/100 - train_loss: 0.2147 - test_loss: 0.098663\n",
      "Epoch: 165/220 - train_loss: 0.1995 - test_loss: 0.105559\n",
      "Epoch: 50/100 - train_loss: 0.2088 - test_loss: 0.119249\n",
      "Epoch: 171/230 - train_loss: 0.2012 - test_loss: 0.106003\n",
      "Epoch: 50/100 - train_loss: 0.2022 - test_loss: 0.104911\n",
      "Epoch: 171/230 - train_loss: 0.1995 - test_loss: 0.104459\n",
      "Epoch: 50/100 - train_loss: 0.2165 - test_loss: 0.114317\n",
      "Epoch: 50/100 - train_loss: 0.2000 - test_loss: 0.107986\n",
      "Epoch: 75/100 - train_loss: 0.1993 - test_loss: 0.112194\n",
      "Epoch: 75/100 - train_loss: 0.2160 - test_loss: 0.111362\n",
      "Epoch: 75/100 - train_loss: 0.2034 - test_loss: 0.114366\n",
      "Epoch: 75/100 - train_loss: 0.2049 - test_loss: 0.106862\n",
      "Epoch: 99/100 - train_loss: 0.2114 - test_loss: 0.108955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:40:22,897]\u001b[0m Trial 42 finished with value: 15.631030871044118 and parameters: {'n layers': 6, 'Hidden size': 33, 'Learning rate': 0.003882039305549773, 'Dropout rate': 0.37884273336501284, 'Epochs': 220}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 99/100 - train_loss: 0.2100 - test_loss: 0.115749\n",
      "Epoch: 228/230 - train_loss: 0.2038 - test_loss: 0.112755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:40:29,526]\u001b[0m Trial 43 finished with value: 11.993227161647491 and parameters: {'n layers': 6, 'Hidden size': 13, 'Learning rate': 0.004293535347170201, 'Dropout rate': 0.39009924933679163, 'Epochs': 220}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 229/230 - train_loss: 0.1989 - test_loss: 0.104178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:40:34,149]\u001b[0m Trial 40 finished with value: 13.82424314064601 and parameters: {'n layers': 6, 'Hidden size': 32, 'Learning rate': 0.0010576025660951197, 'Dropout rate': 0.6024710999708192, 'Epochs': 230}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 228/230 - train_loss: 0.1993 - test_loss: 0.104612\n",
      "lookback 3\n",
      "Epoch: 229/230 - train_loss: 0.2025 - test_loss: 0.107005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:40:39,728]\u001b[0m Trial 38 finished with value: 12.49145746600397 and parameters: {'n layers': 6, 'Hidden size': 99, 'Learning rate': 0.000840361138244277, 'Dropout rate': 0.5916373476803234, 'Epochs': 230}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 - train_loss: 0.2012 - test_loss: 0.110884\n",
      "Epoch: 25/100 - train_loss: 0.2221 - test_loss: 0.105058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:40:49,189]\u001b[0m Trial 46 finished with value: 16.084717029609163 and parameters: {'n layers': 6, 'Hidden size': 34, 'Learning rate': 0.003697866118081424, 'Dropout rate': 0.3359132739828187, 'Epochs': 100}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219/220 - train_loss: 0.1994 - test_loss: 0.105382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:40:52,264]\u001b[0m Trial 39 finished with value: 13.315404157319042 and parameters: {'n layers': 6, 'Hidden size': 371, 'Learning rate': 0.001149098032478587, 'Dropout rate': 0.5923272090767165, 'Epochs': 220}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 228/230 - train_loss: 0.2008 - test_loss: 0.110860\n",
      "Epoch: 229/230 - train_loss: 0.1975 - test_loss: 0.105966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:41:06,585]\u001b[0m Trial 41 finished with value: 12.741101151245973 and parameters: {'n layers': 6, 'Hidden size': 13, 'Learning rate': 0.0013612631043974672, 'Dropout rate': 0.36247821097144445, 'Epochs': 230}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 - train_loss: 0.2005 - test_loss: 0.101249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:41:17,435]\u001b[0m Trial 44 finished with value: 12.782250532663715 and parameters: {'n layers': 6, 'Hidden size': 33, 'Learning rate': 0.003981068404731748, 'Dropout rate': 0.3838867034570841, 'Epochs': 230}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219/220 - train_loss: 0.2022 - test_loss: 0.101940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:41:24,900]\u001b[0m Trial 35 finished with value: 13.010165506728962 and parameters: {'n layers': 6, 'Hidden size': 20, 'Learning rate': 0.0012391381679853592, 'Dropout rate': 0.34093101308154616, 'Epochs': 210}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/100 - train_loss: 0.7965 - test_loss: 0.628429\n",
      "Epoch: 50/100 - train_loss: 0.2042 - test_loss: 0.111433\n",
      "Epoch: 107/430 - train_loss: 0.2031 - test_loss: 0.104514\n",
      "Epoch:  0/100 - train_loss: 1.2752 - test_loss: 0.877520\n",
      "Epoch:  0/100 - train_loss: 1.3333 - test_loss: 0.825437\n",
      "Epoch: 321/430 - train_loss: 0.1990 - test_loss: 0.109577\n",
      "Epoch: 214/430 - train_loss: 0.2603 - test_loss: 0.105865\n",
      "Epoch: 25/100 - train_loss: 0.2133 - test_loss: 0.108751\n",
      "Epoch: 75/100 - train_loss: 0.2238 - test_loss: 0.113102\n",
      "Epoch: 25/100 - train_loss: 0.2945 - test_loss: 0.212870\n",
      "Epoch: 25/100 - train_loss: 0.5325 - test_loss: 0.454786\n",
      "Epoch: 50/100 - train_loss: 0.2236 - test_loss: 0.115141\n",
      "Epoch: 99/100 - train_loss: 0.2044 - test_loss: 0.119640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:42:42,637]\u001b[0m Trial 45 finished with value: 11.637820764522411 and parameters: {'n layers': 6, 'Hidden size': 32, 'Learning rate': 0.0043933671604979, 'Dropout rate': 0.3875170528996404, 'Epochs': 230}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100 - train_loss: 0.2159 - test_loss: 0.113403\n",
      "Epoch: 50/100 - train_loss: 0.3479 - test_loss: 0.287228\n",
      "Epoch: 214/430 - train_loss: 0.2992 - test_loss: 0.230767\n",
      "Epoch: 75/100 - train_loss: 0.2606 - test_loss: 0.122006\n",
      "Epoch: 75/100 - train_loss: 0.2154 - test_loss: 0.106121\n",
      "Epoch: 75/100 - train_loss: 0.2587 - test_loss: 0.187019\n",
      "Epoch: 107/430 - train_loss: 0.5660 - test_loss: 0.498825\n",
      "Epoch: 99/100 - train_loss: 0.2069 - test_loss: 0.111686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:27,262]\u001b[0m Trial 47 finished with value: 13.372806289865409 and parameters: {'n layers': 5, 'Hidden size': 13, 'Learning rate': 0.004972401744125126, 'Dropout rate': 0.17503893398129378, 'Epochs': 100}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 - train_loss: 0.2069 - test_loss: 0.104555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:29,680]\u001b[0m Trial 48 finished with value: 11.657361064786619 and parameters: {'n layers': 5, 'Hidden size': 32, 'Learning rate': 0.0014388359432647984, 'Dropout rate': 0.7983510520689157, 'Epochs': 120}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 - train_loss: 0.2291 - test_loss: 0.137090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:32,632]\u001b[0m Trial 49 finished with value: 15.08547848208527 and parameters: {'n layers': 5, 'Hidden size': 8, 'Learning rate': 0.0005504837556937195, 'Dropout rate': 0.7986525365854663, 'Epochs': 100}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428/430 - train_loss: 0.1993 - test_loss: 0.113408\n",
      "Epoch: 429/430 - train_loss: 0.1992 - test_loss: 0.111018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:43:47,089]\u001b[0m Trial 6 finished with value: 13.099539711568829 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.000362778941792709, 'Dropout rate': 0.7486138494240855, 'Epochs': 120}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.1982 - test_loss: 0.101721\n",
      "Epoch: 214/430 - train_loss: 0.2128 - test_loss: 0.104842\n",
      "Epoch: 107/430 - train_loss: 0.2030 - test_loss: 0.105815\n",
      "Epoch: 321/430 - train_loss: 0.2165 - test_loss: 0.139980\n",
      "Epoch: 107/430 - train_loss: 0.2008 - test_loss: 0.107502\n",
      "Epoch: 214/430 - train_loss: 0.3973 - test_loss: 0.342239\n",
      "Epoch: 107/430 - train_loss: 0.2149 - test_loss: 0.121351\n",
      "Epoch: 428/430 - train_loss: 0.2013 - test_loss: 0.108131\n",
      "Epoch: 429/430 - train_loss: 0.1988 - test_loss: 0.102231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:45:30,767]\u001b[0m Trial 10 finished with value: 13.631741553497308 and parameters: {'n layers': 6, 'Hidden size': 351, 'Learning rate': 0.008146776002533182, 'Dropout rate': 0.5025473108752152, 'Epochs': 480}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.2172 - test_loss: 0.129258\n",
      "Epoch: 107/430 - train_loss: 0.4911 - test_loss: 0.439351\n",
      "Epoch: 214/430 - train_loss: 0.1982 - test_loss: 0.106983\n",
      "Epoch: 428/430 - train_loss: 0.2631 - test_loss: 0.113172\n",
      "Epoch: 429/430 - train_loss: 0.2089 - test_loss: 0.114090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:46:08,140]\u001b[0m Trial 16 finished with value: 15.803287871929998 and parameters: {'n layers': 6, 'Hidden size': 340, 'Learning rate': 0.00016711413806010276, 'Dropout rate': 0.674793147849887, 'Epochs': 430}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214/430 - train_loss: 0.2095 - test_loss: 0.103656\n",
      "Epoch: 321/430 - train_loss: 0.2917 - test_loss: 0.230539\n",
      "Epoch: 107/430 - train_loss: 0.4584 - test_loss: 0.404073\n",
      "Epoch: 428/430 - train_loss: 0.2022 - test_loss: 0.103122\n",
      "Epoch: 429/430 - train_loss: 0.1981 - test_loss: 0.105033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:47:07,823]\u001b[0m Trial 11 finished with value: 14.902365978058825 and parameters: {'n layers': 6, 'Hidden size': 148, 'Learning rate': 0.008526587332104615, 'Dropout rate': 0.4855570490489962, 'Epochs': 420}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214/430 - train_loss: 0.2012 - test_loss: 0.109964\n",
      "Epoch: 321/430 - train_loss: 0.2181 - test_loss: 0.105579\n",
      "Epoch: 214/430 - train_loss: 0.3203 - test_loss: 0.269595\n",
      "Epoch: 321/430 - train_loss: 0.2070 - test_loss: 0.104693\n",
      "Epoch: 428/430 - train_loss: 0.2461 - test_loss: 0.156752\n",
      "Epoch: 429/430 - train_loss: 0.2463 - test_loss: 0.157034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:47:58,124]\u001b[0m Trial 13 finished with value: 16.659925524306615 and parameters: {'n layers': 3, 'Hidden size': 78, 'Learning rate': 0.00010970372729199715, 'Dropout rate': 0.11185371412543788, 'Epochs': 310}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.2653 - test_loss: 0.107888\n",
      "Epoch: 428/430 - train_loss: 0.1978 - test_loss: 0.100616\n",
      "Epoch: 429/430 - train_loss: 0.1998 - test_loss: 0.102557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:48:34,437]\u001b[0m Trial 8 finished with value: 13.43944754067497 and parameters: {'n layers': 5, 'Hidden size': 79, 'Learning rate': 0.000801386709318863, 'Dropout rate': 0.5327497048647553, 'Epochs': 320}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214/430 - train_loss: 0.2802 - test_loss: 0.223969\n",
      "Epoch: 321/430 - train_loss: 0.2520 - test_loss: 0.164866\n",
      "Epoch: 428/430 - train_loss: 0.2042 - test_loss: 0.104057\n",
      "Epoch: 429/430 - train_loss: 0.1981 - test_loss: 0.101925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:48:53,235]\u001b[0m Trial 18 finished with value: 13.126853613384545 and parameters: {'n layers': 3, 'Hidden size': 17, 'Learning rate': 0.0016705300942156257, 'Dropout rate': 0.42543442623924604, 'Epochs': 410}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428/430 - train_loss: 0.2000 - test_loss: 0.105119\n",
      "Epoch: 429/430 - train_loss: 0.1992 - test_loss: 0.104207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:49:14,223]\u001b[0m Trial 1 finished with value: 13.976855660054111 and parameters: {'n layers': 5, 'Hidden size': 289, 'Learning rate': 0.006832810119630063, 'Dropout rate': 0.6493399742322924, 'Epochs': 480}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.2246 - test_loss: 0.137616\n",
      "Epoch: 428/430 - train_loss: 0.2137 - test_loss: 0.121435\n",
      "Epoch: 429/430 - train_loss: 0.2080 - test_loss: 0.122107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:49:28,263]\u001b[0m Trial 19 finished with value: 13.829562304735399 and parameters: {'n layers': 3, 'Hidden size': 60, 'Learning rate': 0.0001428727273097696, 'Dropout rate': 0.22539565233041733, 'Epochs': 430}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428/430 - train_loss: 0.2085 - test_loss: 0.111673\n",
      "Epoch: 429/430 - train_loss: 0.2562 - test_loss: 0.112919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 01:49:45,681]\u001b[0m Trial 5 finished with value: 15.318204105813303 and parameters: {'n layers': 3, 'Hidden size': 24, 'Learning rate': 0.00016533124682011974, 'Dropout rate': 0.27603828043803896, 'Epochs': 470}. Best is trial 32 with value: 11.576500365134045.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 01:49:45,698]\u001b[0m A new study created in memory with name: no-name-457e045b-b429-482e-8a92-8894f0ca5bfd\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Quảng Trị\n",
      "  Value:  11.576500365134045\n",
      "optimize result of city: Quảng Trị\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "Epoch:  0/430 - train_loss: 2.2231 - test_loss: 2.291605\n",
      "Epoch:  0/430 - train_loss: 1.6658 - test_loss: 1.070759\n",
      "Epoch:  0/430 - train_loss: 1.1293 - test_loss: 0.793279\n",
      "Epoch:  0/430 - train_loss: 1.3071 - test_loss: 0.758527\n",
      "Epoch:  0/430 - train_loss: 0.9414 - test_loss: 0.786108\n",
      "Epoch:  0/430 - train_loss: 1.1401 - test_loss: 0.807574\n",
      "Epoch:  0/430 - train_loss: 0.8612 - test_loss: 0.679074\n",
      "Epoch:  0/430 - train_loss: 1.1984 - test_loss: 0.777840\n",
      "Epoch:  0/430 - train_loss: 1.0517 - test_loss: 0.713425\n",
      "Epoch:  0/430 - train_loss: 1.5353 - test_loss: 1.129002\n",
      "Epoch:  0/430 - train_loss: 1.1610 - test_loss: 0.935708\n",
      "Epoch:  0/430 - train_loss: 1.1500 - test_loss: 0.754561Epoch:  0/430 - train_loss: 1.1887 - test_loss: 0.743524\n",
      "Epoch:  0/430 - train_loss: 1.2778 - test_loss: 0.999452\n",
      "\n",
      "Epoch:  0/430 - train_loss: 1.3324 - test_loss: 0.870734\n",
      "Epoch:  0/430 - train_loss: 1.2635 - test_loss: 1.132723\n",
      "Epoch:  0/430 - train_loss: 0.8434 - test_loss: 0.699142\n",
      "Epoch:  0/430 - train_loss: 1.4265 - test_loss: 0.813425\n",
      "Epoch:  0/430 - train_loss: 1.6439 - test_loss: 0.812925\n",
      "Epoch:  0/430 - train_loss: 1.1798 - test_loss: 0.729008\n",
      "Epoch: 107/430 - train_loss: 0.7251 - test_loss: 0.701894\n",
      "Epoch: 107/430 - train_loss: 0.5511 - test_loss: 0.607894\n",
      "Epoch: 107/430 - train_loss: 0.3136 - test_loss: 0.408974\n",
      "Epoch: 107/430 - train_loss: 0.3552 - test_loss: 0.342124\n",
      "Epoch: 107/430 - train_loss: 0.3477 - test_loss: 0.493235\n",
      "Epoch: 107/430 - train_loss: 0.3162 - test_loss: 0.394306\n",
      "Epoch: 107/430 - train_loss: 0.3147 - test_loss: 0.373153\n",
      "Epoch: 214/430 - train_loss: 0.5007 - test_loss: 0.521542\n",
      "Epoch: 214/430 - train_loss: 0.3667 - test_loss: 0.422919\n",
      "Epoch: 214/430 - train_loss: 0.3104 - test_loss: 0.379034\n",
      "Epoch: 214/430 - train_loss: 0.3179 - test_loss: 0.396975\n",
      "Epoch: 107/430 - train_loss: 0.4302 - test_loss: 0.440938\n",
      "Epoch: 214/430 - train_loss: 0.3165 - test_loss: 0.366675\n",
      "Epoch: 214/430 - train_loss: 0.3243 - test_loss: 0.372885\n",
      "Epoch: 214/430 - train_loss: 0.3157 - test_loss: 0.381282\n",
      "Epoch: 321/430 - train_loss: 0.4140 - test_loss: 0.434709\n",
      "Epoch: 321/430 - train_loss: 0.3267 - test_loss: 0.389122\n",
      "Epoch: 107/430 - train_loss: 0.4117 - test_loss: 0.380166\n",
      "Epoch: 321/430 - train_loss: 0.3177 - test_loss: 0.359703\n",
      "Epoch: 321/430 - train_loss: 0.3295 - test_loss: 0.442796\n",
      "Epoch: 321/430 - train_loss: 0.3264 - test_loss: 0.404005\n",
      "Epoch: 321/430 - train_loss: 0.3168 - test_loss: 0.384673\n",
      "Epoch: 428/430 - train_loss: 0.3447 - test_loss: 0.374081\n",
      "Epoch: 429/430 - train_loss: 0.3382 - test_loss: 0.375748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:03:25,519]\u001b[0m Trial 4 finished with value: 62.84330673526824 and parameters: {'n layers': 5, 'Hidden size': 22, 'Learning rate': 0.00010256296025284948, 'Dropout rate': 0.1526194004764192, 'Epochs': 160}. Best is trial 4 with value: 62.84330673526824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 214/430 - train_loss: 0.3201 - test_loss: 0.383617\n",
      "Epoch: 428/430 - train_loss: 0.3232 - test_loss: 0.402513\n",
      "Epoch: 429/430 - train_loss: 0.3240 - test_loss: 0.400879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:03:36,656]\u001b[0m Trial 18 finished with value: 61.59795312930091 and parameters: {'n layers': 3, 'Hidden size': 44, 'Learning rate': 0.0001557502971592396, 'Dropout rate': 0.7470236819646585, 'Epochs': 250}. Best is trial 18 with value: 61.59795312930091.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 428/430 - train_loss: 0.3110 - test_loss: 0.367032\n",
      "Epoch: 429/430 - train_loss: 0.3500 - test_loss: 0.377419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:03:53,225]\u001b[0m Trial 15 finished with value: 55.299915537504454 and parameters: {'n layers': 4, 'Hidden size': 163, 'Learning rate': 0.001126667196742504, 'Dropout rate': 0.318495598338337, 'Epochs': 460}. Best is trial 15 with value: 55.299915537504454.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 321/430 - train_loss: 0.3210 - test_loss: 0.400175\n",
      "Epoch: 428/430 - train_loss: 0.3582 - test_loss: 0.375284\n",
      "Epoch: 429/430 - train_loss: 0.3171 - test_loss: 0.301970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:04:32,764]\u001b[0m Trial 14 finished with value: 54.946520116684745 and parameters: {'n layers': 6, 'Hidden size': 96, 'Learning rate': 0.0027707415375923176, 'Dropout rate': 0.7744755958658742, 'Epochs': 270}. Best is trial 14 with value: 54.946520116684745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/220 - train_loss: 1.1093 - test_loss: 0.739175\n",
      "Epoch:  0/410 - train_loss: 1.2658 - test_loss: 0.830880\n",
      "Epoch: 428/430 - train_loss: 0.3154 - test_loss: 0.368656\n",
      "Epoch: 429/430 - train_loss: 0.3821 - test_loss: 0.367074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:05:16,691]\u001b[0m Trial 9 finished with value: 49.236604099578294 and parameters: {'n layers': 4, 'Hidden size': 24, 'Learning rate': 0.008764498860235207, 'Dropout rate': 0.5283186625538, 'Epochs': 250}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/410 - train_loss: 1.1592 - test_loss: 0.780834\n",
      "lookback 3\n",
      "Epoch:  0/220 - train_loss: 1.9270 - test_loss: 1.154610\n",
      "Epoch: 428/430 - train_loss: 0.3163 - test_loss: 0.391442\n",
      "Epoch: 429/430 - train_loss: 0.3340 - test_loss: 0.385464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:06:12,421]\u001b[0m Trial 12 finished with value: 49.54080825090639 and parameters: {'n layers': 4, 'Hidden size': 274, 'Learning rate': 0.008742013504312163, 'Dropout rate': 0.7016422755455228, 'Epochs': 370}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/400 - train_loss: 1.5511 - test_loss: 1.315583\n",
      "Epoch: 214/430 - train_loss: 0.3672 - test_loss: 0.341797\n",
      "Epoch: 55/220 - train_loss: 0.3361 - test_loss: 0.334746\n",
      "Epoch: 107/430 - train_loss: 0.3137 - test_loss: 0.425457\n",
      "Epoch:  0/400 - train_loss: 1.3385 - test_loss: 1.029454\n",
      "Epoch: 55/220 - train_loss: 0.7305 - test_loss: 0.659466\n",
      "Epoch: 321/430 - train_loss: 0.3435 - test_loss: 0.377483\n",
      "Epoch: 110/220 - train_loss: 0.3182 - test_loss: 0.370315\n",
      "Epoch: 428/430 - train_loss: 0.3101 - test_loss: 0.382458\n",
      "Epoch: 102/410 - train_loss: 0.3144 - test_loss: 0.413066\n",
      "Epoch: 429/430 - train_loss: 0.3091 - test_loss: 0.354092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:07:26,192]\u001b[0m Trial 17 finished with value: 49.723757900854345 and parameters: {'n layers': 4, 'Hidden size': 37, 'Learning rate': 0.0022622533273327365, 'Dropout rate': 0.42047691638717005, 'Epochs': 120}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 102/410 - train_loss: 0.3185 - test_loss: 0.427514\n",
      "Epoch:  0/380 - train_loss: 1.0611 - test_loss: 0.742092\n",
      "Epoch: 110/220 - train_loss: 0.5697 - test_loss: 0.568919\n",
      "Epoch: 100/400 - train_loss: 0.3185 - test_loss: 0.409621\n",
      "Epoch: 165/220 - train_loss: 0.3192 - test_loss: 0.409213\n",
      "Epoch: 100/400 - train_loss: 0.3310 - test_loss: 0.392048\n",
      "Epoch: 165/220 - train_loss: 0.4929 - test_loss: 0.489116\n",
      "Epoch: 204/410 - train_loss: 0.3253 - test_loss: 0.433207\n",
      "Epoch: 219/220 - train_loss: 0.3192 - test_loss: 0.329858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:09:28,173]\u001b[0m Trial 20 finished with value: 55.25676028118934 and parameters: {'n layers': 6, 'Hidden size': 60, 'Learning rate': 0.003523559694801827, 'Dropout rate': 0.44177975311493156, 'Epochs': 320}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 204/410 - train_loss: 0.3149 - test_loss: 0.386370\n",
      "Epoch:  0/150 - train_loss: 1.5130 - test_loss: 0.843065\n",
      "Epoch: 428/430 - train_loss: 0.3406 - test_loss: 0.373279\n",
      "Epoch: 429/430 - train_loss: 0.3106 - test_loss: 0.379840\n",
      "Epoch: 219/220 - train_loss: 0.4173 - test_loss: 0.434676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:10:34,682]\u001b[0m Trial 11 finished with value: 59.03475149311783 and parameters: {'n layers': 3, 'Hidden size': 17, 'Learning rate': 0.0002423417246239051, 'Dropout rate': 0.38082778229421954, 'Epochs': 120}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:10:36,138]\u001b[0m Trial 23 finished with value: 65.92038687541024 and parameters: {'n layers': 5, 'Hidden size': 60, 'Learning rate': 0.0001404715742696626, 'Dropout rate': 0.5461525892147838, 'Epochs': 410}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 200/400 - train_loss: 0.3166 - test_loss: 0.392052\n",
      "Epoch: 95/380 - train_loss: 0.3606 - test_loss: 0.413428\n",
      "Epoch: 321/430 - train_loss: 0.3130 - test_loss: 0.383030\n",
      "Epoch: 37/150 - train_loss: 0.3625 - test_loss: 0.398820\n",
      "Epoch:  0/210 - train_loss: 1.0213 - test_loss: 0.764978\n",
      "Epoch:  0/210 - train_loss: 1.4636 - test_loss: 1.389331\n",
      "Epoch: 200/400 - train_loss: 0.3193 - test_loss: 0.397630\n",
      "Epoch: 306/410 - train_loss: 0.3116 - test_loss: 0.355435\n",
      "Epoch: 74/150 - train_loss: 0.3768 - test_loss: 0.421448\n",
      "Epoch: 306/410 - train_loss: 0.3207 - test_loss: 0.342612\n",
      "Epoch: 52/210 - train_loss: 0.3966 - test_loss: 0.393119\n",
      "Epoch: 111/150 - train_loss: 0.3331 - test_loss: 0.352192\n",
      "Epoch: 300/400 - train_loss: 0.3154 - test_loss: 0.432667\n",
      "Epoch: 52/210 - train_loss: 0.6122 - test_loss: 0.592061\n",
      "Epoch: 148/150 - train_loss: 0.3092 - test_loss: 0.383229\n",
      "Epoch: 149/150 - train_loss: 0.3244 - test_loss: 0.379249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:13:31,097]\u001b[0m Trial 27 finished with value: 54.7861947516467 and parameters: {'n layers': 5, 'Hidden size': 187, 'Learning rate': 0.0010610601332242341, 'Dropout rate': 0.1011580078067374, 'Epochs': 150}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 190/380 - train_loss: 0.3186 - test_loss: 0.364283\n",
      "Epoch: 104/210 - train_loss: 0.3202 - test_loss: 0.370817\n",
      "Epoch: 214/430 - train_loss: 0.3129 - test_loss: 0.396899\n",
      "Epoch:  0/360 - train_loss: 0.8274 - test_loss: 0.684250\n",
      "Epoch: 408/410 - train_loss: 0.3245 - test_loss: 0.384089\n",
      "Epoch: 409/410 - train_loss: 0.3217 - test_loss: 0.384061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:14:13,822]\u001b[0m Trial 21 finished with value: 51.36299642344446 and parameters: {'n layers': 6, 'Hidden size': 147, 'Learning rate': 0.00315316997740033, 'Dropout rate': 0.4781513804451586, 'Epochs': 340}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 300/400 - train_loss: 0.3954 - test_loss: 0.367785\n",
      "Epoch: 408/410 - train_loss: 0.3217 - test_loss: 0.420402\n",
      "Epoch: 409/410 - train_loss: 0.3110 - test_loss: 0.357673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:14:46,136]\u001b[0m Trial 22 finished with value: 52.09732593827468 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.004317012102211092, 'Dropout rate': 0.34481451734446555, 'Epochs': 220}. Best is trial 9 with value: 49.236604099578294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/380 - train_loss: 1.0186 - test_loss: 0.677920\n",
      "Epoch: 104/210 - train_loss: 0.4557 - test_loss: 0.468341\n",
      "Epoch: 156/210 - train_loss: 0.3142 - test_loss: 0.378000\n",
      "Epoch:  0/380 - train_loss: 0.9357 - test_loss: 0.713151\n",
      "Epoch: 428/430 - train_loss: 0.3118 - test_loss: 0.366836\n",
      "Epoch: 429/430 - train_loss: 0.3122 - test_loss: 0.384001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:15:57,379]\u001b[0m Trial 8 finished with value: 48.51442117462789 and parameters: {'n layers': 6, 'Hidden size': 24, 'Learning rate': 0.0069910750433957594, 'Dropout rate': 0.2033047758900022, 'Epochs': 490}. Best is trial 8 with value: 48.51442117462789.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 399/400 - train_loss: 0.3128 - test_loss: 0.394026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:16:02,035]\u001b[0m Trial 24 finished with value: 46.06747392635227 and parameters: {'n layers': 6, 'Hidden size': 361, 'Learning rate': 0.0024282532820617893, 'Dropout rate': 0.19972446228245166, 'Epochs': 220}. Best is trial 24 with value: 46.06747392635227.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 90/360 - train_loss: 0.3624 - test_loss: 0.393270\n",
      "Epoch: 285/380 - train_loss: 0.3511 - test_loss: 0.374817\n",
      "Epoch: 208/210 - train_loss: 0.3549 - test_loss: 0.369510\n",
      "Epoch:  0/500 - train_loss: 0.9674 - test_loss: 0.766613\n",
      "Epoch: 209/210 - train_loss: 0.3247 - test_loss: 0.338603\n",
      "Epoch:  0/500 - train_loss: 1.1802 - test_loss: 1.033748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:16:58,993]\u001b[0m Trial 29 finished with value: 37.31138241251012 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.008368740575206493, 'Dropout rate': 0.04482246859053035, 'Epochs': 210}. Best is trial 29 with value: 37.31138241251012.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 107/430 - train_loss: 0.3214 - test_loss: 0.371448\n",
      "Epoch: 156/210 - train_loss: 0.3627 - test_loss: 0.401648\n",
      "Epoch:  0/220 - train_loss: 1.6117 - test_loss: 1.346758\n",
      "Epoch: 95/380 - train_loss: 0.3917 - test_loss: 0.338218\n",
      "Epoch: 399/400 - train_loss: 0.3120 - test_loss: 0.388602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:17:43,730]\u001b[0m Trial 25 finished with value: 48.274588602641245 and parameters: {'n layers': 6, 'Hidden size': 16, 'Learning rate': 0.003431244956253899, 'Dropout rate': 0.3439140090828378, 'Epochs': 400}. Best is trial 29 with value: 37.31138241251012.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 95/380 - train_loss: 0.3423 - test_loss: 0.379681\n",
      "Epoch:  0/210 - train_loss: 1.7333 - test_loss: 1.403569\n",
      "Epoch: 55/220 - train_loss: 0.4101 - test_loss: 0.399628\n",
      "Epoch: 180/360 - train_loss: 0.3102 - test_loss: 0.366623\n",
      "Epoch: 208/210 - train_loss: 0.3382 - test_loss: 0.384157\n",
      "Epoch: 209/210 - train_loss: 0.3352 - test_loss: 0.389179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:19:20,012]\u001b[0m Trial 28 finished with value: 62.240104357132516 and parameters: {'n layers': 3, 'Hidden size': 46, 'Learning rate': 0.0002089481018097159, 'Dropout rate': 0.3634757423155202, 'Epochs': 100}. Best is trial 29 with value: 37.31138241251012.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 52/210 - train_loss: 0.4870 - test_loss: 0.481237\n",
      "Epoch: 379/380 - train_loss: 0.3212 - test_loss: 0.379635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:19:51,450]\u001b[0m Trial 26 finished with value: 47.512619597986266 and parameters: {'n layers': 3, 'Hidden size': 14, 'Learning rate': 0.00503319480676109, 'Dropout rate': 0.29623355050083006, 'Epochs': 380}. Best is trial 29 with value: 37.31138241251012.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 190/380 - train_loss: 0.3193 - test_loss: 0.401946\n",
      "Epoch:  0/190 - train_loss: 2.1105 - test_loss: 1.745692\n",
      "Epoch: 321/430 - train_loss: 0.3195 - test_loss: 0.393893\n",
      "Epoch: 125/500 - train_loss: 0.3156 - test_loss: 0.368368\n",
      "Epoch: 110/220 - train_loss: 0.3162 - test_loss: 0.405543\n",
      "Epoch:  0/190 - train_loss: 1.6107 - test_loss: 1.175228\n",
      "Epoch: 190/380 - train_loss: 0.3361 - test_loss: 0.449164\n",
      "Epoch: 104/210 - train_loss: 0.3698 - test_loss: 0.372913\n",
      "Epoch: 270/360 - train_loss: 0.3173 - test_loss: 0.351228\n",
      "Epoch: 47/190 - train_loss: 0.5710 - test_loss: 0.562740\n",
      "Epoch: 165/220 - train_loss: 0.3148 - test_loss: 0.383173\n",
      "Epoch: 47/190 - train_loss: 0.4535 - test_loss: 0.471348\n",
      "Epoch: 285/380 - train_loss: 0.3169 - test_loss: 0.334458\n",
      "Epoch: 156/210 - train_loss: 0.3474 - test_loss: 0.382520\n",
      "Epoch: 285/380 - train_loss: 0.3599 - test_loss: 0.386125\n",
      "Epoch: 219/220 - train_loss: 0.3513 - test_loss: 0.404408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:22:34,182]\u001b[0m Trial 35 finished with value: 58.00715296072703 and parameters: {'n layers': 3, 'Hidden size': 8, 'Learning rate': 0.0006241062702116798, 'Dropout rate': 0.043182826044675826, 'Epochs': 220}. Best is trial 29 with value: 37.31138241251012.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 359/360 - train_loss: 0.3180 - test_loss: 0.349594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:22:49,925]\u001b[0m Trial 30 finished with value: 25.41492021245247 and parameters: {'n layers': 4, 'Hidden size': 6, 'Learning rate': 0.009974837689821924, 'Dropout rate': 0.5987988209186107, 'Epochs': 360}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 125/500 - train_loss: 0.3266 - test_loss: 0.435055\n",
      "Epoch: 94/190 - train_loss: 0.3260 - test_loss: 0.411272\n",
      "Epoch: 250/500 - train_loss: 0.3101 - test_loss: 0.382574\n",
      "Epoch: 94/190 - train_loss: 0.3964 - test_loss: 0.410331\n",
      "Epoch:  0/200 - train_loss: 1.3915 - test_loss: 0.921463\n",
      "Epoch: 208/210 - train_loss: 0.3254 - test_loss: 0.362547\n",
      "Epoch: 209/210 - train_loss: 0.3175 - test_loss: 0.389846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:23:45,317]\u001b[0m Trial 36 finished with value: 57.27993331735158 and parameters: {'n layers': 3, 'Hidden size': 5, 'Learning rate': 0.00039139963471988853, 'Dropout rate': 0.017328828735669183, 'Epochs': 210}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/290 - train_loss: 1.0479 - test_loss: 1.024333\n",
      "Epoch: 379/380 - train_loss: 0.3282 - test_loss: 0.397475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:24:04,158]\u001b[0m Trial 31 finished with value: 59.17287565998323 and parameters: {'n layers': 4, 'Hidden size': 6, 'Learning rate': 0.009499833997685784, 'Dropout rate': 0.5950593264474702, 'Epochs': 380}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 107/430 - train_loss: 0.4282 - test_loss: 0.456205\n",
      "Epoch: 141/190 - train_loss: 0.3229 - test_loss: 0.388828\n",
      "Epoch:  0/300 - train_loss: 1.6078 - test_loss: 0.931955\n",
      "Epoch: 141/190 - train_loss: 0.3314 - test_loss: 0.376356\n",
      "Epoch: 379/380 - train_loss: 0.3410 - test_loss: 0.408445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:25:02,680]\u001b[0m Trial 32 finished with value: 53.66853105512697 and parameters: {'n layers': 4, 'Hidden size': 317, 'Learning rate': 0.009813209266843563, 'Dropout rate': 0.6271606200251378, 'Epochs': 380}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 50/200 - train_loss: 0.3217 - test_loss: 0.383681\n",
      "Epoch:  0/180 - train_loss: 1.4391 - test_loss: 0.848439\n",
      "Epoch:  0/180 - train_loss: 1.7125 - test_loss: 1.066763\n",
      "Epoch: 72/290 - train_loss: 0.3320 - test_loss: 0.415543\n",
      "Epoch: 188/190 - train_loss: 0.3102 - test_loss: 0.371770\n",
      "Epoch: 189/190 - train_loss: 0.3220 - test_loss: 0.377219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:25:59,723]\u001b[0m Trial 38 finished with value: 61.364074675047874 and parameters: {'n layers': 5, 'Hidden size': 5, 'Learning rate': 0.0004997799983693352, 'Dropout rate': 0.06294302386847506, 'Epochs': 190}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 45/180 - train_loss: 0.3552 - test_loss: 0.359995\n",
      "Epoch: 100/200 - train_loss: 0.3111 - test_loss: 0.381763\n",
      "Epoch: 188/190 - train_loss: 0.3722 - test_loss: 0.372473\n",
      "Epoch: 189/190 - train_loss: 0.3259 - test_loss: 0.408397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:26:21,687]\u001b[0m Trial 37 finished with value: 62.508126989002875 and parameters: {'n layers': 5, 'Hidden size': 5, 'Learning rate': 0.0003956416699719635, 'Dropout rate': 0.011266144731700463, 'Epochs': 200}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 428/430 - train_loss: 0.3320 - test_loss: 0.409777\n",
      "Epoch: 429/430 - train_loss: 0.3503 - test_loss: 0.403768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:26:41,843]\u001b[0m Trial 5 finished with value: 48.11724003251296 and parameters: {'n layers': 4, 'Hidden size': 292, 'Learning rate': 0.005638357781116285, 'Dropout rate': 0.5900958198347893, 'Epochs': 400}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 214/430 - train_loss: 0.3543 - test_loss: 0.371761\n",
      "Epoch: 375/500 - train_loss: 0.3111 - test_loss: 0.381457\n",
      "Epoch: 75/300 - train_loss: 0.3211 - test_loss: 0.352288\n",
      "Epoch:  0/290 - train_loss: 1.3259 - test_loss: 0.873763\n",
      "Epoch: 45/180 - train_loss: 0.3382 - test_loss: 0.398130\n",
      "Epoch:  0/290 - train_loss: 1.1595 - test_loss: 0.685730\n",
      "Epoch: 90/180 - train_loss: 0.3476 - test_loss: 0.384876\n",
      "Epoch: 250/500 - train_loss: 0.3333 - test_loss: 0.327807\n",
      "Epoch:  0/290 - train_loss: 1.1863 - test_loss: 0.891700\n",
      "Epoch: 150/200 - train_loss: 0.3183 - test_loss: 0.391966\n",
      "Epoch: 144/290 - train_loss: 0.3144 - test_loss: 0.353526\n",
      "Epoch: 90/180 - train_loss: 0.3134 - test_loss: 0.327582\n",
      "Epoch: 135/180 - train_loss: 0.3174 - test_loss: 0.367410\n",
      "Epoch: 199/200 - train_loss: 0.3505 - test_loss: 0.441566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:28:36,555]\u001b[0m Trial 39 finished with value: 47.06867238575739 and parameters: {'n layers': 5, 'Hidden size': 338, 'Learning rate': 0.0018276134242574975, 'Dropout rate': 0.2261296215214389, 'Epochs': 190}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 150/300 - train_loss: 0.3137 - test_loss: 0.407149\n",
      "Epoch: 72/290 - train_loss: 0.3139 - test_loss: 0.367859\n",
      "Epoch: 135/180 - train_loss: 0.3143 - test_loss: 0.370000\n",
      "Epoch: 216/290 - train_loss: 0.3109 - test_loss: 0.386046\n",
      "Epoch: 179/180 - train_loss: 0.3256 - test_loss: 0.370045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:29:19,979]\u001b[0m Trial 42 finished with value: 55.168438530612356 and parameters: {'n layers': 5, 'Hidden size': 10, 'Learning rate': 0.00186598396985036, 'Dropout rate': 0.23564045496109312, 'Epochs': 300}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/280 - train_loss: 1.1400 - test_loss: 0.872190\n",
      "Epoch: 72/290 - train_loss: 0.3199 - test_loss: 0.371282\n",
      "Epoch: 499/500 - train_loss: 0.3185 - test_loss: 0.364482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:29:50,277]\u001b[0m Trial 34 finished with value: 58.640057068485795 and parameters: {'n layers': 6, 'Hidden size': 10, 'Learning rate': 0.0004756061437684779, 'Dropout rate': 0.197557192913764, 'Epochs': 500}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/270 - train_loss: 0.9366 - test_loss: 0.701112\n",
      "Epoch: 179/180 - train_loss: 0.3141 - test_loss: 0.380419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:30:17,214]\u001b[0m Trial 43 finished with value: 50.91710197335425 and parameters: {'n layers': 5, 'Hidden size': 9, 'Learning rate': 0.001585834698085785, 'Dropout rate': 0.222753483015246, 'Epochs': 180}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/270 - train_loss: 0.9733 - test_loss: 0.744109\n",
      "Epoch: 225/300 - train_loss: 0.3145 - test_loss: 0.417108\n",
      "Epoch: 144/290 - train_loss: 0.3176 - test_loss: 0.377903\n",
      "Epoch: 288/290 - train_loss: 0.3145 - test_loss: 0.426244\n",
      "Epoch: 289/290 - train_loss: 0.3126 - test_loss: 0.407074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:31:02,849]\u001b[0m Trial 40 finished with value: 53.08404097301955 and parameters: {'n layers': 5, 'Hidden size': 5, 'Learning rate': 0.0017353489128526054, 'Dropout rate': 0.02766986100920198, 'Epochs': 200}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/280 - train_loss: 0.3198 - test_loss: 0.406241\n",
      "Epoch: 72/290 - train_loss: 0.3169 - test_loss: 0.359980\n",
      "Epoch: 67/270 - train_loss: 0.3363 - test_loss: 0.417713\n",
      "Epoch: 144/290 - train_loss: 0.3149 - test_loss: 0.433975\n",
      "Epoch: 67/270 - train_loss: 0.3276 - test_loss: 0.427276\n",
      "Epoch: 375/500 - train_loss: 0.3109 - test_loss: 0.400406\n",
      "Epoch: 299/300 - train_loss: 0.3094 - test_loss: 0.376349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:32:18,636]\u001b[0m Trial 41 finished with value: 48.636212398591965 and parameters: {'n layers': 5, 'Hidden size': 9, 'Learning rate': 0.00179998659114046, 'Dropout rate': 0.6386284314841956, 'Epochs': 290}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216/290 - train_loss: 0.3301 - test_loss: 0.410645\n",
      "Epoch: 140/280 - train_loss: 0.3128 - test_loss: 0.352004\n",
      "Epoch: 134/270 - train_loss: 0.3147 - test_loss: 0.420577\n",
      "Epoch: 134/270 - train_loss: 0.3253 - test_loss: 0.470531\n",
      "Epoch: 216/290 - train_loss: 0.3133 - test_loss: 0.362442\n",
      "Epoch: 321/430 - train_loss: 0.3190 - test_loss: 0.393638\n",
      "Epoch: 144/290 - train_loss: 0.3119 - test_loss: 0.381764\n",
      "Epoch: 288/290 - train_loss: 0.3495 - test_loss: 0.331936\n",
      "Epoch: 289/290 - train_loss: 0.3526 - test_loss: 0.355634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:33:51,366]\u001b[0m Trial 44 finished with value: 46.76804699757298 and parameters: {'n layers': 5, 'Hidden size': 10, 'Learning rate': 0.0017172967064258027, 'Dropout rate': 0.23067961054676225, 'Epochs': 300}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210/280 - train_loss: 0.3198 - test_loss: 0.362642\n",
      "Epoch: 201/270 - train_loss: 0.3137 - test_loss: 0.377196\n",
      "Epoch: 201/270 - train_loss: 0.3724 - test_loss: 0.353256\n",
      "Epoch: 214/430 - train_loss: 0.3715 - test_loss: 0.391227\n",
      "Epoch: 288/290 - train_loss: 0.3157 - test_loss: 0.377051\n",
      "Epoch: 289/290 - train_loss: 0.3299 - test_loss: 0.403069\n",
      "Epoch: 107/430 - train_loss: 0.4633 - test_loss: 0.480995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:34:33,429]\u001b[0m Trial 45 finished with value: 52.33514176591939 and parameters: {'n layers': 5, 'Hidden size': 8, 'Learning rate': 0.0017670782967908348, 'Dropout rate': 0.23529361088149003, 'Epochs': 290}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499/500 - train_loss: 0.3113 - test_loss: 0.406357\n",
      "Epoch: 107/430 - train_loss: 0.4654 - test_loss: 0.485378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:34:36,984]\u001b[0m Trial 33 finished with value: 46.899499850252276 and parameters: {'n layers': 5, 'Hidden size': 10, 'Learning rate': 0.009690705560787488, 'Dropout rate': 0.2267629457283368, 'Epochs': 470}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216/290 - train_loss: 0.3511 - test_loss: 0.381045\n",
      "Epoch: 279/280 - train_loss: 0.3131 - test_loss: 0.432276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:08,360]\u001b[0m Trial 47 finished with value: 53.0291733731357 and parameters: {'n layers': 3, 'Hidden size': 9, 'Learning rate': 0.0015772223537745568, 'Dropout rate': 0.25060434714740365, 'Epochs': 290}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268/270 - train_loss: 0.3161 - test_loss: 0.359184\n",
      "Epoch: 269/270 - train_loss: 0.3186 - test_loss: 0.354241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:11,408]\u001b[0m Trial 48 finished with value: 54.85277510002063 and parameters: {'n layers': 3, 'Hidden size': 12, 'Learning rate': 0.006171354005209853, 'Dropout rate': 0.16134991205185933, 'Epochs': 280}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268/270 - train_loss: 0.3234 - test_loss: 0.381860\n",
      "Epoch: 269/270 - train_loss: 0.3135 - test_loss: 0.386095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:32,184]\u001b[0m Trial 49 finished with value: 41.10033650021274 and parameters: {'n layers': 3, 'Hidden size': 8, 'Learning rate': 0.006942397195085244, 'Dropout rate': 0.12657868240740372, 'Epochs': 270}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428/430 - train_loss: 0.3128 - test_loss: 0.355579\n",
      "Epoch: 429/430 - train_loss: 0.3116 - test_loss: 0.376894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:35:42,407]\u001b[0m Trial 13 finished with value: 58.45805989951217 and parameters: {'n layers': 6, 'Hidden size': 375, 'Learning rate': 0.0006842484266814916, 'Dropout rate': 0.7352865650941901, 'Epochs': 290}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107/430 - train_loss: 0.3467 - test_loss: 0.364210\n",
      "Epoch: 288/290 - train_loss: 0.3131 - test_loss: 0.359437\n",
      "Epoch: 289/290 - train_loss: 0.3210 - test_loss: 0.410170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:36:10,870]\u001b[0m Trial 46 finished with value: 52.67869862518628 and parameters: {'n layers': 5, 'Hidden size': 9, 'Learning rate': 0.001840994857107267, 'Dropout rate': 0.25175333567602765, 'Epochs': 290}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.3172 - test_loss: 0.371918\n",
      "Epoch: 214/430 - train_loss: 0.3447 - test_loss: 0.378353\n",
      "Epoch: 107/430 - train_loss: 0.5474 - test_loss: 0.513675\n",
      "Epoch: 214/430 - train_loss: 0.3369 - test_loss: 0.384925\n",
      "Epoch: 107/430 - train_loss: 0.3363 - test_loss: 0.401656\n",
      "Epoch: 214/430 - train_loss: 0.3145 - test_loss: 0.378837\n",
      "Epoch: 107/430 - train_loss: 0.3528 - test_loss: 0.371667\n",
      "Epoch: 428/430 - train_loss: 0.3170 - test_loss: 0.370645\n",
      "Epoch: 429/430 - train_loss: 0.3913 - test_loss: 0.368182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:37:54,698]\u001b[0m Trial 7 finished with value: 61.216114065949945 and parameters: {'n layers': 4, 'Hidden size': 7, 'Learning rate': 0.00022662988511524786, 'Dropout rate': 0.28274748214419454, 'Epochs': 410}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.3512 - test_loss: 0.359268\n",
      "Epoch: 321/430 - train_loss: 0.3173 - test_loss: 0.380511\n",
      "Epoch: 214/430 - train_loss: 0.3621 - test_loss: 0.384734\n",
      "Epoch: 107/430 - train_loss: 0.3081 - test_loss: 0.371889\n",
      "Epoch: 214/430 - train_loss: 0.3236 - test_loss: 0.346740\n",
      "Epoch: 321/430 - train_loss: 0.3208 - test_loss: 0.444472\n",
      "Epoch: 107/430 - train_loss: 0.3158 - test_loss: 0.349778\n",
      "Epoch: 214/430 - train_loss: 0.3545 - test_loss: 0.369425\n",
      "Epoch: 428/430 - train_loss: 0.3141 - test_loss: 0.380241\n",
      "Epoch: 429/430 - train_loss: 0.3186 - test_loss: 0.379613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:39:27,810]\u001b[0m Trial 19 finished with value: 57.09041557726718 and parameters: {'n layers': 4, 'Hidden size': 19, 'Learning rate': 0.000180783002172837, 'Dropout rate': 0.059668049974001526, 'Epochs': 430}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428/430 - train_loss: 0.3140 - test_loss: 0.388556\n",
      "Epoch: 429/430 - train_loss: 0.3356 - test_loss: 0.389010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:39:36,162]\u001b[0m Trial 6 finished with value: 60.420892918852424 and parameters: {'n layers': 3, 'Hidden size': 41, 'Learning rate': 0.00018847632258969538, 'Dropout rate': 0.27080874390579934, 'Epochs': 470}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.3421 - test_loss: 0.364779\n",
      "Epoch: 214/430 - train_loss: 0.3254 - test_loss: 0.390158\n",
      "Epoch: 321/430 - train_loss: 0.3103 - test_loss: 0.382694\n",
      "Epoch: 428/430 - train_loss: 0.3311 - test_loss: 0.372849\n",
      "Epoch: 429/430 - train_loss: 0.3148 - test_loss: 0.410418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:40:12,651]\u001b[0m Trial 10 finished with value: 48.547625965636904 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.003432499972708783, 'Dropout rate': 0.6902566703080597, 'Epochs': 450}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.3100 - test_loss: 0.379784\n",
      "Epoch: 428/430 - train_loss: 0.3185 - test_loss: 0.382045\n",
      "Epoch: 429/430 - train_loss: 0.3128 - test_loss: 0.373047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:40:38,812]\u001b[0m Trial 0 finished with value: 60.434230302739365 and parameters: {'n layers': 3, 'Hidden size': 8, 'Learning rate': 0.00016908464478933646, 'Dropout rate': 0.7848130548925699, 'Epochs': 370}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214/430 - train_loss: 0.3275 - test_loss: 0.348201\n",
      "Epoch: 428/430 - train_loss: 0.3121 - test_loss: 0.446454\n",
      "Epoch: 429/430 - train_loss: 0.3555 - test_loss: 0.374352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:40:52,403]\u001b[0m Trial 2 finished with value: 51.54547552180902 and parameters: {'n layers': 6, 'Hidden size': 6, 'Learning rate': 0.004443561066959474, 'Dropout rate': 0.3044556853426071, 'Epochs': 350}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.3183 - test_loss: 0.324480\n",
      "Epoch: 428/430 - train_loss: 0.3127 - test_loss: 0.351971\n",
      "Epoch: 429/430 - train_loss: 0.3119 - test_loss: 0.349962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:41:02,380]\u001b[0m Trial 16 finished with value: 49.78045338330881 and parameters: {'n layers': 6, 'Hidden size': 260, 'Learning rate': 0.0069021564095516595, 'Dropout rate': 0.227970092894235, 'Epochs': 240}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321/430 - train_loss: 0.3557 - test_loss: 0.406116\n",
      "Epoch: 428/430 - train_loss: 0.3133 - test_loss: 0.378190\n",
      "Epoch: 429/430 - train_loss: 0.3603 - test_loss: 0.406744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:41:13,962]\u001b[0m Trial 1 finished with value: 51.25144013170956 and parameters: {'n layers': 5, 'Hidden size': 20, 'Learning rate': 0.0015235179188951794, 'Dropout rate': 0.24359110640880283, 'Epochs': 120}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428/430 - train_loss: 0.3283 - test_loss: 0.362636\n",
      "Epoch: 429/430 - train_loss: 0.3543 - test_loss: 0.402110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:41:24,063]\u001b[0m Trial 3 finished with value: 53.44157399092655 and parameters: {'n layers': 5, 'Hidden size': 35, 'Learning rate': 0.004873663929091037, 'Dropout rate': 0.33194924638736245, 'Epochs': 360}. Best is trial 30 with value: 25.41492021245247.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 02:41:24,080]\u001b[0m A new study created in memory with name: no-name-55c99b6d-ad12-4072-8a5e-61bc73dc1820\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Sóc Trăng\n",
      "  Value:  25.41492021245247\n",
      "optimize result of city: Sóc Trăng\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback 3\n",
      "lookback lookback 3\n",
      "3\n",
      "lookback 3\n",
      "Epoch:  0/210 - train_loss: 1.4287 - test_loss: 1.900340\n",
      "Epoch:  0/210 - train_loss: 1.3691 - test_loss: 0.980501\n",
      "Epoch:  0/210 - train_loss: 0.9849 - test_loss: 0.637538\n",
      "Epoch:  0/210 - train_loss: 2.0315 - test_loss: 1.870271\n",
      "Epoch:  0/210 - train_loss: 1.0671 - test_loss: 0.935987Epoch:  0/210 - train_loss: 1.6392 - test_loss: 1.423390\n",
      "Epoch:  0/210 - train_loss: 1.3748 - test_loss: 1.044499\n",
      "\n",
      "Epoch:  0/210 - train_loss: 0.8662 - test_loss: 0.578277\n",
      "Epoch:  0/210 - train_loss: 1.1664 - test_loss: 0.869366\n",
      "Epoch:  0/210 - train_loss: 1.2118 - test_loss: 0.995884\n",
      "Epoch:  0/210 - train_loss: 1.7264 - test_loss: 1.375111\n",
      "Epoch:  0/210 - train_loss: 1.1237 - test_loss: 0.697949\n",
      "Epoch:  0/210 - train_loss: 0.9227 - test_loss: 0.702795\n",
      "Epoch:  0/210 - train_loss: 1.2781 - test_loss: 1.045503\n",
      "Epoch:  0/210 - train_loss: 1.3060 - test_loss: 1.226287Epoch:  0/210 - train_loss: 1.1378 - test_loss: 0.704318\n",
      "\n",
      "Epoch:  0/210 - train_loss: 1.6069 - test_loss: 1.145099Epoch:  0/210 - train_loss: 1.4563 - test_loss: 1.209029\n",
      "\n",
      "Epoch:  0/210 - train_loss: 1.2601 - test_loss: 1.069228\n",
      "Epoch:  0/210 - train_loss: 1.3835 - test_loss: 1.147989\n",
      "Epoch: 52/210 - train_loss: 0.5872 - test_loss: 0.474589\n",
      "Epoch: 52/210 - train_loss: 0.3221 - test_loss: 0.160584\n",
      "Epoch: 52/210 - train_loss: 0.6946 - test_loss: 0.569957\n",
      "Epoch: 52/210 - train_loss: 0.2909 - test_loss: 0.136754\n",
      "Epoch: 52/210 - train_loss: 0.3284 - test_loss: 0.143638\n",
      "Epoch: 52/210 - train_loss: 0.4923 - test_loss: 0.343076\n",
      "Epoch: 52/210 - train_loss: 0.4426 - test_loss: 0.350651\n",
      "Epoch: 104/210 - train_loss: 0.4036 - test_loss: 0.304326\n",
      "Epoch: 104/210 - train_loss: 0.2893 - test_loss: 0.139749\n",
      "Epoch: 104/210 - train_loss: 0.5072 - test_loss: 0.423652\n",
      "Epoch: 104/210 - train_loss: 0.3162 - test_loss: 0.157710\n",
      "Epoch: 104/210 - train_loss: 0.3008 - test_loss: 0.143357\n",
      "Epoch: 52/210 - train_loss: 0.5794 - test_loss: 0.503394\n",
      "Epoch: 104/210 - train_loss: 0.3246 - test_loss: 0.182940\n",
      "Epoch: 104/210 - train_loss: 0.3230 - test_loss: 0.187519\n",
      "Epoch: 156/210 - train_loss: 0.3445 - test_loss: 0.210738\n",
      "Epoch: 156/210 - train_loss: 0.3054 - test_loss: 0.141430\n",
      "Epoch: 156/210 - train_loss: 0.4401 - test_loss: 0.310926\n",
      "Epoch: 156/210 - train_loss: 0.3249 - test_loss: 0.143071\n",
      "Epoch: 156/210 - train_loss: 0.2887 - test_loss: 0.140379\n",
      "Epoch: 52/210 - train_loss: 0.2922 - test_loss: 0.135372\n",
      "Epoch: 156/210 - train_loss: 0.2925 - test_loss: 0.148432\n",
      "Epoch: 208/210 - train_loss: 0.3014 - test_loss: 0.165397\n",
      "Epoch: 209/210 - train_loss: 0.3060 - test_loss: 0.163400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:51:42,205]\u001b[0m Trial 14 finished with value: 16.127722678693495 and parameters: {'n layers': 3, 'Hidden size': 14, 'Learning rate': 0.00025127465876261586, 'Dropout rate': 0.7679924553620109, 'Epochs': 450}. Best is trial 14 with value: 16.127722678693495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 208/210 - train_loss: 0.2952 - test_loss: 0.141258\n",
      "Epoch: 209/210 - train_loss: 0.3056 - test_loss: 0.144384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:51:52,450]\u001b[0m Trial 5 finished with value: 12.526566963460981 and parameters: {'n layers': 4, 'Hidden size': 22, 'Learning rate': 0.001103636003486044, 'Dropout rate': 0.22408307573280417, 'Epochs': 140}. Best is trial 5 with value: 12.526566963460981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 104/210 - train_loss: 0.4376 - test_loss: 0.359738\n",
      "Epoch: 208/210 - train_loss: 0.3414 - test_loss: 0.234022\n",
      "Epoch: 156/210 - train_loss: 0.2892 - test_loss: 0.147603\n",
      "Epoch: 209/210 - train_loss: 0.3744 - test_loss: 0.230826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:52:07,712]\u001b[0m Trial 12 finished with value: 12.469253460411977 and parameters: {'n layers': 6, 'Hidden size': 34, 'Learning rate': 0.00019294956122021777, 'Dropout rate': 0.029433289265970622, 'Epochs': 160}. Best is trial 12 with value: 12.469253460411977.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 208/210 - train_loss: 0.3103 - test_loss: 0.142622\n",
      "Epoch: 209/210 - train_loss: 0.2909 - test_loss: 0.149280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:52:31,264]\u001b[0m Trial 16 finished with value: 10.388062511365286 and parameters: {'n layers': 3, 'Hidden size': 31, 'Learning rate': 0.0015735237565409142, 'Dropout rate': 0.3999373248233408, 'Epochs': 180}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 208/210 - train_loss: 0.2932 - test_loss: 0.141255\n",
      "Epoch: 209/210 - train_loss: 0.2888 - test_loss: 0.131759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:53:01,632]\u001b[0m Trial 13 finished with value: 14.94705627369764 and parameters: {'n layers': 5, 'Hidden size': 193, 'Learning rate': 0.0076547764576698485, 'Dropout rate': 0.44589153267102116, 'Epochs': 320}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/340 - train_loss: 0.8562 - test_loss: 0.624501\n",
      "Epoch:  0/350 - train_loss: 1.2407 - test_loss: 0.691600\n",
      "Epoch: 52/210 - train_loss: 0.3069 - test_loss: 0.141599\n",
      "Epoch: 52/210 - train_loss: 0.3369 - test_loss: 0.178813\n",
      "Epoch: 52/210 - train_loss: 0.7955 - test_loss: 0.612245\n",
      "Epoch: 208/210 - train_loss: 0.2868 - test_loss: 0.142262\n",
      "Epoch:  0/350 - train_loss: 1.0856 - test_loss: 0.979836\n",
      "Epoch: 209/210 - train_loss: 0.2928 - test_loss: 0.140370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:53:47,970]\u001b[0m Trial 7 finished with value: 15.2001485168611 and parameters: {'n layers': 5, 'Hidden size': 13, 'Learning rate': 0.00045109721665004395, 'Dropout rate': 0.6751217961065723, 'Epochs': 290}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 104/210 - train_loss: 0.2911 - test_loss: 0.141004\n",
      "Epoch:  0/110 - train_loss: 0.8720 - test_loss: 0.574981\n",
      "Epoch:  0/110 - train_loss: 1.5001 - test_loss: 1.567090\n",
      "Epoch: 208/210 - train_loss: 0.3245 - test_loss: 0.140059\n",
      "Epoch: 156/210 - train_loss: 0.3546 - test_loss: 0.255429\n",
      "Epoch: 209/210 - train_loss: 0.2937 - test_loss: 0.140788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:54:38,932]\u001b[0m Trial 8 finished with value: 12.984661667010519 and parameters: {'n layers': 3, 'Hidden size': 13, 'Learning rate': 0.0004220194676121362, 'Dropout rate': 0.18395410137665635, 'Epochs': 390}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/440 - train_loss: 1.2479 - test_loss: 1.550477\n",
      "Epoch: 27/110 - train_loss: 0.3142 - test_loss: 0.139644\n",
      "Epoch: 27/110 - train_loss: 0.3543 - test_loss: 0.226789\n",
      "Epoch:  0/440 - train_loss: 0.8307 - test_loss: 0.628091\n",
      "Epoch: 54/110 - train_loss: 0.2968 - test_loss: 0.147877\n",
      "Epoch: 85/340 - train_loss: 0.2898 - test_loss: 0.141919\n",
      "Epoch: 54/110 - train_loss: 0.3241 - test_loss: 0.148190\n",
      "Epoch: 87/350 - train_loss: 0.2869 - test_loss: 0.138342\n",
      "Epoch: 87/350 - train_loss: 0.2987 - test_loss: 0.154585\n",
      "Epoch: 81/110 - train_loss: 0.2939 - test_loss: 0.137400\n",
      "Epoch: 81/110 - train_loss: 0.2961 - test_loss: 0.139441\n",
      "Epoch: 208/210 - train_loss: 0.3079 - test_loss: 0.191347\n",
      "Epoch: 209/210 - train_loss: 0.3140 - test_loss: 0.189780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:56:29,427]\u001b[0m Trial 4 finished with value: 15.40574697108436 and parameters: {'n layers': 6, 'Hidden size': 233, 'Learning rate': 0.00021400071449130797, 'Dropout rate': 0.48703583448641324, 'Epochs': 300}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 156/210 - train_loss: 0.2883 - test_loss: 0.136408\n",
      "Epoch: 104/210 - train_loss: 0.2912 - test_loss: 0.133061\n",
      "Epoch: 108/110 - train_loss: 0.2932 - test_loss: 0.137798\n",
      "Epoch: 109/110 - train_loss: 0.3233 - test_loss: 0.137609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:56:58,916]\u001b[0m Trial 23 finished with value: 13.699319879288488 and parameters: {'n layers': 3, 'Hidden size': 17, 'Learning rate': 0.00812770920462036, 'Dropout rate': 0.6905737289299198, 'Epochs': 340}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/330 - train_loss: 1.0335 - test_loss: 0.774766\n",
      "Epoch: 108/110 - train_loss: 0.2866 - test_loss: 0.139337\n",
      "Epoch: 109/110 - train_loss: 0.2882 - test_loss: 0.138311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:57:22,113]\u001b[0m Trial 24 finished with value: 14.300714669751892 and parameters: {'n layers': 6, 'Hidden size': 11, 'Learning rate': 0.001383058166244756, 'Dropout rate': 0.21974223225968906, 'Epochs': 350}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/210 - train_loss: 1.0068 - test_loss: 0.711044\n",
      "Epoch: 110/440 - train_loss: 0.3947 - test_loss: 0.296684\n",
      "Epoch: 170/340 - train_loss: 0.2905 - test_loss: 0.152091\n",
      "Epoch: 104/210 - train_loss: 0.2920 - test_loss: 0.139013\n",
      "Epoch:  0/210 - train_loss: 1.0279 - test_loss: 0.754214\n",
      "Epoch: 174/350 - train_loss: 0.2914 - test_loss: 0.138698\n",
      "Epoch: 174/350 - train_loss: 0.2902 - test_loss: 0.136697\n",
      "Epoch: 110/440 - train_loss: 0.2955 - test_loss: 0.142709\n",
      "Epoch: 208/210 - train_loss: 0.2989 - test_loss: 0.137693\n",
      "Epoch: 209/210 - train_loss: 0.2875 - test_loss: 0.142873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 02:59:01,019]\u001b[0m Trial 10 finished with value: 10.506806797676454 and parameters: {'n layers': 4, 'Hidden size': 9, 'Learning rate': 0.0029319089288787513, 'Dropout rate': 0.5797271333379872, 'Epochs': 290}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 52/210 - train_loss: 0.3445 - test_loss: 0.195458\n",
      "Epoch:  0/220 - train_loss: 1.4471 - test_loss: 1.373605\n",
      "Epoch: 52/210 - train_loss: 0.2886 - test_loss: 0.139299\n",
      "Epoch: 255/340 - train_loss: 0.2877 - test_loss: 0.135355\n",
      "Epoch: 261/350 - train_loss: 0.2994 - test_loss: 0.157797\n",
      "Epoch: 82/330 - train_loss: 0.3565 - test_loss: 0.148963\n",
      "Epoch: 104/210 - train_loss: 0.2893 - test_loss: 0.140533\n",
      "Epoch: 156/210 - train_loss: 0.2961 - test_loss: 0.136782\n",
      "Epoch: 261/350 - train_loss: 0.3044 - test_loss: 0.140066\n",
      "Epoch: 220/440 - train_loss: 0.3316 - test_loss: 0.157889\n",
      "Epoch: 104/210 - train_loss: 0.2960 - test_loss: 0.139886\n",
      "Epoch: 156/210 - train_loss: 0.2868 - test_loss: 0.140843\n",
      "Epoch: 339/340 - train_loss: 0.2901 - test_loss: 0.154242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:01:45,348]\u001b[0m Trial 20 finished with value: 12.46581041295646 and parameters: {'n layers': 4, 'Hidden size': 7, 'Learning rate': 0.005993569856493984, 'Dropout rate': 0.7623219009772528, 'Epochs': 150}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 220/440 - train_loss: 0.2891 - test_loss: 0.134013\n",
      "Epoch: 348/350 - train_loss: 0.3103 - test_loss: 0.145079\n",
      "Epoch:  0/230 - train_loss: 0.9675 - test_loss: 0.766892\n",
      "Epoch: 156/210 - train_loss: 0.2941 - test_loss: 0.156048\n",
      "Epoch: 349/350 - train_loss: 0.3516 - test_loss: 0.151952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:02:24,062]\u001b[0m Trial 21 finished with value: 11.895729782436705 and parameters: {'n layers': 4, 'Hidden size': 274, 'Learning rate': 0.0021892897340418686, 'Dropout rate': 0.6725449008256433, 'Epochs': 210}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 55/220 - train_loss: 0.2897 - test_loss: 0.141759\n",
      "Epoch: 348/350 - train_loss: 0.3016 - test_loss: 0.138297\n",
      "Epoch: 349/350 - train_loss: 0.2917 - test_loss: 0.139373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:02:49,342]\u001b[0m Trial 22 finished with value: 12.120372903764775 and parameters: {'n layers': 6, 'Hidden size': 5, 'Learning rate': 0.000660601946307945, 'Dropout rate': 0.09521596097582752, 'Epochs': 300}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/230 - train_loss: 1.1333 - test_loss: 0.709892\n",
      "Epoch: 208/210 - train_loss: 0.3111 - test_loss: 0.135582\n",
      "Epoch: 209/210 - train_loss: 0.2949 - test_loss: 0.134613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:03:16,453]\u001b[0m Trial 28 finished with value: 12.899170661752203 and parameters: {'n layers': 3, 'Hidden size': 181, 'Learning rate': 0.0008618546086606198, 'Dropout rate': 0.22987984065857378, 'Epochs': 330}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 164/330 - train_loss: 0.2879 - test_loss: 0.139276\n",
      "Epoch:  0/240 - train_loss: 1.2015 - test_loss: 0.884577\n",
      "Epoch: 104/210 - train_loss: 0.6146 - test_loss: 0.501781\n",
      "Epoch: 330/440 - train_loss: 0.2980 - test_loss: 0.141302\n",
      "Epoch:  0/240 - train_loss: 1.2664 - test_loss: 0.767931\n",
      "Epoch: 208/210 - train_loss: 0.2915 - test_loss: 0.134620\n",
      "Epoch: 209/210 - train_loss: 0.2959 - test_loss: 0.136386\n",
      "Epoch: 208/210 - train_loss: 0.3061 - test_loss: 0.141639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:11,520]\u001b[0m Trial 1 finished with value: 11.144121057549105 and parameters: {'n layers': 4, 'Hidden size': 18, 'Learning rate': 0.005029938051567078, 'Dropout rate': 0.4546476193344003, 'Epochs': 390}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 57/230 - train_loss: 0.2965 - test_loss: 0.140544\n",
      "Epoch: 209/210 - train_loss: 0.3066 - test_loss: 0.137072\n",
      "Epoch: 52/210 - train_loss: 0.3368 - test_loss: 0.190006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:04:15,489]\u001b[0m Trial 29 finished with value: 11.81456716926563 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.0025234700564646735, 'Dropout rate': 0.34517433308179496, 'Epochs': 210}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 156/210 - train_loss: 0.2916 - test_loss: 0.135536\n",
      "Epoch: 57/230 - train_loss: 0.3327 - test_loss: 0.133642\n",
      "Epoch:  0/240 - train_loss: 1.2196 - test_loss: 0.781692\n",
      "Epoch: 110/220 - train_loss: 0.2927 - test_loss: 0.137788\n",
      "Epoch:  0/240 - train_loss: 1.0656 - test_loss: 0.750515\n",
      "Epoch: 60/240 - train_loss: 0.3260 - test_loss: 0.148848\n",
      "Epoch: 114/230 - train_loss: 0.2903 - test_loss: 0.134508\n",
      "Epoch: 60/240 - train_loss: 0.3156 - test_loss: 0.144275\n",
      "Epoch: 330/440 - train_loss: 0.2898 - test_loss: 0.139902\n",
      "Epoch: 114/230 - train_loss: 0.2924 - test_loss: 0.136027\n",
      "Epoch: 60/240 - train_loss: 0.2879 - test_loss: 0.148891\n",
      "Epoch: 439/440 - train_loss: 0.2941 - test_loss: 0.141168\n",
      "Epoch: 120/240 - train_loss: 0.2883 - test_loss: 0.143783\n",
      "Epoch: 246/330 - train_loss: 0.2894 - test_loss: 0.139933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:06:35,306]\u001b[0m Trial 25 finished with value: 13.563786006392917 and parameters: {'n layers': 3, 'Hidden size': 156, 'Learning rate': 0.0002429484004128367, 'Dropout rate': 0.5350722295677163, 'Epochs': 110}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 171/230 - train_loss: 0.2941 - test_loss: 0.139275\n",
      "Epoch: 120/240 - train_loss: 0.3113 - test_loss: 0.137267\n",
      "Epoch:  0/240 - train_loss: 1.1713 - test_loss: 0.687950\n",
      "Epoch: 171/230 - train_loss: 0.2917 - test_loss: 0.139948\n",
      "Epoch: 180/240 - train_loss: 0.2906 - test_loss: 0.133844\n",
      "Epoch: 165/220 - train_loss: 0.2929 - test_loss: 0.138851\n",
      "Epoch: 120/240 - train_loss: 0.2914 - test_loss: 0.139801\n",
      "Epoch: 228/230 - train_loss: 0.3128 - test_loss: 0.137995\n",
      "Epoch: 229/230 - train_loss: 0.2953 - test_loss: 0.144510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:07:57,984]\u001b[0m Trial 31 finished with value: 11.815991935738957 and parameters: {'n layers': 4, 'Hidden size': 72, 'Learning rate': 0.0028145618796617134, 'Dropout rate': 0.5440575080991192, 'Epochs': 230}. Best is trial 16 with value: 10.388062511365286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 180/240 - train_loss: 0.2935 - test_loss: 0.136419\n",
      "Epoch: 228/230 - train_loss: 0.2925 - test_loss: 0.128842\n",
      "Epoch: 60/240 - train_loss: 0.3405 - test_loss: 0.150482\n",
      "Epoch: 229/230 - train_loss: 0.2841 - test_loss: 0.130095\n",
      "Epoch:  0/230 - train_loss: 0.9029 - test_loss: 0.645222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:08:38,956]\u001b[0m Trial 32 finished with value: 9.167614902218277 and parameters: {'n layers': 3, 'Hidden size': 101, 'Learning rate': 0.0032582103985809357, 'Dropout rate': 0.5634988979537259, 'Epochs': 230}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 439/440 - train_loss: 0.2879 - test_loss: 0.135314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:08:44,701]\u001b[0m Trial 26 finished with value: 12.020540168409902 and parameters: {'n layers': 6, 'Hidden size': 74, 'Learning rate': 0.004368960570247092, 'Dropout rate': 0.7174249493151718, 'Epochs': 440}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 328/330 - train_loss: 0.2942 - test_loss: 0.138555\n",
      "Epoch: 60/240 - train_loss: 0.3042 - test_loss: 0.139785\n",
      "Epoch: 329/330 - train_loss: 0.3001 - test_loss: 0.142035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:09:25,138]\u001b[0m Trial 27 finished with value: 13.50513316663988 and parameters: {'n layers': 4, 'Hidden size': 35, 'Learning rate': 0.0008035752798303906, 'Dropout rate': 0.1987039358435533, 'Epochs': 330}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/250 - train_loss: 1.2012 - test_loss: 0.904223\n",
      "Epoch: 239/240 - train_loss: 0.3152 - test_loss: 0.141213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:09:47,473]\u001b[0m Trial 33 finished with value: 13.098375297619214 and parameters: {'n layers': 3, 'Hidden size': 70, 'Learning rate': 0.0030971912317062774, 'Dropout rate': 0.554949504933222, 'Epochs': 230}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 208/210 - train_loss: 0.3038 - test_loss: 0.131156\n",
      "Epoch:  0/260 - train_loss: 1.2391 - test_loss: 0.816052\n",
      "Epoch: 209/210 - train_loss: 0.2925 - test_loss: 0.136756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:09:55,133]\u001b[0m Trial 6 finished with value: 12.421299611753717 and parameters: {'n layers': 5, 'Hidden size': 8, 'Learning rate': 0.009074192540916019, 'Dropout rate': 0.6187777460457625, 'Epochs': 200}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 180/240 - train_loss: 0.2930 - test_loss: 0.136539\n",
      "Epoch: 219/220 - train_loss: 0.2990 - test_loss: 0.151978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:10:16,246]\u001b[0m Trial 30 finished with value: 11.809430037100725 and parameters: {'n layers': 4, 'Hidden size': 5, 'Learning rate': 0.0027690800192607897, 'Dropout rate': 0.5502160358035015, 'Epochs': 220}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 239/240 - train_loss: 0.2882 - test_loss: 0.147321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:10:51,588]\u001b[0m Trial 34 finished with value: 16.288641569103703 and parameters: {'n layers': 4, 'Hidden size': 79, 'Learning rate': 0.003266417020622224, 'Dropout rate': 0.5496412060249122, 'Epochs': 240}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch:  0/260 - train_loss: 1.2629 - test_loss: 1.134687\n",
      "Epoch: 156/210 - train_loss: 0.5141 - test_loss: 0.411479\n",
      "Epoch: 57/230 - train_loss: 0.2919 - test_loss: 0.140783\n",
      "Epoch: 120/240 - train_loss: 0.2915 - test_loss: 0.142197\n",
      "Epoch:  0/260 - train_loss: 1.2020 - test_loss: 0.761574\n",
      "Epoch:  0/260 - train_loss: 1.5672 - test_loss: 1.172724\n",
      "Epoch:  0/260 - train_loss: 1.8874 - test_loss: 2.783575\n",
      "Epoch:  0/260 - train_loss: 1.4660 - test_loss: 1.064477\n",
      "Epoch: 62/250 - train_loss: 0.2944 - test_loss: 0.147256\n",
      "Epoch: 239/240 - train_loss: 0.2970 - test_loss: 0.145161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:12:20,666]\u001b[0m Trial 36 finished with value: 11.349368293153944 and parameters: {'n layers': 5, 'Hidden size': 85, 'Learning rate': 0.003210391540221693, 'Dropout rate': 0.5564651930597642, 'Epochs': 240}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 65/260 - train_loss: 0.2935 - test_loss: 0.139879\n",
      "Epoch: 120/240 - train_loss: 0.3522 - test_loss: 0.140944\n",
      "Epoch: 114/230 - train_loss: 0.2940 - test_loss: 0.142614\n",
      "Epoch: 180/240 - train_loss: 0.2907 - test_loss: 0.131330\n",
      "Epoch: 65/260 - train_loss: 0.2951 - test_loss: 0.142006\n",
      "Epoch:  0/270 - train_loss: 1.5432 - test_loss: 1.469902\n",
      "Epoch: 65/260 - train_loss: 0.3124 - test_loss: 0.138019\n",
      "Epoch: 124/250 - train_loss: 0.2910 - test_loss: 0.137578\n",
      "Epoch: 65/260 - train_loss: 0.2958 - test_loss: 0.145544\n",
      "Epoch: 171/230 - train_loss: 0.2950 - test_loss: 0.140982\n",
      "Epoch: 239/240 - train_loss: 0.3011 - test_loss: 0.153991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:13:53,532]\u001b[0m Trial 37 finished with value: 13.312553651937876 and parameters: {'n layers': 5, 'Hidden size': 67, 'Learning rate': 0.0031292444781853834, 'Dropout rate': 0.35348203691331515, 'Epochs': 240}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 130/260 - train_loss: 0.2891 - test_loss: 0.144949\n",
      "Epoch: 130/260 - train_loss: 0.3185 - test_loss: 0.138280\n",
      "Epoch: 65/260 - train_loss: 0.8588 - test_loss: 0.755559\n",
      "Epoch: 67/270 - train_loss: 0.2920 - test_loss: 0.144231\n",
      "Epoch: 186/250 - train_loss: 0.2947 - test_loss: 0.146541\n",
      "Epoch:  0/270 - train_loss: 1.3015 - test_loss: 1.079685\n",
      "Epoch: 130/260 - train_loss: 0.2897 - test_loss: 0.142344\n",
      "Epoch: 228/230 - train_loss: 0.2958 - test_loss: 0.142489\n",
      "Epoch: 229/230 - train_loss: 0.3157 - test_loss: 0.152662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:14:49,379]\u001b[0m Trial 38 finished with value: 13.112081218746575 and parameters: {'n layers': 5, 'Hidden size': 43, 'Learning rate': 0.0038562644679960185, 'Dropout rate': 0.36001367655106276, 'Epochs': 230}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 130/260 - train_loss: 0.3035 - test_loss: 0.143118\n",
      "Epoch:  0/270 - train_loss: 1.4344 - test_loss: 1.168873\n",
      "Epoch: 195/260 - train_loss: 0.2901 - test_loss: 0.141880\n",
      "Epoch: 195/260 - train_loss: 0.2927 - test_loss: 0.138165\n",
      "Epoch: 248/250 - train_loss: 0.2895 - test_loss: 0.140757\n",
      "Epoch: 249/250 - train_loss: 0.3001 - test_loss: 0.138524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:15:50,642]\u001b[0m Trial 39 finished with value: 11.131134621033306 and parameters: {'n layers': 5, 'Hidden size': 90, 'Learning rate': 0.0016889718812867268, 'Dropout rate': 0.3367921570776009, 'Epochs': 250}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookback 3\n",
      "Epoch: 180/240 - train_loss: 0.2912 - test_loss: 0.137141\n",
      "Epoch: 134/270 - train_loss: 0.2968 - test_loss: 0.135565\n",
      "Epoch: 67/270 - train_loss: 0.2864 - test_loss: 0.140167\n",
      "Epoch: 195/260 - train_loss: 0.3153 - test_loss: 0.139810\n",
      "Epoch:  0/180 - train_loss: 1.1234 - test_loss: 0.711635\n",
      "Epoch: 130/260 - train_loss: 0.5976 - test_loss: 0.474974\n",
      "Epoch: 195/260 - train_loss: 0.2864 - test_loss: 0.138493\n",
      "Epoch: 67/270 - train_loss: 0.2912 - test_loss: 0.144429\n",
      "Epoch: 259/260 - train_loss: 0.2897 - test_loss: 0.144821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:16:53,002]\u001b[0m Trial 42 finished with value: 11.70997660529231 and parameters: {'n layers': 5, 'Hidden size': 111, 'Learning rate': 0.0016971111712879455, 'Dropout rate': 0.6198409833794942, 'Epochs': 260}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259/260 - train_loss: 0.2899 - test_loss: 0.136975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:17:09,691]\u001b[0m Trial 40 finished with value: 11.115256620197341 and parameters: {'n layers': 3, 'Hidden size': 80, 'Learning rate': 0.00169776885519152, 'Dropout rate': 0.3470217313919829, 'Epochs': 250}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/180 - train_loss: 0.3188 - test_loss: 0.139093\n",
      "Epoch: 259/260 - train_loss: 0.2925 - test_loss: 0.136792\n",
      "Epoch: 134/270 - train_loss: 0.3318 - test_loss: 0.163533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:17:25,509]\u001b[0m Trial 45 finished with value: 12.178767377044787 and parameters: {'n layers': 3, 'Hidden size': 114, 'Learning rate': 0.001594626261642627, 'Dropout rate': 0.34874432692730784, 'Epochs': 260}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/270 - train_loss: 0.2916 - test_loss: 0.139482\n",
      "Epoch: 65/260 - train_loss: 0.3068 - test_loss: 0.154449\n",
      "Epoch: 104/210 - train_loss: 0.3134 - test_loss: 0.146628\n",
      "Epoch: 134/270 - train_loss: 0.2889 - test_loss: 0.139868\n",
      "Epoch: 90/180 - train_loss: 0.3011 - test_loss: 0.146649\n",
      "Epoch: 208/210 - train_loss: 0.4447 - test_loss: 0.338777\n",
      "Epoch: 239/240 - train_loss: 0.3129 - test_loss: 0.140278\n",
      "Epoch: 209/210 - train_loss: 0.4343 - test_loss: 0.337388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:18:11,250]\u001b[0m Trial 35 finished with value: 13.139085996587973 and parameters: {'n layers': 5, 'Hidden size': 77, 'Learning rate': 0.0027174890087695715, 'Dropout rate': 0.5767893184204269, 'Epochs': 220}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259/260 - train_loss: 0.3402 - test_loss: 0.145370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:18:12,442]\u001b[0m Trial 18 finished with value: 18.23125112843664 and parameters: {'n layers': 4, 'Hidden size': 41, 'Learning rate': 0.00012189228356825456, 'Dropout rate': 0.22281712737292036, 'Epochs': 170}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n",
      "\u001b[32m[I 2023-02-14 03:18:13,410]\u001b[0m Trial 41 finished with value: 14.173932269210999 and parameters: {'n layers': 3, 'Hidden size': 90, 'Learning rate': 0.001500998582661889, 'Dropout rate': 0.34162621268126947, 'Epochs': 250}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/210 - train_loss: 0.4041 - test_loss: 0.297510\n",
      "Epoch: 195/260 - train_loss: 0.4792 - test_loss: 0.378718\n",
      "Epoch: 201/270 - train_loss: 0.3017 - test_loss: 0.134385\n",
      "Epoch: 268/270 - train_loss: 0.2903 - test_loss: 0.139692\n",
      "Epoch: 269/270 - train_loss: 0.2884 - test_loss: 0.135903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:18:47,560]\u001b[0m Trial 46 finished with value: 11.45137008397955 and parameters: {'n layers': 3, 'Hidden size': 132, 'Learning rate': 0.0015308063615737532, 'Dropout rate': 0.3320920538481016, 'Epochs': 270}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135/180 - train_loss: 0.3137 - test_loss: 0.138326\n",
      "Epoch: 130/260 - train_loss: 0.2932 - test_loss: 0.142096\n",
      "Epoch: 201/270 - train_loss: 0.2904 - test_loss: 0.141721\n",
      "Epoch: 52/210 - train_loss: 0.2962 - test_loss: 0.135858\n",
      "Epoch: 156/210 - train_loss: 0.2962 - test_loss: 0.135379\n",
      "Epoch: 259/260 - train_loss: 0.4123 - test_loss: 0.304315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:19:40,156]\u001b[0m Trial 44 finished with value: 11.327712528693597 and parameters: {'n layers': 3, 'Hidden size': 108, 'Learning rate': 0.0001039294773132314, 'Dropout rate': 0.34632035764090174, 'Epochs': 260}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179/180 - train_loss: 0.2892 - test_loss: 0.143175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:19:42,724]\u001b[0m Trial 49 finished with value: 12.292091591690893 and parameters: {'n layers': 3, 'Hidden size': 114, 'Learning rate': 0.0017876192348923578, 'Dropout rate': 0.44463809541337485, 'Epochs': 180}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104/210 - train_loss: 0.3143 - test_loss: 0.165913\n",
      "Epoch: 268/270 - train_loss: 0.3119 - test_loss: 0.135348\n",
      "Epoch: 269/270 - train_loss: 0.2910 - test_loss: 0.135454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:19:55,070]\u001b[0m Trial 47 finished with value: 13.440906728555802 and parameters: {'n layers': 3, 'Hidden size': 118, 'Learning rate': 0.0016836121514858344, 'Dropout rate': 0.35480816184025743, 'Epochs': 270}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208/210 - train_loss: 0.2940 - test_loss: 0.138389\n",
      "Epoch: 209/210 - train_loss: 0.2856 - test_loss: 0.135886\n",
      "Epoch: 268/270 - train_loss: 0.2898 - test_loss: 0.140209\n",
      "Epoch: 269/270 - train_loss: 0.3689 - test_loss: 0.139739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:20:17,063]\u001b[0m Trial 3 finished with value: 10.066371770812982 and parameters: {'n layers': 6, 'Hidden size': 12, 'Learning rate': 0.0008345619259328371, 'Dropout rate': 0.4740947002653488, 'Epochs': 440}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195/260 - train_loss: 0.2889 - test_loss: 0.138413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:20:18,045]\u001b[0m Trial 48 finished with value: 14.525575610451973 and parameters: {'n layers': 3, 'Hidden size': 136, 'Learning rate': 0.0016919884951063112, 'Dropout rate': 0.4173724241427891, 'Epochs': 270}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104/210 - train_loss: 0.3067 - test_loss: 0.141553\n",
      "Epoch: 52/210 - train_loss: 0.2974 - test_loss: 0.151558\n",
      "Epoch: 156/210 - train_loss: 0.3563 - test_loss: 0.152083\n",
      "Epoch: 52/210 - train_loss: 0.6954 - test_loss: 0.583594\n",
      "Epoch: 52/210 - train_loss: 0.5642 - test_loss: 0.472153\n",
      "Epoch: 52/210 - train_loss: 0.3096 - test_loss: 0.142732\n",
      "Epoch: 156/210 - train_loss: 0.2898 - test_loss: 0.139375\n",
      "Epoch: 259/260 - train_loss: 0.3119 - test_loss: 0.142413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:21:08,577]\u001b[0m Trial 43 finished with value: 13.603441888723141 and parameters: {'n layers': 3, 'Hidden size': 123, 'Learning rate': 0.0015460576631961414, 'Dropout rate': 0.32459368035369107, 'Epochs': 250}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/210 - train_loss: 0.4461 - test_loss: 0.365048\n",
      "Epoch: 104/210 - train_loss: 0.2899 - test_loss: 0.145170\n",
      "Epoch: 208/210 - train_loss: 0.2942 - test_loss: 0.140444\n",
      "Epoch: 209/210 - train_loss: 0.3035 - test_loss: 0.139234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:21:14,653]\u001b[0m Trial 17 finished with value: 12.504140592063584 and parameters: {'n layers': 4, 'Hidden size': 18, 'Learning rate': 0.0005084548614335883, 'Dropout rate': 0.10462050726437114, 'Epochs': 450}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104/210 - train_loss: 0.5391 - test_loss: 0.420055\n",
      "Epoch: 104/210 - train_loss: 0.3994 - test_loss: 0.312386\n",
      "Epoch: 208/210 - train_loss: 0.2860 - test_loss: 0.136725\n",
      "Epoch: 209/210 - train_loss: 0.3019 - test_loss: 0.139517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:21:39,924]\u001b[0m Trial 19 finished with value: 11.835575013255342 and parameters: {'n layers': 3, 'Hidden size': 109, 'Learning rate': 0.0025238694647946526, 'Dropout rate': 0.09578854517066808, 'Epochs': 210}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104/210 - train_loss: 0.2942 - test_loss: 0.134965\n",
      "Epoch: 156/210 - train_loss: 0.2958 - test_loss: 0.135651\n",
      "Epoch: 156/210 - train_loss: 0.4224 - test_loss: 0.325456\n",
      "Epoch: 104/210 - train_loss: 0.3324 - test_loss: 0.201803\n",
      "Epoch: 156/210 - train_loss: 0.3320 - test_loss: 0.215404\n",
      "Epoch: 208/210 - train_loss: 0.2944 - test_loss: 0.138405\n",
      "Epoch: 209/210 - train_loss: 0.2964 - test_loss: 0.155177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:22:12,885]\u001b[0m Trial 2 finished with value: 11.177663592576792 and parameters: {'n layers': 3, 'Hidden size': 6, 'Learning rate': 0.002650778261484116, 'Dropout rate': 0.49300015167321676, 'Epochs': 160}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/210 - train_loss: 0.2987 - test_loss: 0.149616\n",
      "Epoch: 208/210 - train_loss: 0.3575 - test_loss: 0.252605\n",
      "Epoch: 209/210 - train_loss: 0.3648 - test_loss: 0.251945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:22:19,398]\u001b[0m Trial 11 finished with value: 16.837791481323464 and parameters: {'n layers': 6, 'Hidden size': 16, 'Learning rate': 0.00014933946595392043, 'Dropout rate': 0.45514362762531974, 'Epochs': 320}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/210 - train_loss: 0.3353 - test_loss: 0.152272\n",
      "Epoch: 208/210 - train_loss: 0.3011 - test_loss: 0.165841\n",
      "Epoch: 209/210 - train_loss: 0.3032 - test_loss: 0.164934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:22:28,199]\u001b[0m Trial 0 finished with value: 14.661132207219643 and parameters: {'n layers': 4, 'Hidden size': 81, 'Learning rate': 0.00024787495345522675, 'Dropout rate': 0.7214507201703112, 'Epochs': 380}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208/210 - train_loss: 0.2944 - test_loss: 0.143208\n",
      "Epoch: 209/210 - train_loss: 0.2879 - test_loss: 0.148897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:22:32,543]\u001b[0m Trial 15 finished with value: 10.568270961432608 and parameters: {'n layers': 4, 'Hidden size': 135, 'Learning rate': 0.002377085948450994, 'Dropout rate': 0.5639428533621352, 'Epochs': 350}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208/210 - train_loss: 0.2907 - test_loss: 0.140999\n",
      "Epoch: 209/210 - train_loss: 0.3095 - test_loss: 0.141441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-14 03:22:38,967]\u001b[0m Trial 9 finished with value: 13.729605531760166 and parameters: {'n layers': 6, 'Hidden size': 315, 'Learning rate': 0.000398106627907428, 'Dropout rate': 0.7045553857514245, 'Epochs': 200}. Best is trial 32 with value: 9.167614902218277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics for : \n",
      "  Number of finished trials:  50\n",
      "Best trial of city:  Sơn La\n",
      "  Value:  9.167614902218277\n",
      "optimize result of city: Sơn La\n",
      "kết thúc study trong: 187\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Main Cell for optimize\n",
    "#########################\n",
    "dt_started = datetime.now()\n",
    "\n",
    "##################################################\n",
    "# Input param for Optimize Run\n",
    "ntry = 50\n",
    "njob = -1\n",
    "\n",
    "# Lưu thông tin traceback study và error city trong quá trình optimize\n",
    "l_study_city ={}\n",
    "# l_errCity =[]\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "  best_param = pd.DataFrame()\n",
    "  l_studies = {}\n",
    "  l_errCity =[]\n",
    "\n",
    "  for city in cities:\n",
    "    # Use Tree-structured Parzen Estimator sampler to minimise RMSE\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "\n",
    "    # truyền multiple param vào trong biến trial\n",
    "    obj_func = lambda trial: objective(trial, city)\n",
    "\n",
    "    try:\n",
    "      # Optimise over 100 trials\n",
    "      study.optimize(obj_func, n_trials=ntry, n_jobs=njob)\n",
    "\n",
    "      # Print results\n",
    "      print(\"Study statistics for : \")\n",
    "      print(\"  Number of finished trials: \", len(study.trials))\n",
    "      \n",
    "      print(\"Best trial of city: \",city)\n",
    "      best_trial = study.best_trial\n",
    "      print(\"  Value: \", best_trial.value)   \n",
    "\n",
    "      # lưu best param vào trong biến toàn cục\n",
    "      one_city_param = pd.DataFrame({\n",
    "                              'City': city,\n",
    "                              'Alg_name': 'transformer',\n",
    "                              'Best_value': best_trial.value,\n",
    "                              'n_try_opt': ntry,\n",
    "                              'n Feature': 3, # set cứng\n",
    "                              'Batch Size': 16, # set cứng\n",
    "                              'Lookback Window': 3, # set cứng\n",
    "                              'Epochs': best_trial.params['Epochs'],\n",
    "                              'Hidden Size': best_trial.params['Hidden size'],\n",
    "                              'n Layers': best_trial.params['n layers'],\n",
    "                              'Learning rate': best_trial.params['Learning rate'], \n",
    "                              'Num. filters': '', # Transformer không dùng\n",
    "                              'Dropout rate': best_trial.params['Dropout rate']}, index=[0])\n",
    "      one_city_param.to_excel(prj_path_opt+'/tf/diarrhoea_opt_hyperparam_transformer_'+city+'.xlsx')\n",
    "      best_param = best_param.append(one_city_param)\n",
    "    except:# có error thì lưu vào l_errCity để check lại sau \n",
    "      l_errCity.append(city)\n",
    "    # Plot result\n",
    "    l_studies[city] = study # thêm vào danh sách sài sau\n",
    "    print('optimize result of city: '+ city)\n",
    "    # optuna.visualization.plot_optimization_history(study)\n",
    "    # optuna.visualization.plot_param_importances(study)\n",
    "    # optuna.visualization.plot_slice(study)\n",
    "  \n",
    "#   best_param.to_excel(prj_path_opt+'/tf/diarrhoea_opt_hyperparam_transformer.xlsx')\n",
    "\n",
    "dt_ended = datetime.now()\n",
    "print('kết thúc study trong:', round((dt_ended - dt_started).total_seconds()/60))\n",
    "# print(l_errCity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RbjNytCjdHLl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ok\":true,\"result\":{\"message_id\":469,\"sender_chat\":{\"id\":-1001712314864,\"title\":\"PTN_Announcement\",\"username\":\"ptn_announcement\",\"type\":\"channel\"},\"chat\":{\"id\":-1001712314864,\"title\":\"PTN_Announcement\",\"username\":\"ptn_announcement\",\"type\":\"channel\"},\"date\":1676344959,\"text\":\"Server Ch\\u1ea1y Xong TF\"}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def send_to_telegram(message):\n",
    "\n",
    "    apiToken = '5908735099:AAGVSLrW62aXPBP-GrMvxoVgMsuJxXJpP1Q'\n",
    "    chatID = '@ptn_announcement'\n",
    "    apiURL = f'https://api.telegram.org/bot{apiToken}/sendMessage'\n",
    "\n",
    "    try:\n",
    "        response = requests.post(apiURL, json={'chat_id': chatID, 'text': message})\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "send_to_telegram(\"Server Chạy Xong TF\" )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "24f3299fa11d098f3e36f80146bbe61fdadb7bfe8872ee0c4a379787469f5f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
